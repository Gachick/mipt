\documentclass{article}


\input{~/mipt/preamble}

\begin{document}

\section{Занятие 1}

\subsection{Основные распределения в Мат Стат}
\subsubsection{Гамма распределение}
\begin{gather*}
  \xi \sim \Gamma(\lambda,a) \; \lambda>0,a>0 \\
  P(x)=\frac{\lambda^{a}}{\Gamma(a)}x^{a-1}e^{-\lambda x} \; \{(0,+\infty)\}
\end{gather*}

\incfig{l1_g_distr}
\begin{gather*}
  \Gamma(S+1)=S \Gamma(S) \qquad \Gamma(S)= \int_{0}^{\infty}x^{s-1}e^{-x}dx \; x>0 \\
  M[ \Gamma]=\int_{-\infty}^{\infty} \rho(x)dx= \int_{0}^{\infty}\frac{\lambda^{a}}{ \Gamma(a)}(\frac{t}{\lambda})^{a}e^{-t}\frac{dt}{\lambda}=
  =\frac{1}{\lambda \Gamma(a)}\int_{0}^{\infty}t^{a}e^{-t}dt=\frac{a}{\lambda} \\
  D[\xi]=M[\xi^{2}]-M^{2}[\xi]=\frac{a^2+a}{\lambda^2}-(\frac{a}{\lambda})^2=\frac{a}{\lambda^2} \\
\end{gather*}
\begin{theorem}[Свойство суммы]
$\xi_1,\dots,\xi_n$ независимы, $\xi_i \sim \Gamma(\lambda,a_i)$, $\eta=\xi_1+\dots+\xi_n \sim \Gamma(\lambda,a_1+\dots+a_n)$
\end{theorem}
\begin{proof}
$\xi_1 \sim \Gamma(\lambda,a_1)$. $\xi_2 \sim \Gamma(\lambda,a_2)$ - независимые, $\eta=\xi_1+\xi_2$
\begin{gather*}
\Phi(y)=P(\eta < y)=P(\xi_2+\xi_2<y)=\iint_{x_1+x_2<y}p(x_1,x_2)dx_1dx_2= \\
=\int_{0}^{y}dx_2\int_{0}^{y-x_1}\frac{\lambda^{a_1}}{\Gamma(a_1)x_1^{a_1-1}e^{-\lambda x_1}}\frac{\lambda^{a_2}}{\Gamma(a_2)x_2^{a_2-2}e^{-\lambda x_2}}dx_2 \\
  \phi(y)=\Phi'(y)
\end{gather*}
\end{proof}

\subsubsection[Распределение Парсона]{Распределение Парсона $\chi^2$}
$\xi_i\sim N(0,1)$ - независимы, $\eta=\xi_1^2+\dots+\xi_n^2=\chi^2$
\begin{gather*}
  \Phi(y)=P(\xi^2<y)=\left\{\begin{aligned}
    & y\le0 \quad :0 \\
    & y > 0 \quad :P(-\sqrt{y}<\xi<\sqrt{y})
  \end{aligned}\right. \\
  \phi(x)=   \left\{\begin{aligned}
      & \frac{1}{2\sqrt{y}}F'(\sqrt{y})+\frac{1}{2\sqrt{y}}F'(-\sqrt{y}), \; y> 0 \\
      & 0, \; y<0
    \end{aligned}\right. \\
  p(x)=\frac{e^{x^2/2}}{\sqrt{2\pi}} \\
  \phi(y)=\left\{\begin{aligned}
    & \frac{1}{\sqrt{y}}\frac{e^{-y/2}}{\sqrt{2\pi}}, \; y>0  \\
    & 0, \; y\le 0
  \end{aligned}\right. \\
  p(x)=\frac{\lambda^{a}}{\Gamma(a)}x^{a-1}e^{-\lambda x}\{(0;+\infty)\} \qquad \lambda=\frac{1}{2} \qquad a=\frac{1}{2} \\
  \xi^{2}\sim \Gamma(\frac{1}{2}, \frac{1}{2}) \qquad \xi_1^{2}+\dots+\xi_n^{2} \sim \Gamma(\frac{1}{2}, \frac{n}{2})=\chi^{2}(n)
\end{gather*}
$n$ - число степеней свободы
\begin{gather*}
  M[\eta]=\frac{a}{\lambda}=\frac{n/2}{1/2}=n \\
  D[\eta]=\frac{a}{\lambda^{2}}=\frac{n/2}{1/4}=2n
\end{gather*}

\begin{theorem}[Свойство суммы]
  $\xi_1,\dots,\xi_m$ - независ, $\xi_i\sim \chi^{2}(n_i)$, $\xi_1+\dots+\xi_n\sim \chi^2(n_1+\dots+n_m)$
\end{theorem}

\subsection{Распределение Стьюдента (Госсет)}
$\xi \sim N(0,1)$, $\eta \sim \chi^2(m)$ - независимы, $\frac{\xi}{\sqrt{\eta/m}}\sim t(m)$

\incfig{l1_st_distr}
\[
  p(x)=\frac{(m)^{m/2}\Gamma(\frac{m+1}{2})}{\sqrt{\pi}\Gamma(\frac{m}{2})(x^2+m)^{\frac{m+1}{2}}}
\]

\subsection{Распределение Фишера}
$\xi\sim \chi^2(n)$, $\eta\sim \chi^2(m)$ - независимые, $\frac{\xi/n}{\eta/m}\sim F(n,m)$

\incfig{l1_fi_distr}
\subsection{Нормальное распределение}
\begin{gather*}
  p(\vec{x})=\frac{1}{(\sqrt{2\pi})^n}\frac{1}{\sqrt{detK}}e^{-\frac{1}{2}(\vec{x}-\vec{a})^T K^{-1}(\vec{x}-\vec{a})} \\
  \vec{\xi}\sim N(\vec{a},R)\\
\end{gather*}
Свойства:
\begin{itemize}
  \item $\xi\sim N(0,1)$, $\eta=a\xi+b \sim N(b,a^2)$
  \item $\xi\sim N(\alpha, \sigma^2)$, $\eta=a\xi+b\sim N(a\alpha+b, \sigma^2a^2)$
  \item $\xi\sim N(\vec{0},E)$,$\vec{\eta}=A\vec{\xi}+\vec{b}$, $A:n\times n,detA\neq 0$
      
    \begin{gather*}
      \Phi(t_1,\dots,t_n)=P(\eta_1<t_1,\dots,\eta_n<t_n)=P(\vec{\eta}<\vec{t})=P(A\vec{\xi}+\vec{b}<\vec{t})= \\
    = \int\dots\int_{A\vec{x}+\vec{b}<\vec{t}}p(x_1,\dots,x_n)dx_1\dots dx_n= \\
      \vec{y}=A\vec{x}+\vec{b} \qquad J=\left|\frac{\partial \vec{x}}{\partial \vec{y}}\right| \qquad \frac{1}{J}=detA \\
    =\idotsint_{\vec{y}<\vec{t}}p(A^{-1}(\vec{y}-\vec{b}))\frac{1}{|detA|}dy_1\dots dy_n \\
    \phi(\vec{t})=p(A^{-1}(\vec{y}-\vec{b}))\frac{1}{|detA|} \\
    \phi(\vec{t})=\frac{1}{|detA|}\frac{1}{(\sqrt{2\pi})^n}e^{-\frac{1}{2}(A^{-1}(\vec{y}-\vec{b})^T) (A^{-1}(\vec{y}-\vec{b}))}= \\
  =\frac{1}{|detA|}\frac{1}{(\sqrt{2\pi})^n}e^{-\frac{1}{2}(\vec{t}-\vec{b})^T (A^T)^{-1} A^{-1}(\vec{t}-\vec{b})} \\
  K=AA^T \qquad \vec{\eta}=A\vec{\xi}+\vec{b}\sim N(\vec{b}, AA^T) \\
    \end{gather*}
\item $\xi\sim N(\vec{a},K)$, $\vec{\eta}=A\vec{\xi}+\vec{b}\sim N(A\vec{a}+\vec{b},AKA^{T})$, $A:n\times n$, $detA\neq 0$
\item Для $A:m\times n$ два предыдущих свойства так же верны
\item $\xi,\eta$ - независ $\implies$ $cov(\xi,\eta)=0$, в другую сторону не верно
\[
  \left\{\begin{aligned}
    \xi \sim N(a_1, \sigma_1^2) \\ 
    \eta \sim N(a_2, \sigma_2^2) \\ 
    \text{независимые}
  \end{aligned}\right.
  \Leftrightarrow
  (\xi,\eta)\sim N\left(\begin{pmatrix}
    a_1 \\ a_2
  \end{pmatrix}\begin{pmatrix}
  \sigma_1^{2} & 0 \\ 
  0 & \sigma_2^{2}
\end{pmatrix}\right)
\]
\[
  \left\{\begin{aligned}
    \xi \sim N(a_1, \sigma_1^2) \\ 
    \eta \sim N(a_2, \sigma_2^2) \\ 
    cov(\xi,\eta)=0
  \end{aligned}\right.
  \Leftarrow
  (\xi,\eta)\sim N\left(\begin{pmatrix}
    a_1 \\ a_2
  \end{pmatrix}\begin{pmatrix}
  \sigma_1^{2} & 0 \\ 
  0 & \sigma_2^{2} 
\end{pmatrix}\right)
\]
\end{itemize}
\begin{lemma}[Лемма Фишера]
Пусть $\vec{\xi}\sim N(\vec{0},E)$ и $C$ ортогональная матрица,
$\vec{\eta}=C\vec{\xi}$, тогда $\forall k=1\dots n-1$ сл. вел. 
$\kappa=\sum_{i=1}^{n}\xi_{i}^{2}-\eta_{1}^{2}-\eta_{2}^{2}-\dots -\eta_{k}^{2}\sim \chi^{2}(n-k) $
и вел $\kappa,\eta_1,\eta_2,\dots ,\eta_k$ независ.
\end{lemma}
\begin{proof}
  \begin{gather*}
    \vec{\eta}\sim N(\vec{0},\underbrace{CC^{T}}_{E}) \\ 
    \eta_1^{2}+\dots +\eta_n^{2}=\vec{\eta}^{T}\vec{\eta}=\vec{\xi}^{T}C^{T}C\vec{\xi}=\xi_1^{2}+\dots +\xi_{n}^{2} \\ 
    \kappa= \eta_{k-1}^{2}+\dots+\eta_{n}^{2} \\ 
    \kappa=\chi^{2}(n-k)
  \end{gather*}
\end{proof}

\begin{theorem}[Фишера]
  Пусть $\xi_1,\dots ,\xi_n$ независ и $\xi_i\sim N(a,\sigma^{2})$, тогда:
  \begin{enumerate}
    \item $\phi=\sqrt{n}\frac{\bar{\xi}-a}{\sigma}\sim N(0,1)$,
      $\bar{\xi}=\frac{1}{n}\sum_{1}^{n}\xi_i$
    \item $\psi=\sum_{i=1}^{n}\frac{(\xi_i-\bar{\xi})^2}{\sigma^{2}}\sim \chi^{2}(n-1)$
    \item $\phi$ и $\psi$ независ.
  \end{enumerate}
\end{theorem}
\begin{proof}
  \begin{gather*}
    \phi=\frac{1}{\sqrt{n}}\frac{\sum_{}^{n}\xi_i-na}{\sigma}=\frac{1}{\sqrt{n}}\sum_{}^{n}\left(\frac{\xi_i-a}{\sigma}\right) \\ 
    \frac{\xi_i-a}{\sigma}=\frac{1}{\sigma}\xi_i-\frac{a}{\sigma} \sim N(\frac{a}{\sigma}-\frac{a}{\sigma}, \sigma^{2}\frac{1}{\sigma^{2}})=N(0,1) \\ 
  \phi = \frac{1}{\sqrt{n}}\sum_{}^{n}\eta_i=(\frac{1}{\sqrt{n}}\dots \frac{1}{\sqrt{n}})\vec{\eta}\sim N(\vec{0}, AA^{T})=N(0,1)
  \end{gather*}
  1) Доказан 
  \begin{gather*}
    \psi = \sum_{}^{n}\left(\underbrace{\frac{\xi_i-a}{\sigma}}_{\eta_i\sim N(0,1)}-\underbrace{\frac{\bar{\xi}-a}{\sigma}}_{\bar{\eta}}\right)^{2}=
    \sum_{}^{n}(\eta_i-\bar{\eta})^{2}=\sum_{}^{n}(\eta_i^2-2\eta_i \bar{\eta}+(\bar{\eta})^2)= \\
    = \sum_{}^{n}\eta_i^{2}-2\bar{\eta}\sum_{}^{n}\eta_i+n(\bar{\eta})^{2}=\sum_{}^{n}\eta_i^{2}-n(\bar{\eta})^{2} \\ 
    \eta_i\sim N(0,1) \qquad \zeta^{2}=n\bar{\eta}^{2} \qquad \zeta=\sqrt{n}\bar{\eta}=\frac{1}{\sqrt{n}}\sum_{}^{n}\eta_i=A\vec{\eta}=\phi
  \end{gather*}
  $A=\left(\frac{1}{\sqrt{n}}\dots \frac{1}{\sqrt{n}}\right)$ $\implies$ $C$ - ортог. матрица (Грамма-Шмидта)
  
  ($A$ получается строчкой матрицы $C$ и тогда $\zeta$ - одна из координат в другом базисе и применима Лемма Фишера)

  По лемме Фишера $\psi\sim \chi^{2}(n-1)$, $\psi$ и $A\bar{\eta}$ независ
\end{proof}

\begin{theorem}[О проекции]
  Пусть $\vec{\xi}\sim N(\vec{0},\sigma^{2}E)$, $L_1:dimL_1=m_1$ и $L_2:dimL_2=m_2$ два
  ортогональных подпространства $\R^{n}$, $\vec{\eta}_1$ - проекция $\vec{\xi}$ на $L_1$,
  норм. распр., независ. и $\frac{|\eta_1|^{2}}{\sigma^{2}}\sim\chi^{2}(dimL_1)$,
  $\frac{|\eta_2|^{2}}{\sigma^{2}}\sim\chi^{2}(dimL_2)$
\end{theorem}
\begin{proof}
  $\vec{\eta}_1=A_1\vec{\xi}\sim N(\dots,\dots )$, $\vec{\zeta}=C\vec{\xi}$,
  $C$ - ортогональная. $\vec{\zeta}\sim N(\vec{0},C\sigma^{2}EC^{T})=N(\vec{0},\sigma^{2}E)$.
  Новый ортонормированный базис $e_1'\dots e_{m}'$ в $L_1$, 
  $e_{m+1}'\dots e_{n}'$ в $L_2$, $\vec{\eta_1}=\zeta_1e_1'+\dots +\zeta_{m}e_{m}'$,
  $\vec{\eta_2}=\zeta_{m+1}e_{m+1}'+\dots +\zeta_{n}e_{n}'$
\[
  \frac{\bar{\xi}}{\sigma}\sim N(\vec{0},E) \qquad \frac{|\eta_1|^{2}}{\sigma^{2}}=\sum_{}^{}\frac{\xi_i^{2}}{\sigma^{2}}\sim \chi^{2}(m_1)
\]
\end{proof}

% lecture 2 
 
\section{Порядковые случайные величины}
$\xi_1,\xi_2,\dots ,\xi_n$ назавис, $\xi_i \sim F(x)$
\[
  \eta=min(\xi_1,\dots \xi_n) \sim ? \qquad
  \zeta=max(\xi_1,\dots \xi_n) \sim ? 
\]
\begin{gather*}
  \Phi(y)=P(\eta<y)=1-P(\eta \ge y)=1-P(min(\xi_1,\dots ,\xi_n) \ge y)= \\ 
  =1-P(\xi_1\ge y,\dots ,\xi_n \ge y) = 1 - \prod_{i=1}^{n}P(\xi_i \ge y)= \\ 
  =1 - \prod_{i=1}^{n}(1-P(\xi_i < y))=1-(1-F(y))^{n}
\end{gather*}
\begin{gather*}
  \Psi(z)=P(\zeta<z)=P(max(\xi_1,\dots ,\xi_n) < z)= \\ 
  = P(\xi_1 < z, \dots , \xi_n<z)=\prod_{i=1}^{n}P(\xi_i < z)=(F(z))^{n}
\end{gather*}
Порядковые величины:
\begin{gather*}
  \xi_{(1)}=min(\xi_1, \dots , \xi_n) \\
  \xi_{(2)}=min(\xi_i:\xi_i\neq \xi_{(1)}) \\
  \xi_{(3)}=min(\xi_i:\xi_i\neq \xi_{(1)}, \xi_i \neq \xi_{(2)}) \\
  \dots \\ 
  \xi_{(n)}=max(\xi_1, \dots , \xi_n)
\end{gather*}
Положим $F(x)$ - непрерывна:

\incfig{l2_poryad}
\begin{gather*}
  P(t\ \le \xi_{(k)} < t + \Delta t)= \\
  =nP(t\le \xi<t+\Delta t)C_{n-1}^{k-1}(P(\xi<t))^{k-1}(P(\xi \ge t+\Delta t))^{n-k}C_{n-k}^{n-k}= \\
  =\kappa(t+\Delta t) - \kappa(t) \\ 
  n\frac{F(t+\Delta t)-F(t)}{\Delta t}C_{n-1}^{k-1}(F(t))^{k-1}(1-F(t+\Delta t))^{n-k}=\frac{\kappa(t+\Delta t)-\kappa(t)}{\Delta t}\\ 
  \kappa(t)=np(t)C_{n-1}^{k-1}(1-F(t))^{n-k}(F(t))^{k-1}
\end{gather*}
$\kappa(t)$ - плотность распределения $\xi_{(k)}$, $p(t)=F'(t)$

$\xi_{(1)}$ и $\xi_{(n)}$ совместное распр
\begin{gather*}
  G(y,z)=P(\xi_{(1)}<y,\xi_{(n)}<z) \\ 
  P(\xi_{(n)}<z)=P(\xi_{(1)}<y, \xi_{(n)} < z) + P(\xi_{(1)} \ge y, \xi_{(n)} < z) \\ 
  \Psi(z)=(F(z))^{n}=P(\xi_{(1)}<y,\xi_{(n)}<z)+\prod_{i=1}^{n}\underbrace{P(y \le \xi_i < z)}_{F(z)-F(y)} \\ 
  G(y,z)=P(\xi_{(1)}<y,\xi_{(n)}<z)=\left\{\begin{aligned}
      &(F(z))^{n},\; & y > z \\ 
      &(F(z))^{n}-(F(z)-F(y))^{n}, \; & y\le z
  \end{aligned}\right.
\end{gather*}

\section{Моделирование случайных величин}
\incfig{l2_model}
$\xi\sim F(x)$, $\eta\sim R(0,1)$, $F(x)=\eta_1 \to x_1$, 
для псевдослучайных чисел вихрь Мерсенна

\section{Основные задачи статистики}
Явление $\rightarrow$ математическая модель явления $\rightarrow$ вероятностная модель явления $\xi_i$.

Выборка - n наблюдений над явлением 
$\rightarrow$описательная статистика (непараметрическая), выбор классов (e.g. $\epsilon \sim N(a,\sigma^{2})$)
$\rightarrow$ параметрическая статистика (e.g. $\epsilon\sim N(a,\sigma^{2})$, $a-?$, $b-?$)

\begin{eg}
  Пытаемся понять как остывает чашка чая.
  \[
    \frac{dT}{dt}=k(T-T_0)+\epsilon
  \]
  Вероятностная модель явления с двумя случайными величинами
  (погрешности измерений $\epsilon$ и внутри $k$).

  Распределения полагаем нормальными и так далее.
\end{eg}

\begin{enumerate}
  \item Определение параметров и оценка их точности
  \item Проверка статистических гипотиз
\end{enumerate}

Характеристики модели $\theta$, по выборке оценка $\bar{\theta}(\vec{x}_n)$,
$n$ - объём выборки.

Статистика - $\forall$ барелевская функция от $\vec{x}_n$
(борелевская $g:\R\to\R \; \forall B\in \mathbb{B} \true g^{-1}(B)\in \mathbb{B}$).

Воспринимаем $\vec{x}_n$ с двух сторон:
\begin{enumerate}
  \item конкретные наблюдения над явлением
  \item независимые случайные величны с распределением, одинаковым со случайными величинами в вероятностной модели
\end{enumerate}

\subsection{Свойства оценок}
$\Theta$ - множество значений $\theta$, $\theta \in \Theta$, 
$\tilde{\theta}(\vec{x}_n)$ - оценка $\theta$ по выборке
\begin{enumerate}
  \item несмещённость $\forall\theta \in \Theta \true M[\tilde{\theta}(\vec{x}_n)]=\theta$
  \item состоятельность $\forall \theta \in \Theta \true \tilde{\theta} \overset{P}{\to}\theta$
    (i.e. $\forall \epsilon > 0 \; P(|\tilde{\theta}-\theta|\ge\epsilon)\underset{n\to\infty}{\to}0$)
  \item сравнение оценок $\tilde{\theta}_1$ эффективнее $\tilde{\theta}_2$,
    если $\forall \theta \in \Theta \true D[\tilde{\theta}_1] \le D[\tilde{\theta}_2]$
    и $\exists \theta \in \Theta : \; D[\tilde{\theta}_1] < D[\tilde{\theta}_2]$
\end{enumerate}
\begin{theorem}[Достаточное условие состоятельности]
  Если $\tilde{\theta}$ является несмещённой оценкой $\theta$ и $D[\tilde{\theta}]\underset{n\to\infty}{\to}0$, 
  то $\tilde{\theta}$ является состоятельной оценкой ($\forall \theta \in \Theta$)
\end{theorem}
\begin{proof}
  $M[\tilde{\theta}]=\theta$, по неравенству Чебышёва:
  \[
    \forall \epsilon>0 \true P(|\tilde{\theta}-\underbrace{M[\tilde{\theta}]}_{\theta}| < \epsilon) \ge 1 - \frac{D[\tilde{\theta}]}{\epsilon^{2}} \underset{n\to\infty}{\to} 1
  \]
\end{proof}

\hr
\begin{problem}[Т1] Пытаемся понять по двум серийным номерам сколько всего танков.

  $\xi\sim R(0,\theta)$, $\theta >0$ вер. модель., $\vec{x}_n$ - выбрка объёмом $n$
  \begin{gather*}
    \tilde{\theta}_1=2\bar{x}=2\frac{1}{n}\sum_{i=1}^{n}x_i \\
    \tilde{\theta}_2= \min x_i \\
    \tilde{\theta}_3= \max x_i \\
    \tilde{\theta}_4= x_1 + \frac{1}{(n-1)}\sum_{i=2}^{n}x_i
  \end{gather*}
  \begin{gather*}
    M[\xi]=\int_{-\infty}^{\infty}xp(x)dx=\int_{0}^{\theta}\frac{x}{\theta}dx=\frac{\theta}{2} \\
    M[\xi^{2}]=\int_{-\infty}^{\infty}x^{2}p(x)dx=\int_{0}^{\theta}\frac{x^2}{\theta}dx=\frac{\theta^{2}}{3} \\
  \end{gather*}
  Рассматриваем $\tilde{\theta}_1$:

  Несмещённость $\forall \theta >0 M[\tilde\theta]=\theta$:

  $M[\frac{\theta}{n}\sum_{i=1}^{n}x_i]=\frac{2}{n}\sum_{i=1}^{n}M[x_i]=2M[\xi]=\theta$ несмещённая

  $D[\tilde\theta_1]=D[\frac{2}{n}\sum_{}^{}x_i]=\frac{1}{n^{2}}\sum_{}^{}D[x_i]=
  \frac{4}{n}D[\xi]=\frac{\theta^{2}}{3n}\underset{n\to\infty}{\to}0$,
  по достаточному условия оценка состоятельная

  Рассматриваем $\tilde{\theta}_2$:
  \begin{gather*}
    M[\tilde\theta_2]=\int_{-\infty}^{\infty}y\phi(y)dy \\ 
    \Phi(y)=1-(1-F(y))^{n} \qquad \phi(y)=n(1-F(y))^{n-1}p(y) \\
    M[\tilde\theta_2]=\int_{0}^{\theta}n(1-\frac{y}{\theta})^{n-1}\frac{1}{\theta}ydy =\\
    t = 1 - \frac{y}{\theta} \\ 
    = -\int_{1}^{0}nt^{n-1}(1-t)\theta dt=\int_{0}^{1}n\theta t^{n-1}dt - \int_{0}^{1}n\theta t^{n}dt= \\
    =n\theta[1-\frac{n}{n+1}]=\frac{\theta}{n+1}\quad \text{  смещённая} \\
    \tilde\theta_2'=(n+1)x_{min}=(n+1)\tilde\theta_2 \quad \text{несмещённая} \\
    M[\tilde\theta_2^{2}]=\int_{0}^{\theta}n(1-\frac{y}{\theta})^{n-1}\frac{1}{\theta}y^{2}dy =\\
    = -\int_{1}^{0}nt^{n-1}(1-t)^{2}\theta^{2} dt= \frac{2\theta^{2}}{(n+1)(n+2)} \\ 
    D[\tilde\theta_2]=\frac{2\theta^{2}}{(n+1)(n+2)}-\frac{\theta^{2}}{(n+1)^{2}}=
    \theta^{2}\left[\frac{2(n+1)-(n+2)}{(n+1)^{2}(n+2)}\right]= \\ 
    =\theta^{2}\left[\frac{n}{(n+1)^{2}(n+2)}\right] \underset{n\to\infty}{\to}0
    \quad \text{достаточное не выполнятеся} \\ 
    D[\tilde\theta_2']=(n+1)^{2}D[\tilde\theta_2]=\frac{\theta^{2}n}{n+2}\not\to 0
  \end{gather*}
  Смотрим состоятельность $\tilde\theta_2'$ по определению
  \[
    \forall \theta >0 \; \forall \epsilon>0 \true P(|\tilde\theta_2'-\theta|\ge\epsilon) \underset{n\to\infty}{\to} 0 
  \]
  \begin{gather*}
    P(|\tilde\theta_2'-\theta|\ge\epsilon) \ge  P(\tilde\theta_2' > \theta +\epsilon)= \\ 
    = P((n+1)x_{min}\ge \theta + \epsilon)=P(x_{min} \ge \frac{\theta+\epsilon}{n+1}) = \\ 
    = 1-P(x_{min}<\frac{\theta+\epsilon}{n+1})=1-(1-(1-F(\frac{\theta+\epsilon}{n+1}))^{n})= \\ 
    =(1-(\frac{\theta+\epsilon}{\theta(n+1)}))^{n}\underset{n\to\infty}{\to}e^{-\frac{\theta+\epsilon}{\theta}} >0
  \end{gather*}
  Не является состоятельной!

  Смотрим состоятельность $\tilde\theta_2$ по определению:
  \begin{gather*}
    P(\tilde\theta_2<\theta-\epsilon) + \underbrace{P(\tilde\theta_2>\theta+\epsilon)}_{=0, \text{т.к.} \tilde\theta_2=x_{min}} \\ 
    P(x_{min}<\theta-\epsilon=\Phi(\theta-\epsilon))=1-(1-\frac{\theta-\epsilon}{\theta})^{n}=
    1-\left(\frac{\epsilon}{\theta}\right)^{n} \underset{n\to\infty}{\to}1
  \end{gather*}
  Не является состоятельной!

  Рассматриваем $\tilde\theta_3=x_{max}$:
  \begin{gather*}
    M[\tilde\theta_3]=\int_{-\infty}^{+\infty}z\psi(z)dz=\int_{0}^{\theta}n\frac{z^{n}}{\theta^{n}}dz=\frac{n}{n+1}\theta \qquad \text{смешённая}\\
    \Psi(z)=(F(z))^{n} \qquad \psi(z)=n(F(z))^{n-1}p(z)=n\left(\frac{z}{\theta}\right)^{n-1}\frac{1}{\theta} \{(0;\theta)\} \\
    D[\tilde\theta_3]\frac{n}{n+2}\theta^{2}-\frac{n^{2}}{(n+1)^{2}}\theta^{2}=\frac{n\theta^{2}}{(n+2)(n+1)^{2}} \\ 
    D[\tilde\theta_3']\frac{(n+1)^{2}}{n^{2}}D[\tilde\theta_3]=\frac{\theta^{2}}{n(n+2)} \underset{n\to\infty}{\to} 0 \qquad \text{состоятельная} \\
  \end{gather*}
  Смотрим состоятельность $\tilde\theta_2'$ по определению
  \begin{gather*}
    \forall\theta>0 \; \forall \epsilon > 0 \\ 
    P(|\tilde\theta_2'-\theta|\ge\epsilon)=P(x_{max}<\theta-\epsilon) + \underbrace{P(x_{max}\ge\theta+\epsilon)}_{=0}= \\ 
    =(F(\theta-\epsilon))^{n}=\left\{\begin{aligned}
      & 0<\epsilon<\theta: \; \left(\frac{\theta-\epsilon}{\theta}\right)^{n}\underset{n\to\infty}{to} 0 \\ 
      & \epsilon \ge \theta: \; (0)^{n} \underset{n\to\infty}{\to} 0 
    \end{aligned}\right.
  \end{gather*}
  Является состоятельной!

  % lecture 3

  Рассматриваем $\tilde\Theta_4$:
  \begin{gather*}
    M[\tilde\theta_4]=M[x_1+\sum_{i=2}^{n}x_i]=
    M[x_1]+\frac{1}{n-1}\sum_{i=1}^{n}M[x_i] =\frac{\theta}{2}+\frac{\theta}{2}=\theta \\ 
    D[\tilde \theta_4]=D[\xi]+\frac{1}{(n-1)^{2}}(n-1)D[\xi]=\frac{\theta^{2}}{12}\frac{n}{n-1} \underset{n\to\infty}{\not \to} 0
  \end{gather*}
  Достаточое усл. не работает.

  Используем теорему $\xi_n \overset{p}{\to} \xi$, $\eta_n \overset{p}{\to}\eta$, $\xi_n+\eta_n \overset{p}{\to}\xi+\eta$.

  И ЗБЧ Хинчина: $\xi_1,\dots ,\xi_n$ незав., одинак распр. $\implies$ $\frac{1}{n}\sum_{i=1}^{n}\xi_i \overset{p}{\to} M[\xi]$.
  \begin{gather*}
    x_1 \overset{p}{\to} x_1 \qquad \frac{1}{n-1}\sum_{i=2}^{n}x_i \overset{p}{\to} \frac{\theta}{2} \\ 
    \tilde \theta_4 \overset{p}{\to} x_1 + \frac{\theta}{2}
  \end{gather*}
  Не состоятельна!
 
  Адекватные остались $\tilde\theta_1=2 \bar x$, $\tilde\theta_3'=\frac{n+1}{n}x_{max}$
  \[
    D[\tilde\theta_1]=\frac{\theta^{2}}{3n} > D[\tilde{\theta}_3']=\frac{\theta^{2}}{n(n+2)}
  \]
  Лучшая оценка $\tilde{\theta}_3$.
\end{problem}
\hr

\section{Оптимальность и эффективность оценок}
\begin{definition}
  Несмещённая оценка $\tilde{\theta}(\vec{x}_n)$ характеристики $\theta$ называется
  оптимальной $\tilde{\theta}_{opt}$ если для $\forall \theta \in \Theta$ $\implies$
  $D[\tilde{\theta}_{opt}]=\inf D[\tilde{\theta}]$,
  $\inf$ по всем несмещённым оценкам $\theta$.
\end{definition}
\begin{theorem}[Единственность оптимальной оценки]
  Если оптимальная оценка существует, то она единственна.
\end{theorem}
\begin{proof}
  Пусть $\tilde{\theta}_1$ и $\tilde{\theta}_2$ разные оптимальные оценки
  \begin{gather*}
    \tilde{\theta}_3=\frac{\tilde{\theta}_{1}+\tilde{\theta}_{2}}{2} \qquad M[\tilde{\theta}_{3}]=\theta \\
    D[\tilde{\theta}_{3}]=\frac{1}{4}D[\tilde{\theta}_{1}]+D[\tilde{\theta}_{2}]+\frac{1}{2}cov(\tilde{\theta}_{1},\tilde{\theta}_{2})=
    \frac{1}{2}D[\tilde{\theta}_{1}]+\frac{1}{2}cos(\tilde{\theta}_{1},\tilde{\theta}_{2}) \\ 
    D[a\xi+b\eta]=a^{2}D[\xi]+b^{2}D[\eta]+2abcov(\xi,\eta) \\ 
    |cov(\tilde{\theta}_{1},\tilde{\theta}_{2})|\le \sqrt{D \tilde{\theta}_{1} D \tilde{\theta}_{2}}=D[\tilde{\theta}_{1}] \\
    D[\tilde{\theta}_{3}]\le D[\tilde{\theta}_{1}] \qquad D[\tilde{\theta}_{3}]=D[\tilde{\theta}_{1}] \\ 
    cov(\tilde{\theta}_{1},\tilde{\theta}_{2})=D[\tilde{\theta}_{1}] \quad \implies \quad r=1 \iff \tilde{\theta}_{1}=a \tilde{\theta}_{2}+b \\ 
    M[\tilde{\theta}_{1}]=M[\tilde{\theta}_{2}]=\theta \qquad D[\tilde{\theta}_{1}]=D[\tilde{\theta}_{2}] \\ 
    \left\{\begin{aligned}
      & \theta=a\theta+b \\ 
      & a^{2}D[\tilde{\theta}_{2}]=D[\tilde{\theta}_{2}]
    \end{aligned}\right. \implies 
    \left\{\begin{aligned}
      & a = 1 \\ 
      & b=0
    \end{aligned}\right. \\
    \implies \tilde{\theta}_{1}=\tilde{\theta}_{2}
  \end{gather*}
  Противоречие.
\end{proof}
Будем рассматриватть параметрические вероятностные модели:
\begin{gather*}
  \xi \sim \rho(x,\theta) , \, \theta\in\Theta\subset \R, \,x\in A(\theta)\\
  \xi \sim \rho(x, \vec{\theta}) , \, \vec{\theta}\in\Theta\subset \R^{m}, \,x\in A(\vec{\theta})\\ 
  \rho(x,\theta)=\underbrace{p(x,\theta)\{E\}}_{\text{непр. часть}} + \underbrace{\sum_{k}^{}p_k(\theta)\{x_k\}}_{\text{дискр. часть}}
\end{gather*}

\incfig{l3_rho}
\subsection{Информация Фишера}
\begin{gather*}
  I(\theta)=M\left[(\frac{\partial \ln \rho(x,\theta)}{\partial\theta})^{2}\right]= \\ 
  = \int_{E}^{}\left(\frac{\partial \ln p(x,\theta)}{\partial\theta}\right)^{2}p(x,\theta)dx+\sum_{k}^{}\left(\frac{\partial \ln p_k(x,\theta)}{\partial\theta}\right)^{2}p_k(\theta)
\end{gather*}
$I(\vec{\theta})$ - информационная матрица Фишера
\[
  I_{ij}(\vec{\theta})=M\left[\frac{\partial \ln p(x,\theta)}{\partial\theta_i}\frac{\partial \ln p(x,\theta)}{\partial\theta_j}\right]
\]
\begin{definition}
  Вероятностьная модель $\xi\sim \zeta(x,\theta)$, $\theta\in\Theta\subset \R$, $x\in A$
  называется регулярной, если
  \begin{enumerate}
    \item $\rho(x,\theta)$ непр дифф по $\theta$ на $\Theta$
    \item $\frac{\partial}{\partial\theta}\int_{A}^{}\rho(x,\theta)dx=\int_{A}^{}\frac{\partial}{\partial\theta}\rho(x,\theta)dx$ на $\Theta$
    \item $I(\theta)$ непр на $\Theta$ и $I(\theta)>0$ на $\Theta$
  \end{enumerate}
\end{definition}
\begin{definition}
  Вероятностьная модель $\xi\sim \zeta(x,\vec{\theta})$, $\vec{\theta}\in\Theta\subset \R^{m}$, $x\in A$
  называется регулярной, если
  \begin{enumerate}
    \item $\rho(x,\vec{\theta})$ непр дифф по $\vec{\theta}$ на $\Theta$
    \item $\frac{\partial}{\partial\theta_i}\int_{A}^{}\rho(x,\vec{\theta})dx=\int_{A}^{}\frac{\partial}{\partial\theta_i}\rho(x,\vec{\theta})dx$ на $\Theta$, $i=1,\dots ,m$
    \item $I(\vec{\theta})$ положительно определена на $\Theta$ и $I_{ij}(\vec{\theta})$ непрер. на $\Theta$
  \end{enumerate}
\end{definition}
\begin{definition}
  Вероятностная модель $\xi\sim\rho(x,\theta)$,  $\vec{\theta}\in\Theta\subset \R^{m}$, $x\in A$
  называется сильно регулярной, если эта модель регулярна и
  \begin{enumerate}
    \item $\rho(x,\theta)$ $k$ раз непрерывно дифф по $\theta$ на $\Theta$ ($k\ge 2$)
    \item $\frac{\partial^{l}}{\partial\theta^{l}}\int_{A}^{}\rho(x,\theta)dx=\int_{A}^{}\frac{\partial^{l}}{\partial\theta^{l}}\rho(x,\theta)dx$, $l=1,\dots ,k$
  \end{enumerate}
\end{definition}
\begin{definition}
  Вероятностная модель $\xi\sim \zeta(x,\vec{\theta})$, $\vec{\theta}\in\Theta\subset \R^{m}$, $x\in A$
  называется сильно регулярной, если эта модель регулярна и
  \begin{enumerate}
    \item $\rho(x,\vec{\theta})$ $k$ раз непрерывно дифф по $\theta$ на $\Theta$ ($k\ge 2$)
    \item все производные по $\vec{\theta}$ перестановочные с $\int_{}^{}$ по $x$
  \end{enumerate}
\end{definition}

\begin{definition}
  Статистика $\tilde{g}(\vec{x}_n)$ называется регулярной оценкой функции $g(\theta)$,
  если она является несмещённой оценкой и 
  \begin{gather*}
    \frac{\partial}{\partial\theta}\int_{B}^{}\tilde{g}(\vec{x}_n)L(\vec{x}_n,\theta)d\vec{x}_n=
    \int_{B}^{}\tilde{g}(\vec{x}_n)\frac{\partial}{\partial \theta}L(\vec{x}_n,\theta)d\vec{x}_n
  \end{gather*}
  где $L(\vec{x}_n,\theta)$ - плотность распределения случайного вектора $\vec{x}_n$ \\ 
  ($L(\vec{x}_n,\theta)=\prod_{i=1}^{n}\rho(x_i,\theta)$), $B=\underbrace{A\times A\times\dots \times A}_{n}$
\end{definition}
\begin{theorem}[Достаточное условие регулярности оценки]
  Если модель регулярна, $\tilde{g}(\vec{x}_n)$ является несмещ. оценкой $g(\theta)$
  и $D[\tilde{g}(\vec{x}_n)]$ ограничена на $\forall$ компакте из $\Theta$ по $\theta$,
  тогда оценка регулярна.
\end{theorem}

% lecture 5


\subsection{Неравенство Крамера-Рао}
\begin{theorem}
Пусть модель является регулярной, $\tilde{g}(\vec{x}_n)$
является регулярной оценкой оценкой дифф функции $g(\theta)$.
Тогда
\[
  \forall \theta \in \Theta \true D[\tilde{g}]\ge \frac{(g')^{2}(\theta)}{nI(\theta)}
\]
\end{theorem}
\begin{proof}
  $\xi \sim \rho(x,\theta)$, $\theta\in\Theta\subset \R$, $x\in A(\theta)$,
  $\vec{x}_n$ независ. выборка

  $L(\vec{x}_n,\theta)=\prod_{i=1}^{n}\rho(x_i,\theta)$ - распр. выборки $\vec{x}_n$,
  $B=A\times\dots \times A$
  \[
    \frac{\partial}{\partial\theta}\idotsint \limits_{B} L(\vec{x},\theta)d\vec{x}=\frac{\partial}{\partial\theta}1=0
  \]
  в силу регулярности модели
  \[
    \idotsint \limits_{B}\frac{\partial}{\partial\theta}Ld\vec{x}=0 \\ 
  \]
  Домножаем и делим на $L$, там где $L=0$ считаем что интеграл $0$
  \begin{gather*}
    \int_{B}^{}\frac{\partial\ln L}{\partial \theta}Ld\vec{x}=0 \\ 
    M[\tilde{g}]=g(\theta) \\ 
    \int_{B}^{}\tilde{g}(\vec{x}_n)L(\vec{x}_n,\theta)d\vec{x}_n=g(\theta) \\
    \frac{\partial}{\partial \theta}\int_{B}^{}\tilde{g}(\vec{x}_n)L(\vec{x}_n,\theta)d\vec{x}_n=\frac{\partial}{\partial \theta}g(\theta) \\ 
    \int_{B}^{}\tilde{g}(\vec{x}_n)\frac{\partial}{\partial \theta}Ld\vec{x}_n=g'(\theta) \\ 
    \int_{B}^{}\tilde{g}(\vec{x}_n)\frac{\partial \ln L}{\partial \theta}Ld\vec{x}_n=g'(\theta) \\ 
    \int_{B}^{}(\tilde{g}(\vec{x}_n)-g(\theta))\frac{\partial \ln L}{\partial \theta}Ld\vec{x}_n=g'(\theta) \\ 
  \end{gather*}
  $\eta=\tilde{g}(\vec{x}_n)-g(\theta)$ - сл. вел

  $\zeta=\frac{\partial \ln L(\vec{x}_n,\theta)}{\partial \theta}$ - сл. вел.
  \begin{gather*}
    M[\eta]=0 \qquad M[\zeta]=0 \\
    M[\eta\zeta]=g'(\theta) \\ 
    cov(\eta,\zeta)=M[\eta\zeta]-M[\eta]M[\zeta]=g'(\theta) \\ 
    r=\frac{cov(\eta,\zeta)}{\sqrt{D\eta D\zeta}} \qquad |r|\le 1 \\ 
    \frac{cov^{2}(\zeta,\eta)}{D\zeta D\eta} \le 1 \\ 
    g'^{2}(\theta) \le D\zeta \underbrace{D[\tilde{g}]}_{D[\tilde{g}]} \\ 
    D\zeta=M[\zeta^{2}]-M^{2}[\zeta]=M[\zeta^{2}] \\ 
    D\zeta=D\left[\frac{\partial\ln L}{\partial\theta}\right] 
    =D\left[\sum_{i=1}^{n}\frac{\partial\ln \rho(x_i,\theta)}{\partial\theta}\right]
    =\sum_{i=1}^{n}D\left[\frac{\partial\ln \rho(x_i,\theta)}{\partial\theta}\right]= \\
    =nD\left[\frac{\partial\ln \rho(x_i,\theta)}{\partial\theta}\right]
    =nM\left[\left(\frac{\partial \ln \rho}{\partial\theta}\right)^{2}\right] - n\underbrace{M^{2}\left[\frac{\partial \ln \rho}{\partial \theta}\right]}_{0}=nI(\theta)
  \end{gather*}
\end{proof}
\begin{corollary}
  \phantom{.}

  \begin{enumerate}
    \item оценка параметра $\theta$, $g(t)=\theta$,
      \[
        D[\tilde{\theta}]\ge\frac{1}{nI(\theta)}
      \]
    \item многомерный аналог нер. Крамера-Рао
      \[
        D[\tilde{g}(\vec{x}_n)]\ge \frac{1}{n}\nabla^{T}g(\vec{\theta})I^{-1}(\vec{\theta})\nabla g(\vec{\theta})
      \]
  \end{enumerate}
\end{corollary}

\begin{definition}[Эффективная оценка]
  Регулярная оценка $\tilde{g}(\vec{x}_n)$ функции $g(\theta)$ называется 
  эффективной ($\tilde{g}_{eff}$), если 
  $\forall \theta\in\Theta \true D[\tilde{g}_{ef f}]=\inf D[\tilde{g}]$,
  $\inf$ берётся по всем регулярным оценкам.
\end{definition}
\begin{theorem}
  Если эффективная оценка $\exists$,
  то она единственна.
\end{theorem}
\begin{proof}
  Так же как и оптимальная только нужно доказать что
  $\tilde{\theta}_{3}=\frac{\tilde{\theta}_{1}+\tilde{\theta}_{2}}{2}$ - регулярная.
\end{proof}
\begin{theorem}[Достаточное условие эффективности]
  Пусть выполнены условия нер. Крамера-Рао и
  $D[\tilde{g}]=\frac{g'^{2}}{nI(\theta)}$, тогда
  $\tilde{g}$ эффективная оценка $g(\theta)$.
\end{theorem}
\begin{theorem}[Теорема о частоте]
  Частота появления события $A$ в $n$ независимых опытах является несмещённой,
  состоятельной и эффективной оценкой вероятности появления этого события.
\end{theorem}
\begin{proof} (на примере)
  \begin{gather*}
    \xi \sim \rho(x,\theta)=\theta\{1\} + (1-\theta)\{0\} \qquad \theta \in (0,1) \\ 
    \xi \sim Bi(1,\theta) \qquad \nu=\frac{m}{n} \\ 
    \vec{x}_n=(0,0,1,\dots ) \qquad \nu=\frac{1}{n}\sum_{}^{}x_i=\bar{x} \qquad \tilde{\theta}=\bar{x} \\ 
  \end{gather*}
  \begin{enumerate}
    \item несмещённость ($\xi\sim Bi(l,\theta)$, $M[\xi]=l\theta$, $D[\xi]=l\theta(1-\theta)$)
      \[
        M[\bar{x}]=\frac{1}{n}M[\sum_{}^{}x_i]=M[\xi]
      \]
    \item состоятельность 
      \[
        D[\tilde{\theta}]=D[\frac{1}{n}\sum_{}^{}x_i]=\frac{1}{n^{2}}nD[\xi]=\frac{1}{n}\theta(1-\theta) \underset{n\to\infty}{\to}0
      \]
      состоятельна по достаточному условию
    \item эффективность, модель регулярна
      \[
        I(\theta)=\frac{l}{\theta(1-\theta)}\Big|_{l=1}=\frac{1}{\theta(1-\theta)}
      \]
      $\tilde{\theta}=\bar{x}$ - регулярная оценка?

      $D[\tilde{\theta}]=\frac{1}{n}\theta(1-\theta)$ огран на $\forall$ компакте из $(0,1)$

      Является регулярной $\checkmark$

      Неравенство Крамера-Рао:
      \[
        D[\tilde{\theta}]=\frac{1}{n}\theta(1-\theta) \ge \frac{1}{nI(\theta)}=\frac{\theta(1-\theta)}{n}
      \]
      достигает нижней грани $\implies$ эффективная (в данном случае ещё и оптимальная)
  \end{enumerate}
\end{proof}

\section{Описательная стат. (непараметр. стат.)}
$\vec{x}_n$ - выборка

Вероятностная модель - все распределения, кроме сингулярных и вырожденных.
\begin{enumerate}
  \item Вариационный ряд - упорядоченная ваборка
    \[
      x_{min}=x_{(1)}\le x_{(2)}\le x_{(3)} \le \dots \le x_{(n)}=x_{max}
    \]
    $x_{(k)}$ - k-ая порядковая сл. вел
  \item Размах выборки $l=x_{max}-x_{min}$
  \item Медиана выборки $med$
    \[
      mes =\left\{\begin{aligned}
        & x_{(k+1)}, \mu n=2k+1 \\ 
        & \frac{x_{(k+1)}+x_{(k)}}{2}, \; n=2k
      \end{aligned}\right.
    \]
  \item Мода - эл. выборки, который встречается чаще всего
  \item Квартили $q_1$, $q_2$ (медианы половинок)
  \item Boxplot

    \incfig{l5_boxplot}
    $\epsilon=q_2-q_1$, если $x_{min}<q_1-1.5\epsilon$ или $x_{max}>q_2+1.5\epsilon$
    рисуем усики до $q_1-1.5\epsilon$ или $q_2+1.5\epsilon$ соответственно,
    а дальше выбросы обозначаем точками для каждого значения
  \item эмпирическая функция распределения
    \[
      \tilde{F}(x)=\frac{m(x)}{n}
    \]
    где $m(x)$ число элементов выборки, которые $<x$.
    \begin{gather*}
      F(x)=P(\underbrace{\xi<x}_{A})
    \end{gather*}
    $\tilde{F}$ является несмещённой, состоятельной и эффективной оценкой $F(x)$
    (по Т. о частоте).
  \item Гистограмма

    Статистический ряд
    \[
      \underbrace{[y_1,y_2)}_{\nu_1=\frac{m_1}{n}}, \underbrace{[y_2,y_3)}_{\nu_2}\dots \underbrace{[y_k,y_{k+1})}_{\nu_k}
    \]
    Эмперически $k=1+\log_2 n$
    
    \incfig{l5_histo}
    
    $\nu_m=P(y_m \le \xi < y_{m+1})=\int_{y_m}^{y_{m+1}}p(x)dx=p(\bar{x})\Delta_m$
  \item числовые характеристики

    $\alpha_k=M[\xi^{k}]$ момент к-го порядка
    \[
      \tilde{\alpha}_k=\frac{1}{n}\sum_{i=1}^{n}x_i^{k} \qquad \tilde{\alpha}_1=\bar{x} \\ 
    \]
    \hr
    \begin{itemize}
      \item несмещ: $M[\alpha_k]=\frac{1}{n}M[\sum_{}^{}x_i^{k}]=M[\xi^{k}]=\alpha_k$
      \item состоятельность: ЗБЧ Хинчина $\tilde{\alpha}_k \overset{p}{\to}\alpha_k=M[\xi^{k}]$
    \end{itemize}
    \hr

    $\mu_k=M[(\xi-M\xi)^{K}]$ - центральный момент k-го порядка
    \[
      \tilde{\mu}_k=\frac{1}{n}\sum_{i=1}^{n}(x_i-\bar{x})^{k} \\ 
    \]
    \hr
    \begin{itemize}
      \item состоятельность
        \begin{gather*}
           \mu_k=M[\sum_{m=0}^{k}C_k^{m}\xi^{m}(-1)^{k-m}(M\xi)^{k-m}]= \\
           = \sum_{m=0}^{k}C_k^{m}(-1)^{k-m}\alpha_m (\alpha_1)^{k-m} \\ 
           \tilde{\mu}_k=\sum_{m=0}^{k}C_k^{m}(-1)^{k-m}\tilde{\alpha}_m (\tilde{\alpha}_1)^{k-m} 
        \end{gather*}

        Теорема наследования сходимости:

        $\xi_n \overset{p}{\to} \xi$, $f(x)$ непр на $\R$ $\implies f(\xi_n) \overset{p}{\to} f(\xi)$

        $\xi_n \overset{p}{\to} C$, $f(x)$ непр в точке $x=C$ $\implies f(\xi_n) \overset{p}{\to} f(C)$

        $\tilde{\alpha}_k \overset{p}{\to} \alpha_k$, $f(x_1,\dots ,x_n)$ непр $\implies$
        $\tilde{\mu}_k \overset{p}{\to} \mu_k$ 
      \item несмещённость 
        \begin{gather*}
          \mu_2=D\xi \qquad \tilde{\mu}_2=\tilde{\alpha}_2 - (\tilde{\alpha})^{2} \\ 
          M[\tilde{\mu}_2]
          =M\left[\frac{1}{n}\sum_{}^{}x_i^{2}\right]-M\left[(\frac{1}{n}\sum_{}^{}x_i)^{2}\right] = \\
          = M\xi^{2}-(D[\bar{x}]+(M[\bar{x}])^{2})
          = M\xi^{2}-\frac{1}{n^{2}}nD\xi - (M\xi)^{2}= \\
          = D\xi \left[1-\frac{1}{n}\right]=\mu_2\frac{n-1}{n}
        \end{gather*}
        $S^{2}=\frac{n}{n-1}\tilde{\mu}_2$, $M[S^{2}]=\mu_2$ несмещ оценка дисперсии
        \[
          S^{2}=\frac{1}{n-1}\sum_{i=1}^{n}(x_i-\bar{x})^{2}
        \]
    \end{itemize}
    \hr
    коэффициент асимметрии
    \begin{gather*}
      \gamma=\frac{\mu_3}{\sigma^{3}}=\frac{\mu_3}{\mu_2^{3/2}} \\ 
      \tilde{\gamma}=\frac{\tilde{\mu}_3}{\tilde{\mu}_2^{3/2}} \overset{p}{\to}\gamma
    \end{gather*}
  \item оценка распределения статистики
    \[
      \vec{x}_n \qquad \tilde{g}(\vec{x}_n)
    \]
    $\vec{x}_n$ становится вероятностной моделью,
    вытаскиваем 1000 подвыбоок с повторением элементов того же объёма $\vec{x}_n^{*}$,
    $\vec{x}_n^{*} \rightarrow \tilde{g}_i^{*}(\vec{x}_n^{*})$,
    строим гистограмму из $\tilde{g}_1^{*}\dots \tilde{g}_{10 0 0}^{*}$
\end{enumerate}

\section{Методы нахожд. параметров модели}
\[
  \xi\sim \rho(x,\vec{\theta}), \ \vec{\theta}\in\Theta \subset \R^{m}, \ x\in A
\]
Парметрическая модель, $\vec{x}_n$ выборка
\begin{enumerate}
  \item Метод моментов (Пирсон)
    \[
      \alpha_k(\vec{\theta})=M[\xi^{k}] \rightarrow \tilde{\alpha}_k=\alpha_k(\vec{\theta})
    \]
    Если можем решить систему получаем $\tilde{\vec{\theta}}$ оценку методом моментов (ОММ)
\end{enumerate}

\end{document}
