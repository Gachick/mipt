\documentclass{article}


\input{~/mipt/preamble}

\begin{document}

\section{Занятие 1}

\subsection{Основные распределения в Мат Стат}
\subsubsection{Гамма распределение}
\begin{gather*}
  \xi \sim \Gamma(\lambda,a) \; \lambda>0,a>0 \\
  P(x)=\frac{\lambda^{a}}{\Gamma(a)}x^{a-1}e^{-\lambda x} \; \{(0,+\infty)\}
\end{gather*}

\incfig{l1_g_distr}
\begin{gather*}
  \Gamma(S+1)=S \Gamma(S) \qquad \Gamma(S)= \int_{0}^{\infty}x^{s-1}e^{-x}dx \; x>0 \\
  M[ \Gamma]=\int_{-\infty}^{\infty} \rho(x)dx= \int_{0}^{\infty}\frac{\lambda^{a}}{ \Gamma(a)}(\frac{t}{\lambda})^{a}e^{-t}\frac{dt}{\lambda}=
  =\frac{1}{\lambda \Gamma(a)}\int_{0}^{\infty}t^{a}e^{-t}dt=\frac{a}{\lambda} \\
  D[\xi]=M[\xi^{2}]-M^{2}[\xi]=\frac{a^2+a}{\lambda^2}-(\frac{a}{\lambda})^2=\frac{a}{\lambda^2} \\
\end{gather*}
\begin{theorem}[Свойство суммы]
$\xi_1,\dots,\xi_n$ независимы, $\xi_i \sim \Gamma(\lambda,a_i)$, $\eta=\xi_1+\dots+\xi_n \sim \Gamma(\lambda,a_1+\dots+a_n)$
\end{theorem}
\begin{proof}
$\xi_1 \sim \Gamma(\lambda,a_1)$. $\xi_2 \sim \Gamma(\lambda,a_2)$ - независимые, $\eta=\xi_1+\xi_2$
\begin{gather*}
\Phi(y)=P(\eta < y)=P(\xi_2+\xi_2<y)=\iint_{x_1+x_2<y}p(x_1,x_2)dx_1dx_2= \\
=\int_{0}^{y}dx_2\int_{0}^{y-x_1}\frac{\lambda^{a_1}}{\Gamma(a_1)x_1^{a_1-1}e^{-\lambda x_1}}\frac{\lambda^{a_2}}{\Gamma(a_2)x_2^{a_2-2}e^{-\lambda x_2}}dx_2 \\
  \phi(y)=\Phi'(y)
\end{gather*}
\end{proof}

\subsubsection[Распределение Пирсона]{Распределение Пирсона $\chi^2$}
$\xi_i\sim N(0,1)$ - независимы, $\eta=\xi_1^2+\dots+\xi_n^2=\chi^2$
\begin{gather*}
  \Phi(y)=P(\xi^2<y)=\left\{\begin{aligned}
    & y\le0 \quad :0 \\
    & y > 0 \quad :P(-\sqrt{y}<\xi<\sqrt{y})
  \end{aligned}\right. \\
  \phi(x)=   \left\{\begin{aligned}
      & \frac{1}{2\sqrt{y}}F'(\sqrt{y})+\frac{1}{2\sqrt{y}}F'(-\sqrt{y}), \; y> 0 \\
      & 0, \; y<0
    \end{aligned}\right. \\
  p(x)=\frac{e^{x^2/2}}{\sqrt{2\pi}} \\
  \phi(y)=\left\{\begin{aligned}
    & \frac{1}{\sqrt{y}}\frac{e^{-y/2}}{\sqrt{2\pi}}, \; y>0  \\
    & 0, \; y\le 0
  \end{aligned}\right. \\
  p(x)=\frac{\lambda^{a}}{\Gamma(a)}x^{a-1}e^{-\lambda x}\{(0;+\infty)\} \qquad \lambda=\frac{1}{2} \qquad a=\frac{1}{2} \\
  \xi^{2}\sim \Gamma(\frac{1}{2}, \frac{1}{2}) \qquad \xi_1^{2}+\dots+\xi_n^{2} \sim \Gamma(\frac{1}{2}, \frac{n}{2})=\chi^{2}(n)
\end{gather*}
$n$ - число степеней свободы
\begin{gather*}
  M[\eta]=\frac{a}{\lambda}=\frac{n/2}{1/2}=n \\
  D[\eta]=\frac{a}{\lambda^{2}}=\frac{n/2}{1/4}=2n
\end{gather*}

\begin{theorem}[Свойство суммы]
  $\xi_1,\dots,\xi_m$ - независ, $\xi_i\sim \chi^{2}(n_i)$, $\xi_1+\dots+\xi_n\sim \chi^2(n_1+\dots+n_m)$
\end{theorem}

\subsection{Распределение Стьюдента (Госсет)}
$\xi \sim N(0,1)$, $\eta \sim \chi^2(m)$ - независимы, $\frac{\xi}{\sqrt{\eta/m}}\sim t(m)$

\incfig{l1_st_distr}
\[
  p(x)=\frac{(m)^{m/2}\Gamma(\frac{m+1}{2})}{\sqrt{\pi}\Gamma(\frac{m}{2})(x^2+m)^{\frac{m+1}{2}}}
\]

\subsection{Распределение Фишера}
$\xi\sim \chi^2(n)$, $\eta\sim \chi^2(m)$ - независимые, $\frac{\xi/n}{\eta/m}\sim F(n,m)$

\incfig{l1_fi_distr}
\subsection{Нормальное распределение}
\begin{gather*}
  p(\vec{x})=\frac{1}{(\sqrt{2\pi})^n}\frac{1}{\sqrt{detK}}e^{-\frac{1}{2}(\vec{x}-\vec{a})^T K^{-1}(\vec{x}-\vec{a})} \\
  \vec{\xi}\sim N(\vec{a},R)\\
\end{gather*}
Свойства:
\begin{itemize}
  \item $\xi\sim N(0,1)$, $\eta=a\xi+b \sim N(b,a^2)$
  \item $\xi\sim N(\alpha, \sigma^2)$, $\eta=a\xi+b\sim N(a\alpha+b, \sigma^2a^2)$
  \item $\xi\sim N(\vec{0},E)$,$\vec{\eta}=A\vec{\xi}+\vec{b}$, $A:n\times n,detA\neq 0$
      
    \begin{gather*}
      \Phi(t_1,\dots,t_n)=P(\eta_1<t_1,\dots,\eta_n<t_n)=P(\vec{\eta}<\vec{t})=P(A\vec{\xi}+\vec{b}<\vec{t})= \\
    = \int\dots\int_{A\vec{x}+\vec{b}<\vec{t}}p(x_1,\dots,x_n)dx_1\dots dx_n= \\
      \vec{y}=A\vec{x}+\vec{b} \qquad J=\left|\frac{\partial \vec{x}}{\partial \vec{y}}\right| \qquad \frac{1}{J}=detA \\
    =\idotsint_{\vec{y}<\vec{t}}p(A^{-1}(\vec{y}-\vec{b}))\frac{1}{|detA|}dy_1\dots dy_n \\
    \phi(\vec{t})=p(A^{-1}(\vec{y}-\vec{b}))\frac{1}{|detA|} \\
    \phi(\vec{t})=\frac{1}{|detA|}\frac{1}{(\sqrt{2\pi})^n}e^{-\frac{1}{2}(A^{-1}(\vec{y}-\vec{b})^T) (A^{-1}(\vec{y}-\vec{b}))}= \\
  =\frac{1}{|detA|}\frac{1}{(\sqrt{2\pi})^n}e^{-\frac{1}{2}(\vec{t}-\vec{b})^T (A^T)^{-1} A^{-1}(\vec{t}-\vec{b})} \\
  K=AA^T \qquad \vec{\eta}=A\vec{\xi}+\vec{b}\sim N(\vec{b}, AA^T) \\
    \end{gather*}
\item $\xi\sim N(\vec{a},K)$, $\vec{\eta}=A\vec{\xi}+\vec{b}\sim N(A\vec{a}+\vec{b},AKA^{T})$, $A:n\times n$, $detA\neq 0$
\item Для $A:m\times n$ два предыдущих свойства так же верны
\item $\xi,\eta$ - независ $\implies$ $cov(\xi,\eta)=0$, в другую сторону не верно
\[
  \left\{\begin{aligned}
    \xi \sim N(a_1, \sigma_1^2) \\ 
    \eta \sim N(a_2, \sigma_2^2) \\ 
    \text{независимые}
  \end{aligned}\right.
  \Leftrightarrow
  (\xi,\eta)\sim N\left(\begin{pmatrix}
    a_1 \\ a_2
  \end{pmatrix}\begin{pmatrix}
  \sigma_1^{2} & 0 \\ 
  0 & \sigma_2^{2}
\end{pmatrix}\right)
\]
\[
  \left\{\begin{aligned}
    \xi \sim N(a_1, \sigma_1^2) \\ 
    \eta \sim N(a_2, \sigma_2^2) \\ 
    cov(\xi,\eta)=0
  \end{aligned}\right.
  \Leftarrow
  (\xi,\eta)\sim N\left(\begin{pmatrix}
    a_1 \\ a_2
  \end{pmatrix}\begin{pmatrix}
  \sigma_1^{2} & 0 \\ 
  0 & \sigma_2^{2} 
\end{pmatrix}\right)
\]
\end{itemize}
\begin{lemma}[Лемма Фишера]
Пусть $\vec{\xi}\sim N(\vec{0},E)$ и $C$ ортогональная матрица,
$\vec{\eta}=C\vec{\xi}$, тогда $\forall k=1\dots n-1$ сл. вел. 
$\kappa=\sum_{i=1}^{n}\xi_{i}^{2}-\eta_{1}^{2}-\eta_{2}^{2}-\dots -\eta_{k}^{2}\sim \chi^{2}(n-k) $
и вел $\kappa,\eta_1,\eta_2,\dots ,\eta_k$ независ.
\end{lemma}
\begin{proof}
  \begin{gather*}
    \vec{\eta}\sim N(\vec{0},\underbrace{CC^{T}}_{E}) \\ 
    \eta_1^{2}+\dots +\eta_n^{2}=\vec{\eta}^{T}\vec{\eta}=\vec{\xi}^{T}C^{T}C\vec{\xi}=\xi_1^{2}+\dots +\xi_{n}^{2} \\ 
    \kappa= \eta_{k-1}^{2}+\dots+\eta_{n}^{2} \\ 
    \kappa=\chi^{2}(n-k)
  \end{gather*}
\end{proof}

\begin{theorem}[Фишера]
  Пусть $\xi_1,\dots ,\xi_n$ независ и $\xi_i\sim N(a,\sigma^{2})$, тогда:
  \begin{enumerate}
    \item $\phi=\sqrt{n}\frac{\bar{\xi}-a}{\sigma}\sim N(0,1)$,
      $\bar{\xi}=\frac{1}{n}\sum_{1}^{n}\xi_i$
    \item $\psi=\sum_{i=1}^{n}\frac{(\xi_i-\bar{\xi})^2}{\sigma^{2}}\sim \chi^{2}(n-1)$
    \item $\phi$ и $\psi$ независ.
  \end{enumerate}
\end{theorem}
\begin{proof}
  \begin{gather*}
    \phi=\frac{1}{\sqrt{n}}\frac{\sum_{}^{n}\xi_i-na}{\sigma}=\frac{1}{\sqrt{n}}\sum_{}^{n}\left(\frac{\xi_i-a}{\sigma}\right) \\ 
    \frac{\xi_i-a}{\sigma}=\frac{1}{\sigma}\xi_i-\frac{a}{\sigma} \sim N(\frac{a}{\sigma}-\frac{a}{\sigma}, \sigma^{2}\frac{1}{\sigma^{2}})=N(0,1) \\ 
  \phi = \frac{1}{\sqrt{n}}\sum_{}^{n}\eta_i=(\frac{1}{\sqrt{n}}\dots \frac{1}{\sqrt{n}})\vec{\eta}\sim N(\vec{0}, AA^{T})=N(0,1)
  \end{gather*}
  1) Доказан 
  \begin{gather*}
    \psi = \sum_{}^{n}\left(\underbrace{\frac{\xi_i-a}{\sigma}}_{\eta_i\sim N(0,1)}-\underbrace{\frac{\bar{\xi}-a}{\sigma}}_{\bar{\eta}}\right)^{2}=
    \sum_{}^{n}(\eta_i-\bar{\eta})^{2}=\sum_{}^{n}(\eta_i^2-2\eta_i \bar{\eta}+(\bar{\eta})^2)= \\
    = \sum_{}^{n}\eta_i^{2}-2\bar{\eta}\sum_{}^{n}\eta_i+n(\bar{\eta})^{2}=\sum_{}^{n}\eta_i^{2}-n(\bar{\eta})^{2} \\ 
    \eta_i\sim N(0,1) \qquad \zeta^{2}=n\bar{\eta}^{2} \qquad \zeta=\sqrt{n}\bar{\eta}=\frac{1}{\sqrt{n}}\sum_{}^{n}\eta_i=A\vec{\eta}=\phi
  \end{gather*}
  $A=\left(\frac{1}{\sqrt{n}}\dots \frac{1}{\sqrt{n}}\right)$ $\implies$ $C$ - ортог. матрица (Грамма-Шмидта)
  
  ($A$ получается строчкой матрицы $C$ и тогда $\zeta$ - одна из координат в другом базисе и применима Лемма Фишера)

  По лемме Фишера $\psi\sim \chi^{2}(n-1)$, $\psi$ и $A\bar{\eta}$ независ
\end{proof}

\begin{theorem}[О проекции]
  Пусть $\vec{\xi}\sim N(\vec{0},\sigma^{2}E)$, $L_1:dimL_1=m_1$ и $L_2:dimL_2=m_2$ два
  ортогональных подпространства $\R^{n}$, $\vec{\eta}_1$ - проекция $\vec{\xi}$ на $L_1$,
  норм. распр., независ. и $\frac{|\eta_1|^{2}}{\sigma^{2}}\sim\chi^{2}(dimL_1)$,
  $\frac{|\eta_2|^{2}}{\sigma^{2}}\sim\chi^{2}(dimL_2)$
\end{theorem}
\begin{proof}
  $\vec{\eta}_1=A_1\vec{\xi}\sim N(\dots,\dots )$, $\vec{\zeta}=C\vec{\xi}$,
  $C$ - ортогональная. $\vec{\zeta}\sim N(\vec{0},C\sigma^{2}EC^{T})=N(\vec{0},\sigma^{2}E)$.
  Новый ортонормированный базис $e_1'\dots e_{m}'$ в $L_1$, 
  $e_{m+1}'\dots e_{n}'$ в $L_2$, $\vec{\eta_1}=\zeta_1e_1'+\dots +\zeta_{m}e_{m}'$,
  $\vec{\eta_2}=\zeta_{m+1}e_{m+1}'+\dots +\zeta_{n}e_{n}'$
\[
  \frac{\bar{\xi}}{\sigma}\sim N(\vec{0},E) \qquad \frac{|\eta_1|^{2}}{\sigma^{2}}=\sum_{}^{}\frac{\xi_i^{2}}{\sigma^{2}}\sim \chi^{2}(m_1)
\]
\end{proof}

% lecture 2 
 
\section{Порядковые случайные величины}
$\xi_1,\xi_2,\dots ,\xi_n$ назавис, $\xi_i \sim F(x)$
\[
  \eta=min(\xi_1,\dots \xi_n) \sim ? \qquad
  \zeta=max(\xi_1,\dots \xi_n) \sim ? 
\]
\begin{gather*}
  \Phi(y)=P(\eta<y)=1-P(\eta \ge y)=1-P(min(\xi_1,\dots ,\xi_n) \ge y)= \\ 
  =1-P(\xi_1\ge y,\dots ,\xi_n \ge y) = 1 - \prod_{i=1}^{n}P(\xi_i \ge y)= \\ 
  =1 - \prod_{i=1}^{n}(1-P(\xi_i < y))=1-(1-F(y))^{n}
\end{gather*}
\begin{gather*}
  \Psi(z)=P(\zeta<z)=P(max(\xi_1,\dots ,\xi_n) < z)= \\ 
  = P(\xi_1 < z, \dots , \xi_n<z)=\prod_{i=1}^{n}P(\xi_i < z)=(F(z))^{n}
\end{gather*}
Порядковые величины:
\begin{gather*}
  \xi_{(1)}=min(\xi_1, \dots , \xi_n) \\
  \xi_{(2)}=min(\xi_i:\xi_i\neq \xi_{(1)}) \\
  \xi_{(3)}=min(\xi_i:\xi_i\neq \xi_{(1)}, \xi_i \neq \xi_{(2)}) \\
  \dots \\ 
  \xi_{(n)}=max(\xi_1, \dots , \xi_n)
\end{gather*}
Положим $F(x)$ - непрерывна:

\incfig{l2_poryad}
\begin{gather*}
  P(t\ \le \xi_{(k)} < t + \Delta t)= \\
  =nP(t\le \xi<t+\Delta t)C_{n-1}^{k-1}(P(\xi<t))^{k-1}(P(\xi \ge t+\Delta t))^{n-k}C_{n-k}^{n-k}= \\
  =\kappa(t+\Delta t) - \kappa(t) \\ 
  n\frac{F(t+\Delta t)-F(t)}{\Delta t}C_{n-1}^{k-1}(F(t))^{k-1}(1-F(t+\Delta t))^{n-k}=\frac{\kappa(t+\Delta t)-\kappa(t)}{\Delta t}\\ 
  \kappa(t)=np(t)C_{n-1}^{k-1}(1-F(t))^{n-k}(F(t))^{k-1}
\end{gather*}
$\kappa(t)$ - плотность распределения $\xi_{(k)}$, $p(t)=F'(t)$

$\xi_{(1)}$ и $\xi_{(n)}$ совместное распр
\begin{gather*}
  G(y,z)=P(\xi_{(1)}<y,\xi_{(n)}<z) \\ 
  P(\xi_{(n)}<z)=P(\xi_{(1)}<y, \xi_{(n)} < z) + P(\xi_{(1)} \ge y, \xi_{(n)} < z) \\ 
  \Psi(z)=(F(z))^{n}=P(\xi_{(1)}<y,\xi_{(n)}<z)+\prod_{i=1}^{n}\underbrace{P(y \le \xi_i < z)}_{F(z)-F(y)} \\ 
  G(y,z)=P(\xi_{(1)}<y,\xi_{(n)}<z)=\left\{\begin{aligned}
      &(F(z))^{n},\; & y > z \\ 
      &(F(z))^{n}-(F(z)-F(y))^{n}, \; & y\le z
  \end{aligned}\right.
\end{gather*}

\section{Моделирование случайных величин}
\incfig{l2_model}
$\xi\sim F(x)$, $\eta\sim R(0,1)$, $F(x)=\eta_1 \to x_1$, 
для псевдослучайных чисел вихрь Мерсенна

\section{Основные задачи статистики}
Явление $\rightarrow$ математическая модель явления $\rightarrow$ вероятностная модель явления $\xi_i$.

Выборка - n наблюдений над явлением 
$\rightarrow$описательная статистика (непараметрическая), выбор классов (e.g. $\epsilon \sim N(a,\sigma^{2})$)
$\rightarrow$ параметрическая статистика (e.g. $\epsilon\sim N(a,\sigma^{2})$, $a-?$, $b-?$)

\begin{eg}
  Пытаемся понять как остывает чашка чая.
  \[
    \frac{dT}{dt}=k(T-T_0)+\epsilon
  \]
  Вероятностная модель явления с двумя случайными величинами
  (погрешности измерений $\epsilon$ и внутри $k$).

  Распределения полагаем нормальными и так далее.
\end{eg}

\begin{enumerate}
  \item Определение параметров и оценка их точности
  \item Проверка статистических гипотиз
\end{enumerate}

Характеристики модели $\theta$, по выборке оценка $\bar{\theta}(\vec{x}_n)$,
$n$ - объём выборки.

Статистика - $\forall$ барелевская функция от $\vec{x}_n$
(борелевская $g:\R\to\R \; \forall B\in \mathbb{B} \true g^{-1}(B)\in \mathbb{B}$).

Воспринимаем $\vec{x}_n$ с двух сторон:
\begin{enumerate}
  \item конкретные наблюдения над явлением
  \item независимые случайные величны с распределением, одинаковым со случайными величинами в вероятностной модели
\end{enumerate}

\subsection{Свойства оценок}
$\Theta$ - множество значений $\theta$, $\theta \in \Theta$, 
$\tilde{\theta}(\vec{x}_n)$ - оценка $\theta$ по выборке
\begin{enumerate}
  \item несмещённость $\forall\theta \in \Theta \true M[\tilde{\theta}(\vec{x}_n)]=\theta$
  \item состоятельность $\forall \theta \in \Theta \true \tilde{\theta} \overset{P}{\to}\theta$
    (i.e. $\forall \epsilon > 0 \; P(|\tilde{\theta}-\theta|\ge\epsilon)\underset{n\to\infty}{\to}0$)
  \item сравнение оценок $\tilde{\theta}_1$ эффективнее $\tilde{\theta}_2$,
    если $\forall \theta \in \Theta \true D[\tilde{\theta}_1] \le D[\tilde{\theta}_2]$
    и $\exists \theta \in \Theta : \; D[\tilde{\theta}_1] < D[\tilde{\theta}_2]$
\end{enumerate}
\begin{theorem}[Достаточное условие состоятельности]
  Если $\tilde{\theta}$ является несмещённой оценкой $\theta$ и $D[\tilde{\theta}]\underset{n\to\infty}{\to}0$, 
  то $\tilde{\theta}$ является состоятельной оценкой ($\forall \theta \in \Theta$)
\end{theorem}
\begin{proof}
  $M[\tilde{\theta}]=\theta$, по неравенству Чебышёва:
  \[
    \forall \epsilon>0 \true P(|\tilde{\theta}-\underbrace{M[\tilde{\theta}]}_{\theta}| < \epsilon) \ge 1 - \frac{D[\tilde{\theta}]}{\epsilon^{2}} \underset{n\to\infty}{\to} 1
  \]
\end{proof}

\hr
\begin{problem}[Т1] Пытаемся понять по двум серийным номерам сколько всего танков.

  $\xi\sim R(0,\theta)$, $\theta >0$ вер. модель., $\vec{x}_n$ - выбрка объёмом $n$
  \begin{gather*}
    \tilde{\theta}_1=2\bar{x}=2\frac{1}{n}\sum_{i=1}^{n}x_i \\
    \tilde{\theta}_2= \min x_i \\
    \tilde{\theta}_3= \max x_i \\
    \tilde{\theta}_4= x_1 + \frac{1}{(n-1)}\sum_{i=2}^{n}x_i
  \end{gather*}
  \begin{gather*}
    M[\xi]=\int_{-\infty}^{\infty}xp(x)dx=\int_{0}^{\theta}\frac{x}{\theta}dx=\frac{\theta}{2} \\
    M[\xi^{2}]=\int_{-\infty}^{\infty}x^{2}p(x)dx=\int_{0}^{\theta}\frac{x^2}{\theta}dx=\frac{\theta^{2}}{3} \\
  \end{gather*}
  Рассматриваем $\tilde{\theta}_1$:

  Несмещённость $\forall \theta >0 M[\tilde\theta]=\theta$:

  $M[\frac{\theta}{n}\sum_{i=1}^{n}x_i]=\frac{2}{n}\sum_{i=1}^{n}M[x_i]=2M[\xi]=\theta$ несмещённая

  $D[\tilde\theta_1]=D[\frac{2}{n}\sum_{}^{}x_i]=\frac{1}{n^{2}}\sum_{}^{}D[x_i]=
  \frac{4}{n}D[\xi]=\frac{\theta^{2}}{3n}\underset{n\to\infty}{\to}0$,
  по достаточному условия оценка состоятельная

  Рассматриваем $\tilde{\theta}_2$:
  \begin{gather*}
    M[\tilde\theta_2]=\int_{-\infty}^{\infty}y\phi(y)dy \\ 
    \Phi(y)=1-(1-F(y))^{n} \qquad \phi(y)=n(1-F(y))^{n-1}p(y) \\
    M[\tilde\theta_2]=\int_{0}^{\theta}n(1-\frac{y}{\theta})^{n-1}\frac{1}{\theta}ydy =\\
    t = 1 - \frac{y}{\theta} \\ 
    = -\int_{1}^{0}nt^{n-1}(1-t)\theta dt=\int_{0}^{1}n\theta t^{n-1}dt - \int_{0}^{1}n\theta t^{n}dt= \\
    =n\theta[1-\frac{n}{n+1}]=\frac{\theta}{n+1}\quad \text{  смещённая} \\
    \tilde\theta_2'=(n+1)x_{min}=(n+1)\tilde\theta_2 \quad \text{несмещённая} \\
    M[\tilde\theta_2^{2}]=\int_{0}^{\theta}n(1-\frac{y}{\theta})^{n-1}\frac{1}{\theta}y^{2}dy =\\
    = -\int_{1}^{0}nt^{n-1}(1-t)^{2}\theta^{2} dt= \frac{2\theta^{2}}{(n+1)(n+2)} \\ 
    D[\tilde\theta_2]=\frac{2\theta^{2}}{(n+1)(n+2)}-\frac{\theta^{2}}{(n+1)^{2}}=
    \theta^{2}\left[\frac{2(n+1)-(n+2)}{(n+1)^{2}(n+2)}\right]= \\ 
    =\theta^{2}\left[\frac{n}{(n+1)^{2}(n+2)}\right] \underset{n\to\infty}{\to}0
    \quad \text{достаточное не выполнятеся} \\ 
    D[\tilde\theta_2']=(n+1)^{2}D[\tilde\theta_2]=\frac{\theta^{2}n}{n+2}\not\to 0
  \end{gather*}
  Смотрим состоятельность $\tilde\theta_2'$ по определению
  \[
    \forall \theta >0 \; \forall \epsilon>0 \true P(|\tilde\theta_2'-\theta|\ge\epsilon) \underset{n\to\infty}{\to} 0 
  \]
  \begin{gather*}
    P(|\tilde\theta_2'-\theta|\ge\epsilon) \ge  P(\tilde\theta_2' > \theta +\epsilon)= \\ 
    = P((n+1)x_{min}\ge \theta + \epsilon)=P(x_{min} \ge \frac{\theta+\epsilon}{n+1}) = \\ 
    = 1-P(x_{min}<\frac{\theta+\epsilon}{n+1})=1-(1-(1-F(\frac{\theta+\epsilon}{n+1}))^{n})= \\ 
    =(1-(\frac{\theta+\epsilon}{\theta(n+1)}))^{n}\underset{n\to\infty}{\to}e^{-\frac{\theta+\epsilon}{\theta}} >0
  \end{gather*}
  Не является состоятельной!

  Смотрим состоятельность $\tilde\theta_2$ по определению:
  \begin{gather*}
    P(\tilde\theta_2<\theta-\epsilon) + \underbrace{P(\tilde\theta_2>\theta+\epsilon)}_{=0, \text{т.к.} \tilde\theta_2=x_{min}} \\ 
    P(x_{min}<\theta-\epsilon=\Phi(\theta-\epsilon))=1-(1-\frac{\theta-\epsilon}{\theta})^{n}=
    1-\left(\frac{\epsilon}{\theta}\right)^{n} \underset{n\to\infty}{\to}1
  \end{gather*}
  Не является состоятельной!

  Рассматриваем $\tilde\theta_3=x_{max}$:
  \begin{gather*}
    M[\tilde\theta_3]=\int_{-\infty}^{+\infty}z\psi(z)dz=\int_{0}^{\theta}n\frac{z^{n}}{\theta^{n}}dz=\frac{n}{n+1}\theta \qquad \text{смешённая}\\
    \Psi(z)=(F(z))^{n} \qquad \psi(z)=n(F(z))^{n-1}p(z)=n\left(\frac{z}{\theta}\right)^{n-1}\frac{1}{\theta} \{(0;\theta)\} \\
    D[\tilde\theta_3]\frac{n}{n+2}\theta^{2}-\frac{n^{2}}{(n+1)^{2}}\theta^{2}=\frac{n\theta^{2}}{(n+2)(n+1)^{2}} \\ 
    D[\tilde\theta_3']\frac{(n+1)^{2}}{n^{2}}D[\tilde\theta_3]=\frac{\theta^{2}}{n(n+2)} \underset{n\to\infty}{\to} 0 \qquad \text{состоятельная} \\
  \end{gather*}
  Смотрим состоятельность $\tilde\theta_2'$ по определению
  \begin{gather*}
    \forall\theta>0 \; \forall \epsilon > 0 \\ 
    P(|\tilde\theta_2'-\theta|\ge\epsilon)=P(x_{max}<\theta-\epsilon) + \underbrace{P(x_{max}\ge\theta+\epsilon)}_{=0}= \\ 
    =(F(\theta-\epsilon))^{n}=\left\{\begin{aligned}
      & 0<\epsilon<\theta: \; \left(\frac{\theta-\epsilon}{\theta}\right)^{n}\underset{n\to\infty}{to} 0 \\ 
      & \epsilon \ge \theta: \; (0)^{n} \underset{n\to\infty}{\to} 0 
    \end{aligned}\right.
  \end{gather*}
  Является состоятельной!

  % lecture 3

  Рассматриваем $\tilde\Theta_4$:
  \begin{gather*}
    M[\tilde\theta_4]=M[x_1+\sum_{i=2}^{n}x_i]=
    M[x_1]+\frac{1}{n-1}\sum_{i=1}^{n}M[x_i] =\frac{\theta}{2}+\frac{\theta}{2}=\theta \\ 
    D[\tilde \theta_4]=D[\xi]+\frac{1}{(n-1)^{2}}(n-1)D[\xi]=\frac{\theta^{2}}{12}\frac{n}{n-1} \underset{n\to\infty}{\not \to} 0
  \end{gather*}
  Достаточое усл. не работает.

  Используем теорему $\xi_n \overset{p}{\to} \xi$, $\eta_n \overset{p}{\to}\eta$, $\xi_n+\eta_n \overset{p}{\to}\xi+\eta$.

  И ЗБЧ Хинчина: $\xi_1,\dots ,\xi_n$ незав., одинак распр. $\implies$ $\frac{1}{n}\sum_{i=1}^{n}\xi_i \overset{p}{\to} M[\xi]$.
  \begin{gather*}
    x_1 \overset{p}{\to} x_1 \qquad \frac{1}{n-1}\sum_{i=2}^{n}x_i \overset{p}{\to} \frac{\theta}{2} \\ 
    \tilde \theta_4 \overset{p}{\to} x_1 + \frac{\theta}{2}
  \end{gather*}
  Не состоятельна!
 
  Адекватные остались $\tilde\theta_1=2 \bar x$, $\tilde\theta_3'=\frac{n+1}{n}x_{max}$
  \[
    D[\tilde\theta_1]=\frac{\theta^{2}}{3n} > D[\tilde{\theta}_3']=\frac{\theta^{2}}{n(n+2)}
  \]
  Лучшая оценка $\tilde{\theta}_3$.
\end{problem}
\hr

\section{Оптимальность и эффективность оценок}
\begin{definition}
  Несмещённая оценка $\tilde{\theta}(\vec{x}_n)$ характеристики $\theta$ называется
  оптимальной $\tilde{\theta}_{opt}$ если для $\forall \theta \in \Theta$ $\implies$
  $D[\tilde{\theta}_{opt}]=\inf D[\tilde{\theta}]$,
  $\inf$ по всем несмещённым оценкам $\theta$.
\end{definition}
\begin{theorem}[Единственность оптимальной оценки]
  Если оптимальная оценка существует, то она единственна.
\end{theorem}
\begin{proof}
  Пусть $\tilde{\theta}_1$ и $\tilde{\theta}_2$ разные оптимальные оценки
  \begin{gather*}
    \tilde{\theta}_3=\frac{\tilde{\theta}_{1}+\tilde{\theta}_{2}}{2} \qquad M[\tilde{\theta}_{3}]=\theta \\
    D[\tilde{\theta}_{3}]=\frac{1}{4}D[\tilde{\theta}_{1}]+D[\tilde{\theta}_{2}]+\frac{1}{2}cov(\tilde{\theta}_{1},\tilde{\theta}_{2})=
    \frac{1}{2}D[\tilde{\theta}_{1}]+\frac{1}{2}cos(\tilde{\theta}_{1},\tilde{\theta}_{2}) \\ 
    D[a\xi+b\eta]=a^{2}D[\xi]+b^{2}D[\eta]+2abcov(\xi,\eta) \\ 
    |cov(\tilde{\theta}_{1},\tilde{\theta}_{2})|\le \sqrt{D \tilde{\theta}_{1} D \tilde{\theta}_{2}}=D[\tilde{\theta}_{1}] \\
    D[\tilde{\theta}_{3}]\le D[\tilde{\theta}_{1}] \qquad D[\tilde{\theta}_{3}]=D[\tilde{\theta}_{1}] \\ 
    cov(\tilde{\theta}_{1},\tilde{\theta}_{2})=D[\tilde{\theta}_{1}] \quad \implies \quad r=1 \iff \tilde{\theta}_{1}=a \tilde{\theta}_{2}+b \\ 
    M[\tilde{\theta}_{1}]=M[\tilde{\theta}_{2}]=\theta \qquad D[\tilde{\theta}_{1}]=D[\tilde{\theta}_{2}] \\ 
    \left\{\begin{aligned}
      & \theta=a\theta+b \\ 
      & a^{2}D[\tilde{\theta}_{2}]=D[\tilde{\theta}_{2}]
    \end{aligned}\right. \implies 
    \left\{\begin{aligned}
      & a = 1 \\ 
      & b=0
    \end{aligned}\right. \\
    \implies \tilde{\theta}_{1}=\tilde{\theta}_{2}
  \end{gather*}
  Противоречие.
\end{proof}
Будем рассматриватть параметрические вероятностные модели:
\begin{gather*}
  \xi \sim \rho(x,\theta) , \, \theta\in\Theta\subset \R, \,x\in A(\theta)\\
  \xi \sim \rho(x, \vec{\theta}) , \, \vec{\theta}\in\Theta\subset \R^{m}, \,x\in A(\vec{\theta})\\ 
  \rho(x,\theta)=\underbrace{p(x,\theta)\{E\}}_{\text{непр. часть}} + \underbrace{\sum_{k}^{}p_k(\theta)\{x_k\}}_{\text{дискр. часть}}
\end{gather*}

\incfig{l3_rho}
\subsection{Информация Фишера}
\begin{gather*}
  I(\theta)=M\left[(\frac{\partial \ln \rho(x,\theta)}{\partial\theta})^{2}\right]= \\ 
  = \int_{E}^{}\left(\frac{\partial \ln p(x,\theta)}{\partial\theta}\right)^{2}p(x,\theta)dx+\sum_{k}^{}\left(\frac{\partial \ln p_k(x,\theta)}{\partial\theta}\right)^{2}p_k(\theta)
\end{gather*}
$I(\vec{\theta})$ - информационная матрица Фишера
\[
  I_{ij}(\vec{\theta})=M\left[\frac{\partial \ln p(x,\theta)}{\partial\theta_i}\frac{\partial \ln p(x,\theta)}{\partial\theta_j}\right]
\]
\begin{definition}
  Вероятностьная модель $\xi\sim \zeta(x,\theta)$, $\theta\in\Theta\subset \R$, $x\in A$
  называется регулярной, если
  \begin{enumerate}
    \item $\rho(x,\theta)$ непр дифф по $\theta$ на $\Theta$
    \item $\frac{\partial}{\partial\theta}\int_{A}^{}\rho(x,\theta)dx=\int_{A}^{}\frac{\partial}{\partial\theta}\rho(x,\theta)dx$ на $\Theta$
    \item $I(\theta)$ непр на $\Theta$ и $I(\theta)>0$ на $\Theta$
  \end{enumerate}
\end{definition}
\begin{definition}
  Вероятностьная модель $\xi\sim \zeta(x,\vec{\theta})$, $\vec{\theta}\in\Theta\subset \R^{m}$, $x\in A$
  называется регулярной, если
  \begin{enumerate}
    \item $\rho(x,\vec{\theta})$ непр дифф по $\vec{\theta}$ на $\Theta$
    \item $\frac{\partial}{\partial\theta_i}\int_{A}^{}\rho(x,\vec{\theta})dx=\int_{A}^{}\frac{\partial}{\partial\theta_i}\rho(x,\vec{\theta})dx$ на $\Theta$, $i=1,\dots ,m$
    \item $I(\vec{\theta})$ положительно определена на $\Theta$ и $I_{ij}(\vec{\theta})$ непрер. на $\Theta$
  \end{enumerate}
\end{definition}
\begin{definition}
  Вероятностная модель $\xi\sim\rho(x,\theta)$,  $\vec{\theta}\in\Theta\subset \R^{m}$, $x\in A$
  называется сильно регулярной, если эта модель регулярна и
  \begin{enumerate}
    \item $\rho(x,\theta)$ $k$ раз непрерывно дифф по $\theta$ на $\Theta$ ($k\ge 2$)
    \item $\frac{\partial^{l}}{\partial\theta^{l}}\int_{A}^{}\rho(x,\theta)dx=\int_{A}^{}\frac{\partial^{l}}{\partial\theta^{l}}\rho(x,\theta)dx$, $l=1,\dots ,k$
  \end{enumerate}
\end{definition}
\begin{definition}
  Вероятностная модель $\xi\sim \zeta(x,\vec{\theta})$, $\vec{\theta}\in\Theta\subset \R^{m}$, $x\in A$
  называется сильно регулярной, если эта модель регулярна и
  \begin{enumerate}
    \item $\rho(x,\vec{\theta})$ $k$ раз непрерывно дифф по $\theta$ на $\Theta$ ($k\ge 2$)
    \item все производные по $\vec{\theta}$ перестановочные с $\int_{}^{}$ по $x$
  \end{enumerate}
\end{definition}

\begin{definition}
  Статистика $\tilde{g}(\vec{x}_n)$ называется регулярной оценкой функции $g(\theta)$,
  если она является несмещённой оценкой и 
  \begin{gather*}
    \frac{\partial}{\partial\theta}\int_{B}^{}\tilde{g}(\vec{x}_n)L(\vec{x}_n,\theta)d\vec{x}_n=
    \int_{B}^{}\tilde{g}(\vec{x}_n)\frac{\partial}{\partial \theta}L(\vec{x}_n,\theta)d\vec{x}_n
  \end{gather*}
  где $L(\vec{x}_n,\theta)$ - плотность распределения случайного вектора $\vec{x}_n$ \\ 
  ($L(\vec{x}_n,\theta)=\prod_{i=1}^{n}\rho(x_i,\theta)$), $B=\underbrace{A\times A\times\dots \times A}_{n}$
\end{definition}
\begin{theorem}[Достаточное условие регулярности оценки]
  Если модель регулярна, $\tilde{g}(\vec{x}_n)$ является несмещ. оценкой $g(\theta)$
  и $D[\tilde{g}(\vec{x}_n)]$ ограничена на $\forall$ компакте из $\Theta$ по $\theta$,
  тогда оценка регулярна.
\end{theorem}

% lecture 5


\subsection{Неравенство Крамера-Рао}
\begin{theorem}
Пусть модель является регулярной, $\tilde{g}(\vec{x}_n)$
является регулярной оценкой оценкой дифф функции $g(\theta)$.
Тогда
\[
  \forall \theta \in \Theta \true D[\tilde{g}]\ge \frac{(g')^{2}(\theta)}{nI(\theta)}
\]
\end{theorem}
\begin{proof}
  $\xi \sim \rho(x,\theta)$, $\theta\in\Theta\subset \R$, $x\in A(\theta)$,
  $\vec{x}_n$ независ. выборка

  $L(\vec{x}_n,\theta)=\prod_{i=1}^{n}\rho(x_i,\theta)$ - распр. выборки $\vec{x}_n$,
  $B=A\times\dots \times A$
  \[
    \frac{\partial}{\partial\theta}\idotsint \limits_{B} L(\vec{x},\theta)d\vec{x}=\frac{\partial}{\partial\theta}1=0
  \]
  в силу регулярности модели
  \[
    \idotsint \limits_{B}\frac{\partial}{\partial\theta}Ld\vec{x}=0 \\ 
  \]
  Домножаем и делим на $L$, там где $L=0$ считаем что интеграл $0$
  \begin{gather*}
    \int_{B}^{}\frac{\partial\ln L}{\partial \theta}Ld\vec{x}=0 \\ 
    M[\tilde{g}]=g(\theta) \\ 
    \int_{B}^{}\tilde{g}(\vec{x}_n)L(\vec{x}_n,\theta)d\vec{x}_n=g(\theta) \\
    \frac{\partial}{\partial \theta}\int_{B}^{}\tilde{g}(\vec{x}_n)L(\vec{x}_n,\theta)d\vec{x}_n=\frac{\partial}{\partial \theta}g(\theta) \\ 
    \int_{B}^{}\tilde{g}(\vec{x}_n)\frac{\partial}{\partial \theta}Ld\vec{x}_n=g'(\theta) \\ 
    \int_{B}^{}\tilde{g}(\vec{x}_n)\frac{\partial \ln L}{\partial \theta}Ld\vec{x}_n=g'(\theta) \\ 
    \int_{B}^{}(\tilde{g}(\vec{x}_n)-g(\theta))\frac{\partial \ln L}{\partial \theta}Ld\vec{x}_n=g'(\theta) \\ 
  \end{gather*}
  $\eta=\tilde{g}(\vec{x}_n)-g(\theta)$ - сл. вел

  $\zeta=\frac{\partial \ln L(\vec{x}_n,\theta)}{\partial \theta}$ - сл. вел.
  \begin{gather*}
    M[\eta]=0 \qquad M[\zeta]=0 \\
    M[\eta\zeta]=g'(\theta) \\ 
    cov(\eta,\zeta)=M[\eta\zeta]-M[\eta]M[\zeta]=g'(\theta) \\ 
    r=\frac{cov(\eta,\zeta)}{\sqrt{D\eta D\zeta}} \qquad |r|\le 1 \\ 
    \frac{cov^{2}(\zeta,\eta)}{D\zeta D\eta} \le 1 \\ 
    g'^{2}(\theta) \le D\zeta \underbrace{D[\tilde{g}]}_{D[\tilde{g}]} \\ 
    D\zeta=M[\zeta^{2}]-M^{2}[\zeta]=M[\zeta^{2}] \\ 
    D\zeta=D\left[\frac{\partial\ln L}{\partial\theta}\right] 
    =D\left[\sum_{i=1}^{n}\frac{\partial\ln \rho(x_i,\theta)}{\partial\theta}\right]
    =\sum_{i=1}^{n}D\left[\frac{\partial\ln \rho(x_i,\theta)}{\partial\theta}\right]= \\
    =nD\left[\frac{\partial\ln \rho(x_i,\theta)}{\partial\theta}\right]
    =nM\left[\left(\frac{\partial \ln \rho}{\partial\theta}\right)^{2}\right] - n\underbrace{M^{2}\left[\frac{\partial \ln \rho}{\partial \theta}\right]}_{0}=nI(\theta)
  \end{gather*}
\end{proof}
\begin{corollary}
  \phantom{.}

  \begin{enumerate}
    \item оценка параметра $\theta$, $g(t)=\theta$,
      \[
        D[\tilde{\theta}]\ge\frac{1}{nI(\theta)}
      \]
    \item многомерный аналог нер. Крамера-Рао
      \[
        D[\tilde{g}(\vec{x}_n)]\ge \frac{1}{n}\nabla^{T}g(\vec{\theta})I^{-1}(\vec{\theta})\nabla g(\vec{\theta})
      \]
  \end{enumerate}
\end{corollary}

\begin{definition}[Эффективная оценка]
  Регулярная оценка $\tilde{g}(\vec{x}_n)$ функции $g(\theta)$ называется 
  эффективной ($\tilde{g}_{eff}$), если 
  $\forall \theta\in\Theta \true D[\tilde{g}_{ef f}]=\inf D[\tilde{g}]$,
  $\inf$ берётся по всем регулярным оценкам.
\end{definition}
\begin{theorem}
  Если эффективная оценка $\exists$,
  то она единственна.
\end{theorem}
\begin{proof}
  Так же как и оптимальная только нужно доказать что
  $\tilde{\theta}_{3}=\frac{\tilde{\theta}_{1}+\tilde{\theta}_{2}}{2}$ - регулярная.
\end{proof}
\begin{theorem}[Достаточное условие эффективности]
  Пусть выполнены условия нер. Крамера-Рао и
  $D[\tilde{g}]=\frac{g'^{2}}{nI(\theta)}$, тогда
  $\tilde{g}$ эффективная оценка $g(\theta)$.
\end{theorem}
\begin{theorem}[Теорема о частоте]
  Частота появления события $A$ в $n$ независимых опытах является несмещённой,
  состоятельной и эффективной оценкой вероятности появления этого события.
\end{theorem}
\begin{proof} (на примере)
  \begin{gather*}
    \xi \sim \rho(x,\theta)=\theta\{1\} + (1-\theta)\{0\} \qquad \theta \in (0,1) \\ 
    \xi \sim Bi(1,\theta) \qquad \nu=\frac{m}{n} \\ 
    \vec{x}_n=(0,0,1,\dots ) \qquad \nu=\frac{1}{n}\sum_{}^{}x_i=\bar{x} \qquad \tilde{\theta}=\bar{x} \\ 
  \end{gather*}
  \begin{enumerate}
    \item несмещённость ($\xi\sim Bi(l,\theta)$, $M[\xi]=l\theta$, $D[\xi]=l\theta(1-\theta)$)
      \[
        M[\bar{x}]=\frac{1}{n}M[\sum_{}^{}x_i]=M[\xi]
      \]
    \item состоятельность 
      \[
        D[\tilde{\theta}]=D[\frac{1}{n}\sum_{}^{}x_i]=\frac{1}{n^{2}}nD[\xi]=\frac{1}{n}\theta(1-\theta) \underset{n\to\infty}{\to}0
      \]
      состоятельна по достаточному условию
    \item эффективность, модель регулярна
      \[
        I(\theta)=\frac{l}{\theta(1-\theta)}\Big|_{l=1}=\frac{1}{\theta(1-\theta)}
      \]
      $\tilde{\theta}=\bar{x}$ - регулярная оценка?

      $D[\tilde{\theta}]=\frac{1}{n}\theta(1-\theta)$ огран на $\forall$ компакте из $(0,1)$

      Является регулярной $\checkmark$

      Неравенство Крамера-Рао:
      \[
        D[\tilde{\theta}]=\frac{1}{n}\theta(1-\theta) \ge \frac{1}{nI(\theta)}=\frac{\theta(1-\theta)}{n}
      \]
      достигает нижней грани $\implies$ эффективная (в данном случае ещё и оптимальная)
  \end{enumerate}
\end{proof}

\section{Описательная стат. (непараметр. стат.)}
$\vec{x}_n$ - выборка

Вероятностная модель - все распределения, кроме сингулярных и вырожденных.
\begin{enumerate}
  \item Вариационный ряд - упорядоченная ваборка
    \[
      x_{min}=x_{(1)}\le x_{(2)}\le x_{(3)} \le \dots \le x_{(n)}=x_{max}
    \]
    $x_{(k)}$ - k-ая порядковая сл. вел
  \item Размах выборки $l=x_{max}-x_{min}$
  \item Медиана выборки $med$
    \[
      mes =\left\{\begin{aligned}
        & x_{(k+1)}, \mu n=2k+1 \\ 
        & \frac{x_{(k+1)}+x_{(k)}}{2}, \; n=2k
      \end{aligned}\right.
    \]
  \item Мода - эл. выборки, который встречается чаще всего
  \item Квартили $q_1$, $q_2$ (медианы половинок)
  \item Boxplot

    \incfig{l5_boxplot}
    $\epsilon=q_2-q_1$, если $x_{min}<q_1-1.5\epsilon$ или $x_{max}>q_2+1.5\epsilon$
    рисуем усики до $q_1-1.5\epsilon$ или $q_2+1.5\epsilon$ соответственно,
    а дальше выбросы обозначаем точками для каждого значения
  \item эмпирическая функция распределения
    \[
      \tilde{F}(x)=\frac{m(x)}{n}
    \]
    где $m(x)$ число элементов выборки, которые $<x$.
    \begin{gather*}
      F(x)=P(\underbrace{\xi<x}_{A})
    \end{gather*}
    $\tilde{F}$ является несмещённой, состоятельной и эффективной оценкой $F(x)$
    (по Т. о частоте).
  \item Гистограмма

    Статистический ряд
    \[
      \underbrace{[y_1,y_2)}_{\nu_1=\frac{m_1}{n}}, \underbrace{[y_2,y_3)}_{\nu_2}\dots \underbrace{[y_k,y_{k+1})}_{\nu_k}
    \]
    Эмперически $k=1+\log_2 n$
    
    \incfig{l5_histo}
    
    $\nu_m=P(y_m \le \xi < y_{m+1})=\int_{y_m}^{y_{m+1}}p(x)dx=p(\bar{x})\Delta_m$
  \item числовые характеристики

    $\alpha_k=M[\xi^{k}]$ момент к-го порядка
    \[
      \tilde{\alpha}_k=\frac{1}{n}\sum_{i=1}^{n}x_i^{k} \qquad \tilde{\alpha}_1=\bar{x} \\ 
    \]
    \hr
    \begin{itemize}
      \item несмещ: $M[\alpha_k]=\frac{1}{n}M[\sum_{}^{}x_i^{k}]=M[\xi^{k}]=\alpha_k$
      \item состоятельность: ЗБЧ Хинчина $\tilde{\alpha}_k \overset{p}{\to}\alpha_k=M[\xi^{k}]$
    \end{itemize}
    \hr

    $\mu_k=M[(\xi-M\xi)^{K}]$ - центральный момент k-го порядка
    \[
      \tilde{\mu}_k=\frac{1}{n}\sum_{i=1}^{n}(x_i-\bar{x})^{k} \\ 
    \]
    \hr
    \begin{itemize}
      \item состоятельность
        \begin{gather*}
           \mu_k=M[\sum_{m=0}^{k}C_k^{m}\xi^{m}(-1)^{k-m}(M\xi)^{k-m}]= \\
           = \sum_{m=0}^{k}C_k^{m}(-1)^{k-m}\alpha_m (\alpha_1)^{k-m} \\ 
           \tilde{\mu}_k=\sum_{m=0}^{k}C_k^{m}(-1)^{k-m}\tilde{\alpha}_m (\tilde{\alpha}_1)^{k-m} 
        \end{gather*}

        Теорема наследования сходимости:

        $\xi_n \overset{p}{\to} \xi$, $f(x)$ непр на $\R$ $\implies f(\xi_n) \overset{p}{\to} f(\xi)$

        $\xi_n \overset{p}{\to} C$, $f(x)$ непр в точке $x=C$ $\implies f(\xi_n) \overset{p}{\to} f(C)$

        $\tilde{\alpha}_k \overset{p}{\to} \alpha_k$, $f(x_1,\dots ,x_n)$ непр $\implies$
        $\tilde{\mu}_k \overset{p}{\to} \mu_k$ 
      \item несмещённость 
        \begin{gather*}
          \mu_2=D\xi \qquad \tilde{\mu}_2=\tilde{\alpha}_2 - (\tilde{\alpha})^{2} \\ 
          M[\tilde{\mu}_2]
          =M\left[\frac{1}{n}\sum_{}^{}x_i^{2}\right]-M\left[(\frac{1}{n}\sum_{}^{}x_i)^{2}\right] = \\
          = M\xi^{2}-(D[\bar{x}]+(M[\bar{x}])^{2})
          = M\xi^{2}-\frac{1}{n^{2}}nD\xi - (M\xi)^{2}= \\
          = D\xi \left[1-\frac{1}{n}\right]=\mu_2\frac{n-1}{n}
        \end{gather*}
        $S^{2}=\frac{n}{n-1}\tilde{\mu}_2$, $M[S^{2}]=\mu_2$ несмещ оценка дисперсии
        \[
          S^{2}=\frac{1}{n-1}\sum_{i=1}^{n}(x_i-\bar{x})^{2}
        \]
    \end{itemize}
    \hr
    коэффициент асимметрии
    \begin{gather*}
      \gamma=\frac{\mu_3}{\sigma^{3}}=\frac{\mu_3}{\mu_2^{3/2}} \\ 
      \tilde{\gamma}=\frac{\tilde{\mu}_3}{\tilde{\mu}_2^{3/2}} \overset{p}{\to}\gamma
    \end{gather*}
  \item оценка распределения статистики
    \[
      \vec{x}_n \qquad \tilde{g}(\vec{x}_n)
    \]
    $\vec{x}_n$ становится вероятностной моделью,
    вытаскиваем 1000 подвыбоок с повторением элементов того же объёма $\vec{x}_n^{*}$,
    $\vec{x}_n^{*} \rightarrow \tilde{g}_i^{*}(\vec{x}_n^{*})$,
    строим гистограмму из $\tilde{g}_1^{*}\dots \tilde{g}_{10 0 0}^{*}$
\end{enumerate}

\section{Методы нахожд. параметров модели}
\[
  \xi\sim \rho(x,\vec{\theta}), \ \vec{\theta}\in\Theta \subset \R^{m}, \ x\in A
\]
Парметрическая модель, $\vec{x}_n$ выборка
\begin{enumerate}
  \item Метод моментов (Пирсон)
    \[
      \alpha_k(\vec{\theta})=M[\xi^{k}] \rightarrow \tilde{\alpha}_k=\alpha_k(\vec{\theta})
    \]
    Если можем решить систему получаем $\tilde{\vec{\theta}}$ оценку методом моментов (ОММ)

% lecture 6

    \begin{remark}
    ОММГ (ОММ Групированная) для статистического ряда:
    \begin{gather*}
      \underbrace{[y_1,y_2)}_{\nu_1}\dots \underbrace{[y_k,y_{k+1})}_{\nu_k} \qquad \nu_i=\frac{m_i}{n} \\ 
      z_1=\frac{y_1+y_2}{2},\dots ,z_k=\frac{y_k+y_{k+1}}{2} \\ 
      \tilde{\alpha}_l=\sum_{i=1}^{k}z_i^{l}\nu_i
    \end{gather*}
    \end{remark}
  \item Оценка Методом Правдоподобия (Фишер):

    \hr 
    монета 10 раз, 6 орлов, 4 решки
    \begin{enumerate}
      \item $p=\frac{1}{2}$
      \item $p=\frac{1}{3}$ - орёл, $p=\frac{2}{3}$ - решка
        \[
          \left(\frac{1}{2}\right)^{10}=0.0 0 098 \qquad \left(\frac{1}{3}\right)^{6}\left(\frac{2}{3}\right)^{4}=0.0 0 027
        \]
    \end{enumerate}
    \hr
    \[
      L(\vec{x}_n,\theta)=\prod_{i=1}^{n}\rho(x_i,\theta)
    \]
    $fix \, \theta$, $L(\vec{x}_n)$ - плотность распределения выборки

    $fix \, \vec{x}_n$, $L(\theta)=\prod_{i=1}^{n}\rho(x_i, \theta)$ - функция правдоподобия
    (здесь $x_i$ - элемент выборки), пытаемся максимизировать $L(\theta)\to\max$
    \begin{remark}
      ОМПГ для статистического ряда 
      \begin{gather*}
        \underbrace{[y_1,y_2)}_{\nu_1}\dots \underbrace{[y_k,y_{k+1})}_{\nu_k} \qquad \nu_i=\frac{m_i}{n} \\ 
        P_1(\theta)=\int_{-\infty}^{y_2}\rho(x,\theta)dx \\
        P_2(\theta)=\int_{y_2}^{y_3}\rho(x,\theta)dx \\
        \dots \\
        P_k(\theta)=\int_{y_k}^{+\infty}\rho(x,\theta)dx \\
        L(\theta)=P_1^{m_1}\dots P_k^{m_k} \qquad L(\theta)\to\max
      \end{gather*}
    \end{remark}

\end{enumerate}

\section{Асимптотические свойства оценок}
$n\to\infty$
\begin{enumerate}
  \item состоятельность $\forall \theta \in \Theta \true \tilde{g}(\vec{x}_n)\overset{p}{\to}g(\theta)$
  \item асимптотическая несмещённость $\forall \theta \in \Theta \true M[\tilde{g}(\vec{x}_n)] \underset{n\to \infty}{\to}g(\theta)$
  \item асимптотическая эффективность $\forall \theta\in\Theta\true nD[\tilde{g}(\vec{x}_n)] \underset{n\to\infty}{\to}\frac{g'^{2}(\theta)}{I(\theta)}$
  \item асимпотическая нормальность $\forall \theta \in \Theta \true \sqrt{n}(\tilde{g}(\vec{x}_n)-g(\theta)) \overset{F}{\to} \eta\sim N(0,\sigma^{2})$
\end{enumerate}

\subsection{Асимптотические свойства ОММ}
\begin{gather*}
  \alpha_k(\vec{\theta})=\tilde{\alpha}_k \to \tilde{\vec{\theta}}=f(\tilde{\alpha}_1,\dots ,\tilde{\alpha}_k) \\ 
  \tilde{\alpha}_k \overset{p}{\to}\alpha_k
\end{gather*}
$f$ - непр в $\alpha_1,\dots ,\alpha_k$, тогла по теореме наследования 
$\tilde{\vec{\theta}}\overset{p}{\to}f(\alpha_1,\dots ,\alpha_k)=\vec{\theta}$ состоятельная

Теорема о наследовании нормальности:

$\sqrt{n}(\xi_n-a) \rightsquigarrow N(0,\sigma^{2})$ и $f(x)\in C'(r)$ и $f'(a)\neq 0$,
тогда
\[
  \sqrt{n}(g(\xi_n)-g(a)) \rightsquigarrow N(0,g'^{2}(a)\sigma^{2})
\]

ЦПТ:
\begin{gather*}
  \frac{\sum_{}^{}x_i^{k}-nM[\xi^{k}]}{\sqrt{nD[\xi^{k}]}} \rightsquigarrow N(0,1) \\ 
  \frac{\tilde{\alpha}_k-a_k}{\sqrt{\alpha_{2k}-a_k^{2}}}\sqrt{m}\rightsquigarrow N(0, \underbrace{\alpha_{2k}-a_k^{2}}_{\sigma_k^{2}}) \\ 
  (f(\tilde{\alpha}_k)-f(\alpha_j))\sqrt{n} \rightsquigarrow N(0,f'^{2}(\alpha_k)\sigma_k^{2}) \\ 
  (\tilde{\theta}-\theta)\sqrt{n} \rightsquigarrow N(0,f'^{2}(\alpha_k)\sigma_k^{2})
\end{gather*}

\subsubsection{Многомерное ЦПТ}
\begin{gather*}
  \alpha=\begin{pmatrix}
    \alpha_{s_1} \\ \vdots \\ \alpha_{s_k}
  \end{pmatrix}
  \qquad 
  \tilde\alpha=\begin{pmatrix}
    \tilde{\alpha}_{s_1} \\ \vdots \\ \tilde{\alpha}_{s_k}
  \end{pmatrix}
  \qquad
  \tilde{\alpha}_{s_1}=\frac{1}{n}\sum_{i=1}^{n}x_i^{s_1} \\ 
  (\tilde{\alpha}-\alpha)\sqrt{n}\rightsquigarrow N(\vec{0},K) \qquad K_{ij}=\alpha_{s_i+s_j}-\alpha_{s_i}\alpha_{s_j}
\end{gather*}
$f(x)\in C'(R^{k})$ и $\nabla f(\alpha)\neq 0$
\[
  (f(\tilde{\alpha})-f(\alpha))\sqrt{n} \rightsquigarrow N(0, \nabla^{T}f(\alpha)K\nabla f(\alpha))
\]

\subsection{Асимптотические свойства ОМП}
\begin{theorem}
  Пусть вероятностная модель сильно регулярна и множество $\Theta$ открыто.

  Тогда ОМП является состоятельной, асимп. несмещ., асимп. эффект. и асимп. нормальной.
\end{theorem}
\begin{proof}
  $L(\theta)\to\max$, $\ln L\to\max$, $\frac{d\ln L(\tilde{\theta})}{d\theta}=0$
  Ряд Тёйлора с остаточным членом в форме Лагранжа:
  \begin{gather*}
    \underbrace{\frac{d\ln L(\theta)}{d\theta}}_{0}=\frac{d \ln L}{d\theta}(\theta)+\frac{d^{2} \ln L}{d\theta^{2}}(\theta^{*})(\tilde{\theta}-\theta) \\ 
    \tilde{\theta}-\theta=-\frac{(\ln L)'(\theta)}{(\ln L)''(\theta^{*})} \\ 
    \frac{d \ln L}{d \theta}=\frac{d}{d\theta}(\ln \prod_{}^{}p(x_i,\theta))=\sum_{i=1}^{n}\frac{d \ln p(x_i,\theta)}{d\theta}
  \end{gather*}
  ЗБЧ Хинчина:$\frac{1}{n}\sum_{}^{}\frac{d\ln p}{d\theta}\overset{p}{\to}M\left[\frac{d \ln p(\xi, \theta)}{d\theta}\right]$
  \begin{gather*}
    \int_{-\infty}^{+\infty}p(x,\theta)dx=1 \\ 
    \int_{-\infty}^{+\infty}\frac{d}{d\theta}p(x,\theta)dx=1 \\ 
    \int_{-\infty}^{+\infty}\frac{d \ln p}{d\theta}p dx =0 \\ 
    M\left[\frac{d \ln p}{d\theta}\right]=0
  \end{gather*}
  \begin{gather*}
    \frac{d}{d\theta}\int_{-\infty}^{+\infty}\frac{d \ln p}{d\theta}p dx =0 \\ 
    \int_{-\infty}^{+\infty}\frac{d^{2}\ln p}{d\theta^{2}}p dx + \int_{-\infty}^{+\infty}\frac{d \ln p}{d\theta}\frac{dp}{d\theta}dx=0 \\ 
    M\left[\frac{d^{2} \ln p}{d\theta^{2}}\right] + \underbrace{M\left[\left(\frac{d \ln p}{d\theta}\right)^{2}\right]}_{I(\theta)>0} = 0 \\ 
    \frac{d^{2} \ln L}{d\theta^{2}}=\sum_{i=1}^{n}\frac{d^{2}\ln p(x_i,\theta^{*})}{d\theta^{2}} \\ 
    \frac{1}{n}\sum_{}^{}\frac{d\ln p(x_i,\theta^{*})}{d\theta^{2}} \overset{p}{\to}-I(\theta^{*}) \neq 0
  \end{gather*}
  Состоятельность доказана: $\theta^{*}\overset{p}{\to}\theta$
  \begin{gather*}
    \frac{\sum_{}^{}\frac{d\ln p}{d\theta}-\overbrace{nM[\frac{d \ln p}{d \theta}]}^{=0}}{\sqrt{nD[\frac{d\ln p}{d\theta}]}} \rightsquigarrow N(0,1)
  \end{gather*}
  Лемма Слуцкого: $\xi_n \overset{F}{\to}\xi$, $\eta_n \overset{p}{\to} C$, $x_n\eta_n \overset{F}{\to}\xi C$
  \begin{gather*}
    \tilde{\theta}-\theta=-\cfrac{\frac{\sum_{}^{}\frac{d\ln p}{d\theta}}{\sqrt{nI(\theta)}}\sqrt{nI(\theta)}}{\frac{1}{-nI(\theta)}\sum_{}^{}\frac{d^{2} \ln p}{d \theta^{2}}(-nI(\theta))} \\ 
    a = \frac{\sum_{}^{}\frac{d\ln p}{d\theta}}{\sqrt{nI(\theta)}}\rightsquigarrow N(0,1) \qquad b =\frac{1}{-nI(\theta)}\sum_{}^{}\frac{d^{2} \ln p}{d \theta^{2}} \rightsquigarrow1 \\ 
    (\tilde{\theta}-\theta)\sqrt{nI(\theta)}=\frac{a}{b} \rightsquigarrow N(0,1) \\ 
    (\tilde{\theta}-\theta)\sqrt{n} \rightsquigarrow N(0, \frac{1}{I(\theta)}) \\ 
    D[(\tilde{\theta}-\theta)\sqrt{n}]=nD[\tilde{\theta}] \underset{n\to \infty}{\to} \frac{1}{I(\theta)}
  \end{gather*}
  Асимптотическая эффективность.
\end{proof}

% lecture 7

\begin{corollary}
  $\tilde{\theta}\overset{p}{\to}\theta$ - сост. $\tilde{\theta}$ ОМП, $\theta \in \Theta \subset \R$
\[
  \sqrt{n}(\tilde{\theta}-\theta) \rightsquigarrow N(0, \frac{1}{I(\theta)})
\]
  \begin{itemize}
    \item $g(\theta)\in C'(\Theta)$ и $g'(\theta)\neq 0$ на $\Theta$
      \begin{gather*}
        \sqrt{n}(g(\theta)-g(\theta)) \rightsquigarrow N(0, g'^{2}(\theta)\frac{1}{I(\theta)}) \\ 
        g(\tilde{\theta}) \overset{p}{\to} g(\theta)
      \end{gather*}
      $g(\tilde{\theta})$ сост. оценка $g(\theta)$, асим. несмещ., асим. эффект., асим. норм.
    \item многомерный аналог
      \begin{gather*}
        \sqrt{n}(\tilde{\vec{\theta}}-\vec{\theta}) \rightsquigarrow N(\vec{0}, I^{-1}(\vec{\theta})) \\ 
        g(\vec{\theta}) \in C'(\R^{m}) \qquad \nabla g(\vec{\theta}) \neq 0 \; \theta \in \Theta \subset \R^{m} \\ 
        \sqrt{n}(g(\tilde{\vec{\theta}})-g(\vec{\theta})) \rightsquigarrow N(\vec{0}, \nabla ^{T} g(\vec{\theta})I^{-1}(\vec{\theta})\nabla g(\vec{\theta}))
      \end{gather*}
  \end{itemize}
\end{corollary}
\begin{eg}
  $\xi \sim R(0,\theta)$, $\theta>0$, ОМП: $\tilde{\theta}=x_{max}$

  $\tilde{\theta}'=\frac{n+1}{n}x_{max}$ несмещ

  $M[x_{max}]=\frac{n}{n+1}\theta \underset{n\to\infty}{\to} \theta$ асим. несм.

  $x_{max} \overset{p}{\to} \theta$ сост.

  $D[x_{max}]=\frac{n\theta^{2}}{(n+1)^{2}(n+2)}$, $I(\theta)=\frac{1}{\theta^{2}}$,
  $nD[x_{max}] \underset{n\to\infty}{\not \to}\frac{1}{I(\theta)}$,
  значит не является эффективной
  (на самом деле оценка сверхэффективная, модель нерегулярна условия теоремы не выполнены)

  Пусть асим. норм.
  \begin{gather*}
    \sqrt{n}(\underbrace{\tilde{\theta}}_{x_{max}}-\theta) \rightsquigarrow N(0,\sigma^{2}) \\ 
    P(\sqrt{n}(x_{max}-\theta) < x) \underset{n\to\infty}{\to} \Phi(x) \; \forall x\in \R \\ 
    P(\sqrt{n}(x_{max}-\theta)<0)=1 \to 1 \qquad \Phi(0)=\frac{1}{2} 
  \end{gather*}
  Противоречие $\implies$ не является асим. нормальной.
\end{eg}

\section{Доверительный интервал}
\begin{definition}
  Доверительным интервалом величины $h$ вероятностной модели называется
  случайный интервал, который накрывает значение $h$ с вероятностью,
  не меньшей $\beta$.
  \begin{gather*}
    I=(g_{1}(\vec{x}_n), g_2(\vec{x}_n)) \\ 
    P((g_1,g_2)\ni \theta) \ge \beta
  \end{gather*}
  $\beta$ - доверительная вероятность, чаще всего $0.9, 0.95, 0.99$.
\end{definition}

\subsection{Методы построения доверит. инт.}
\begin{itemize}
  \item точный
  \item асимптотический
    \begin{itemize}
      \item по ОММ
      \item по ОМП
    \end{itemize}
  \item численные
    \begin{itemize}
      \item параметрический бутстрап
      \item непараметрический бутстрап
    \end{itemize}
\end{itemize}
\subsubsection{Точный метод}
$h, \vec{x}_n \to f(g,\vec{x}_n) \sim g(t)$ (созерцание)
\begin{enumerate}
  \item $g(t)$ - плотность распр. (сл. вел. непр.)

    \incfig{l7_1}
    $\alpha+\beta=1$, квантиль $F(x_{p})=p$, $x_p$ - квантиль порядка $p$, $F(x_p)=\int_{-\infty}^{x_p}q(t)dt$

    \begin{gather*}
      t_1=g_{\alpha/2}=g_{\frac{1-\beta}{2}} \qquad t_2=g_{\beta+\frac{\alpha}{2}}=g_{\frac{1+\beta}{2}} \\ 
      P(t_1<f(h,\vec{x}_n)<t_2)=\beta \\ 
      g_1(\vec{x}_n) < h < g_2(\vec{x}_n)
    \end{gather*}
  \item $g(t)$ содержит дискр. части, сдвигаем $\beta$ так чтобы получить точное равенство
\end{enumerate}
\begin{eg}
  $\xi\sim N(\theta_1, \theta_2^{2})$, $\theta_1\in \R$, $\theta_2>0$
  \begin{gather*}
    \tilde{\theta}_1=\bar{x} \qquad \tilde{\theta}_{2}^{2}=S^{2}
  \end{gather*}
  Теорема Фишера:
  \[
    \sqrt{n}\frac{\bar{x}-\theta_1}{\theta_2} \sim N(0,1) \qquad \frac{S^{2}(n-1)}{\theta_2^{2}} \sim \chi^{2}(n-1) 
  \]
  \begin{gather*}
    t_1=\chi^{2}_{\frac{1-\beta}{2}}(n-1) \qquad t_2=\chi^{2}_{\frac{1+\beta}{2}}(n-1)  \\ 
    P(t_1<\frac{S^{2}(n-1)}{\theta_2^{2}}<t_2) = ;B \\ 
    \frac{S^{2}(n-1)}{t_2} < \theta^{2}_2 < \frac{S^{2}(n-1)}{t_1} \\
    \sqrt{\frac{S^{2}(n-1)}{t_2}} < \theta_2 < \sqrt{\frac{S^{2}(n-1)}{t_1}}
  \end{gather*}
  \begin{gather*}
    \cfrac{\sqrt{n}\frac{\bar{x}-\theta_1}{\theta_2}}{\sqrt{\frac{S^{2}(n-1)}{\theta_2^{2}(n-1)}}} \sim t(n-1) \\ 
    \sqrt{n}\frac{\bar{x}-\theta_1}{S} \sim t(n-1)
  \end{gather*}

  \incfig{l7_2}
  \begin{gather*}
    t_1=t_{\frac{1-\beta}{2}}(n-1) \qquad t_2=t_{\frac{1+\beta}{2}}(n-1) \\ 
    P(t_1 < \sqrt{n}\frac{\bar{x}-\theta_1}{S} < t_2)= \beta \\ 
    \bar{x}-\frac{S t_2}{\sqrt{n}} < \theta_1 < \bar{x} - \frac{S t_1}{\sqrt{n}}
  \end{gather*}
\end{eg}
\subsection{Асимптотический метод}
$h, \vec{x}_n \rightarrow f(h,\vec{x}_n) \rightsquigarrow g(t)$

По ОММ
  \begin{gather*}
    \sqrt{n}(g(\tilde{\vec{\theta}})-g(\vec{\theta})) \rightsquigarrow N(\vec{0}, \nabla ^{T} g(\vec{\theta})I^{-1}(\vec{\theta})\nabla g(\vec{\theta})) \\ 
    \alpha=\begin{pmatrix}
      \alpha_{s_1} \\ \vdots \\ \alpha_{s_k}
    \end{pmatrix}
    \qquad 
    \tilde\alpha=\begin{pmatrix}
      \tilde{\alpha}_{s_1} \\ \vdots \\ \tilde{\alpha}_{s_k}
    \end{pmatrix} \qquad K_{ij}=\alpha_{s_i+s_j}-\alpha_{s_i}\alpha_{s_j} \\ 
    (\tilde{\alpha}_j-\alpha_j)\sqrt{n} \rightsquigarrow N(0, \alpha_{2k}-\alpha_k^{2}) \\ 
    \frac{\tilde{a}_k-\alpha_k}{\sqrt{\alpha_{2k}-\alpha_k^{2}}}\sqrt{n} \rightsquigarrow N(0,1) \\ 
    \tilde{\alpha}_k \overset{p}{\to} \alpha_k \qquad \sqrt{\tilde{\alpha}_{2k}-\tilde{\alpha}_k^{2}} \overset{p}{\to} \sqrt{\alpha_{2k}-\alpha_k^{2}} \\ 
    \frac{\sqrt{\alpha_{2k}-\alpha_k^{2}}}{\sqrt{\tilde{\alpha}_{2k}-\tilde{\alpha}_k^{2}} } \overset{ p}{ \to} 1
  \end{gather*}
  Лемма Слуцкого $\xi_n \overset{F}{\to} \xi$, $\eta_n \overset{p}{\to} C$, $\xi_n\eta_n \overset{F}{\to} C\xi$
  \begin{gather*}
    \frac{\tilde{a}_k-\alpha_k}{\sqrt{\alpha_{2k}-\alpha_k^{2}}}\sqrt{n}\frac{\sqrt{\alpha_{2k}-\alpha_k^{2}}}{\sqrt{\tilde{\alpha}_{2k}-\tilde{\alpha}_k^{2}} } \rightsquigarrow N(0,1) \\ 
    \boxed{
      \frac{\sqrt{n}(g(\tilde{\alpha})-g(\alpha))}{\sqrt{\nabla ^{T} g(\tilde{\alpha})K(\tilde{\alpha})\nabla g(\tilde{\alpha})}} \rightsquigarrow N(0,1)
    \qquad \text{ОММ} }\\ 
    \boxed{
      \frac{\sqrt{n}(g(\tilde{\vec{\theta}})-g(\vec{\theta}))}{\sqrt{\nabla ^{T} g(\tilde{\vec{\theta}})I^{-1}(\tilde{\vec{\theta}})\nabla g(\tilde{\vec{\theta}})}} \rightsquigarrow N(0,1)
    \qquad \text{ОМП} }
  \end{gather*}
\begin{eg}
  $\xi \sim \rho(x)=x\theta\{(0,1)\}+(1-\frac{\theta}{2})\{2\}$, $\theta\in(0,2)$

  $\vec{x}_n=\{0.53, 0.84, 0.1, 0.83, \underbrace{2,\dots ,2}_{16}\}$, $n=20$
  \begin{enumerate}
    \item ОММ $\tilde{\theta}=\frac{3}{2}(2-\bar{x})$, $\tilde{\theta}=0.4275$, $S=0.6$, $\beta=0.95$
      \begin{gather*}
        \tilde{\theta}=\frac{3}{2}(2-\tilde{\alpha}_1)=g(\tilde{\alpha}_1) \qquad \theta=g(\alpha_1) \\ 
        \frac{\sqrt{n}(g(\tilde{\alpha}_1)-g(\alpha_1))}{\sqrt{\nabla ^{T} g(\tilde{\alpha})K(\tilde{\alpha})\nabla g(\tilde{\alpha})}} \rightsquigarrow N(0,1) \\ 
        \nabla g =0\frac{3}{2} \qquad K_{11}=\alpha_2-\alpha_1^{2} \\ 
        \frac{\sqrt{n}(\tilde{\theta}-\theta)}{\sqrt{-\frac{3}{2}(-\frac{3}{2})(\tilde{\alpha}_2-\tilde{\alpha}_1^{2})}} \rightsquigarrow N(0,1) \\ 
        \tilde{\mu}_2=\tilde{\alpha}_2-\tilde{\alpha}_1^{2}=0.342 \qquad \tilde{\mu}_2=S^{2}\frac{n-1}{n} \\ 
      t_1=u_{\frac{1-0.95}{2}}=u_{0.025}=-1.96 \qquad t_2=u_{\frac{1+0.95}{2}}=u_{0.025}=1.96 
      \end{gather*}
      \begin{gather*}
        -1.96 < \frac{\sqrt{20}(0.4275-\theta)}{\sqrt{\frac{9}{4}\cdot 0.342}} < 1.96 \\ 
        0.0435 < \theta < 0.811 \qquad l=0.768
      \end{gather*}
    \item ОМП $\tilde{\theta}=2(1-\nu)=2(1-\frac{16}{20})=0.4$
      \begin{gather*}
        \frac{\sqrt{n}(\tilde{\theta}-\theta)}{\sqrt{I^{-1}(\theta)}} \rightsquigarrow N(0,1) \\ 
        I(\theta)=\frac{1}{\theta(2-\theta)} \\ 
        \frac{\sqrt{n}(\tilde{\theta}-\theta)}{\sqrt{\tilde{\theta}(2-\tilde{\theta})}} \rightsquigarrow N(0,1) \\ 
        -1.96 < \frac{\sqrt{20}(0.4-\theta)}{\sqrt{0.4 \cdot 1.6}} < 1.96 \\ 
        0.049 < \theta < 0.751 \qquad l=0.702
      \end{gather*}
      ОМП довер. инт. дисперсии
      \begin{gather*}
        D\xi=\frac{11}{12}\theta-\frac{4}{9}\theta^{2} \\ 
        \tilde{D\xi}=\frac{11}{12}\cdot 0.4 - \frac{4}{9} \cdot 0.4 ^{2}=0.296 \\
        \frac{\sqrt{n}(g(\tilde{{\theta}})-g({\theta}))}{\sqrt{\nabla ^{T} g(\tilde{{\theta}})I^{-1}(\tilde{{\theta}})\nabla g(\tilde{{\theta}})}} \rightsquigarrow N(0,1) \\ 
        \nabla g(\theta)=\frac{11}{12}-\frac{8}{9}\theta \\ 
        -1.96 < \frac{\sqrt{20}(\tilde{D\xi}-D\xi)}{\sqrt{(\frac{11}{12}-\frac{8}{9}\cdot 0.4)^{2}\cdot 0.4 \cdot 1.6}} < 1.96 \\ 
        0.1 < D\xi < 0.492
      \end{gather*}
  \end{enumerate}
\end{eg}
\subsection{Численные методы}
\begin{enumerate}
  \item Непараметрические методы

    $h, \vec{x}_n \rightarrow \tilde{h}$, берём выборку за вероятностную модель,
    из выборки формируем подвыборку $N=1000$, $\tilde{h}-h=\tilde{\Delta}$
    \begin{enumerate}
      \item $\vec{x}_n^{*}$ с повторение элем. $\Delta^{*}_1=\tilde{h}^{*}-\tilde{h}$
      \item ...
      \item ???
      \item ...
      \item $\vec{x}_n^{*}$ с повторение элем. $\Delta^{*}_{1000}=\tilde{h}^{*}-\tilde{h}$
      \item Profit!
    \end{enumerate}
    Вариационный ряд $\Delta^{*}_{(1)},\dots ,\Delta^{*}_{(1000)}$
    \begin{gather*}
      K_1=\left[\frac{1-\beta}{2}\cdot 10 0 0\right] \qquad K_2=\left[\frac{1+\beta}{2}\cdot 10 0 0\right] \\ 
      t_1=\Delta_{(k_1)} \qquad t_2=\Delta_{(k_2)} \\ 
      P(t_1< \tilde{h}^{*}-\tilde{h}<t_2) \approx \beta \\ 
      P(t_1< {h}^{*}-{h}<t_2) \approx \beta \\ 
      \tilde{h}-t_2 < h < \tilde{h} - t_1
    \end{gather*}
  \item Параметричекий бутстрап

    $h, \tilde{h}, \Delta=\tilde{h}-h$, $\xi \sim \rho(x,h)$, $\vec{x}_n \to \tilde{h}$ - сост. и несм. оценка

    $\xi \sim \rho(x, \tilde{h})$ моделируем выборки $\vec{x}_n^{*}$, $N=50000$

    $\Delta^{*}_i=\tilde{h}^{*}-\tilde{h}$, $\Delta_{(1)}^{*}\dots \Delta_{(N)}^{*}$
    \begin{gather*}
      K_1=\left[\frac{1-\beta}{2}\cdot N\right] \qquad K_2=\left[\frac{1+\beta}{2}\cdot N \right] \\ 
      t_1=\Delta_{(k_1)}^{*} \qquad t_2=\Delta_{(k_2)}^{*} \\ 
      P(t_1< \tilde{h}^{*}-\tilde{h}<t_2) \approx \beta \\ 
      P(t_1< {h}^{*}-{h}<t_2) \approx \beta
    \end{gather*}
\end{enumerate}

\begin{eg}
  $\vec{x}_n=\{0.53, 0.84, 0.1, 0.83, \underbrace{2,\dots ,2}_{16}\}$, $n=20$
  \begin{enumerate}
    \item Непараметрический бутсрап $\tilde{\theta}=0.4$ ОМП $\tilde{\theta}=2(1-\nu)$
      \begin{itemize}
        \item $\vec{x}_n^{*}={0.53,\dots }$, $m=14$, $\Delta_1^{*}=\tilde\theta^{*}-\tilde{\theta}=0.2$
        \item ...
        \item $\Delta_{1 0 0 0}^{*}=0$
      \end{itemize}
      \begin{gather*}
        \beta=0.95 \qquad k_1=25 \qquad k_2=975 \\ 
        t_1=\Delta_{(25)}^{*}=-0.3 \qquad t_2=\Delta_{(975)}^{*}=0.4 \\ 
        P(-0.3<\tilde{\theta}^{*}-\tilde{\theta}<0.4)\approx 0.95 \\ 
        P(-0.3<\tilde{\theta}-\theta<0.4)\approx 0.95 \\ 
        0<\theta<0.7 \qquad l=0.7
      \end{gather*}
    \item Параметрический бутстрап $\tilde{\theta}=0.4$
      \[
        \xi \sim \rho(x,\theta)=x\theta\{(0,1)\} + (1-\frac{\theta}{2})\{2\} 
        =x \cdot 0.4 \{(0,1)\}+0.8\{2\}\\ 
      \]
      $N=10 0 0 0$, делаем выборки из модели и дальше так же как и непарам.
  \end{enumerate}
\end{eg}
\subsection{Доверительный интервал для частоты}
$\nu=\frac{m}{n}$ хорошая оценка $P(A)$

Интегральная теорема Муавра-Лапласа:
\begin{gather*}
  \frac{m-np}{\sqrt{np(1-p)}} \rightsquigarrow N(0,1) \\ 
  \frac{\nu-p}{\sqrt{p(1-p)}}\sqrt{n} \rightsquigarrow N(0,1) \\ 
  \frac{\nu-p}{\sqrt{\nu(1-\nu)}}\sqrt{n} \rightsquigarrow N(0,1)
\end{gather*}
\subsection{Доверительный интервал функции распределения}
$F$, $\tilde{F}(x)=\frac{m}{n}$, где $m$ - кол-во элементов меньше $x$
\[
  \frac{\tilde{F}(x)-F(x)}{\sqrt{\tilde{F}(x)(1-\tilde{F}(x))}}\sqrt{n}\rightsquigarrow N(0,1)
\]

\section{Проверка статистических гипотез}
\begin{definition}
  Гипотеза - любое высказывание о вероятностной модели.
\end{definition}
\begin{definition}
  Простая гипотеза - однозначное определение вероятностной модели.
\end{definition}
\begin{definition}
  Сложная гипотеза - неоднозначное определение вер. модели.
\end{definition}
$\rho \sim N(0,a)$, $H:a=2$ - простая, $H:a>2$ - сложная
\begin{definition}
  $H_0$ - основная гипотеза, $H_1$ - альтернативная (отклонение от основной)
\end{definition}
$H_0:a=2$, $H_1:a>2$

\subsection{Принцип от маловеороятного}
Пусть $H_0$ - верна. Событие $A$. $P(A|H_0)$ - мала. Событие $A$ наблюдаемо.
Отвергаем $H_0$, иначе нет оснований отвергнуть $H_0$.

% lecture 8 

\section{Критерии согласия}
\subsection{Критерий Пирсона}
Вероятностная модель, $\vec{x}_n$

$H_0: \xi \sim F(x)$ - простая гипотеза

$H_1: \bar{H_0}$ - сложная 

Полная группа событий: $A_1\dots A_k$ - конечная группа событий, $A_1+\dots + A_n=\Omega$,
$A_iA_j = \emptyset \ i\neq j$, $P(A_i)>0$

$H_0: P_i=P(A_i)$, $\tilde{P_i}=\nu_i=\frac{m_i}{n}$
\begin{gather*}
  \Delta = n \sum_{i=1}^{k}\frac{(p_i - \nu)^{2}}{p_i} \\
  \Delta = n \sum_{i=1}^{k}\frac{(p_i - \frac{m_i}{n})^{2}}{p_i}
  = \sum_{i=1}^{k}\frac{(np_i - m_i)^{2}}{np_i} \\
\end{gather*}
\begin{theorem}
  Если $H_0$ верна, то $\Delta \rightsquigarrow \chi^{2}(k-1)$
\end{theorem}
\begin{remark}
  Нормальная аппроксимация при $n \ge 50$, $ np_i \ge 5$
  (можно мухлевать: $np_i \ge 1$ и в $20\%$ случаев можем разрешить $np_i < 5$)
\end{remark}
\begin{eg}
  $H_0:$ красные автомобили штрафуют в 2 раза чаще остальных

  $H_1: \bar{H_0}$

  Выборка: $150$ штрафов, $90$ красные, $A_{red}$, $A_{other}$
\begin{center}
\begin{tabular}{| c | c | c |}
  \hline
   & $A_{r}$ & $A_o$ \\ 
  \hline
  $p_i$ & $2/3$ & $1/3$ \\
  \hline
  $np_i$ & $100$ & $50$ \\
  \hline
  $np_i$ & $90$ & $60$ \\
  \hline
\end{tabular}
\end{center}
\begin{gather*}
  \tilde{\Delta} = \frac{(10 0 -90)^{2}}{10 0} + \frac{(50-60)^{2}}{50}=3
\end{gather*}
$\alpha$ - уровень значимости, $\alpha=.1; \boxed{.05}; .01$

$H_0: \Delta \rightsquigarrow \chi^{2}(1)$, $k=2$

p-value $= P(\Delta \ge \tilde{\Delta}| H_0)=\int_{3}^{\infty}q(t)dt=0.083$

Нет веских оснований отвергнуть $H_0$.

\hr
\begin{remark}
  Правила использования p-value:
  \begin{enumerate}
    \item Если p-value $\le \alpha$, то $H_0$ отвергается, результаты значимы,
      p-value - мера значимости
    \item Если p-value $>\alpha$, то нет оснований отвергать $H_0$,
      результаты незначимы.

      Либо гипотеза верна (отклонения объясняются случайными факторами),
      либо критерий недостаточно мощный.
  \end{enumerate}
  p-value не является вероятностью $H_0$ и не является вероятностью случайных факторов!
\end{remark}
\hr

\begin{eg}[Закон Бенфорда]
  В больших массивах данных, полученных ествественным путём, следуют определённому распределению.
  \[
    P_i = \log_{10}(1+\frac{1}{d_i}) \qquad d_i=1,\dots ,9
  \]
  Рассмотрим числа Фибоначи (первые 100 штпук)
\end{eg}
\begin{center}
\begin{tabular}{| c | c | c | c | c | c | c| c | c | c |}
  \hline
  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 \\
  \hline
  $m_i$ & 29 & 18 & 13 & 9 & 8 & 6 & 5 & 7 & 5 \\
  \hline
  $p_i$ & 0.3 & 0.18 & 0.12 & 0.1 & 0.08 & 0.07 & 0.06 & 0.05 & 0.04 \\ 
  \hline
  $np_i$ & 3 & 18 & 12 & 10 & 8 & 7 & 6 & 5 & 4 \\ 
  \hline
\end{tabular}
\end{center}
8 и 9 объединяем чтобы попадать под условия приминимости
\begin{gather*}
  \tilde{\Delta} = \frac{(30-29)^{2}}{30} + \dots + \frac{(9-12)^{2}}{9}=1.53 \qquad \Delta \rightsquigarrow \chi^{2}(7) \\ 
  \text{p-value}=P(\Delta \ge \tilde{\Delta} | H_0)=\int_{1.53}^{\infty}q(t)dt=0.981
\end{gather*}
Нет оснований отвергать $H_0$.
\end{eg}

\subsection{Критерий Колмогорова (непр. распр.)}
$H_0:\xi \sim F(x)$, $H_1:\bar{H_0}$, $\vec{x}_n$
\[
  \Delta = \sqrt{n}\sup \limits_{x\in\R} |\tilde{F}(x)-F(x)|
\]
- где $\tilde{F}$ - империческая функция распределения.
\begin{theorem}
  Если $H_0$ верна, то $\Delta \rightsquigarrow K(x)$
  $K(x)$ - функ. распределения Колмогорова
  \[
    K(x)=P(\Delta<x)=1+2\sum_{k=1}^{\infty}(-1)^{k}e^{-2k^{2}x^{2}}\{(0, \infty)\}
  \]
\end{theorem}

\incfig{l8_kolm}
\[
  \sup \limits_{\R}|\tilde{F}(x)-F(x)|=
  \max \limits_{i=1,\dots ,n} \max(|\tilde{F}(x_i-0)-F(x_i)|,|\tilde{F}(x_i+0)-F(x_i)| )
\]
\begin{eg}
  $H_0:\xi \sim R(0,1)$, $H_1:\bar{H_0}$, $\vec{x}_n=(0.2; 0.5; 0.8; 0.9)$
  \begin{gather*}
    \tilde{\Delta} = \sqrt{4} \max (0.2;0,25; 0.3; 0.15)=2*0.3=0.6
  \end{gather*}
  $H_0: \Delta \rightsquigarrow K(x)$

  p-value $=P(\Delta \ge \tilde{\Delta} | H_0)=1-K(\tilde{\Delta})=-2\sum_{k=1}^{\infty}(-1)^{j}e^{-2k^{2}\tilde{\Delta}^{2}}=0.8642$

  4 элемента - вообще беда, используем бутстрап, так как считаем в вероятности,
  что верна $H_0$ по хорошему бутстрап параметрический
  \begin{itemize}
    \item $x_4^{*} \rightarrow \Delta_1^{*}=\sqrt{n}\sup|\tilde{F}^{*}(x)-F(x)|$
    \item ...
    \item $x_4^{*} \rightarrow \Delta_{N}^{*}=\sqrt{n}\sup|\tilde{F}^{*}(x)-F(x)|$
  \end{itemize}
  $N=10 0 0 0-50 0 0 0$, вариационный ряд $\Delta_{(1)}^{*}\dots \Delta_{(N)}^{*}$

  p-value $=\frac{K}{N}$, $K$ - число $\Delta^{*}_{(i)} \ge \tilde{\Delta}$

  p-value $=0.47$
\end{eg}

\subsection{Критерий Пирсона для слож. гипотезы}
$H_0: \xi \sim F(x, \vec{\theta})$, $\vec{\theta} \in \Theta \subset \R^{m}$,
$H_1:\bar{H_0}$, $\vec{x}_n$, $A_1\dots A_k$ - полная группа событий
\begin{gather*}
  P_i(\vec{\theta})=P(A_i) \qquad P_i=\nu_i \\ 
  \Delta=\sum_{i=1}^{n}\frac{(np_i(\vec{\theta})-m_i)^{2}}{np_i(\vec{\theta})}
\end{gather*}
\begin{theorem}
  Если $H_0$ верная и $\tilde{\vec{\theta}}$ есть ОМПГ,
  то $\Delta \rightsquigarrow  \chi^{2}(k-1-m)$
\end{theorem}

\begin{eg}
  $H_0: \xi \sim R(0,\theta)$, $\theta > 0$, $H_1: \bar{H_0}$
\begin{center}
  \begin{tabular}{| c | c | c | c| c| c|}
    \hline
    & $[0,1)$ &$[1,2)$ &$[2,3)$ &$[3,4)$ &$[4,\infty)$ \\ 
    \hline
    $m_1$ & 25 & 10 & 15 & 30 & 20 \\
    \hline
    $p_i$ & 1/5 & 1/5 & 1/5 & 1/5 & 1/5 \\ 
    \hline
    $np_i$ & 20 & 20 & 20 & 20 & 20 \\ 
    \hline
  \end{tabular}
\end{center}
\begin{gather*}
  P_i=\int_{a_i}^{b_i}\frac{1}{\theta}dx \qquad P_1=P_2=P_3=P_4=\frac{1}{\theta} \\
  P_5 = \int_{4}^{\infty}p(x,\theta)dx=\int_{4}^{\theta}\frac{1}{\theta}dx=\frac{\theta-4}{\theta} \\ 
  L(\theta)=\left(\frac{1}{\theta}\right)^{25+10+15+30}\left(\frac{\theta-4}{\theta}\right)^{20} \to \max \\ 
  \ln L = -80 \ln \theta + 20 \ln(\theta-4) - 20 \ln \theta= -100 \ln \theta + 20 \ln (\theta-4) \to \max \\ 
  (\ln L)'=-\frac{10 0}{\theta}+\frac{20}{\theta-4}=0 \qquad \tilde{\theta}=5
\end{gather*}
\begin{gather*}
  \Delta \rightsquigarrow \chi^{2}(5-1-1)=\chi^{2}(3) \\ 
  \tilde{\Delta}=\frac{(25-20)^{2}}{20} + \dots + \frac{(20-20)^{2}}{20}=12.5 \\ 
  \text{p-value}=P(\Delta \ge \tilde{\Delta}|H_0)=\int_{12.5}^{\infty}q(t)dt=0.0 0585
\end{gather*}
Отвергаем $H_0$.
\end{eg}
\begin{eg}
  $H_0:$ распределение Эрланга $\xi \sim p(x)=\frac{1}{\lambda^{2}}x e^{-x\ln x}\{(0, +\infty)\}$,
  $\lambda > 0$, $H_1:\bar{H_0}$
  \begin{center}
  \begin{tabular}{| c | c | c | c | c | c | c |}
    \hline
    & $[0;2.5)$ &$[2.5; 5)$ &$[5; 7.5)$ &$[7.5;10)$ &$[10; 12.5)$ & $[12.5; 15)$ \\ 
    \hline
    $m_i$ & 12 & 17 & 12 & 4 & 3 & 2\\
    \hline
    $np_i$ & 12.9 & 16.4 & 10.4 & 5.5 & 2.6 & 2.2 \\ 
    \hline
  \end{tabular}
  \end{center}
  \begin{gather*}
    \int_{a}^{b}p(x)dx=\frac{a}{\lambda}e^{-a/\lambda}-\frac{b}{\lambda}e^{-b/\lambda}+e^{-a/\lambda}-e^{-b/\lambda} \\ 
    P_1=\int_{0}^{2.5}p(x)dx \qquad \dots \qquad P_6=\int_{12.5}^{\infty}p(x)dx \\ 
    L(\lambda)=P_1^{12}\dots P_6^{2} \to \max
  \end{gather*}
  Считаем экстремум численно.
  \begin{gather*}
    \tilde{\lambda}=2.531
  \end{gather*}
  После объединения и пересчёта:
  \begin{gather*}
    \tilde{\lambda}=2.542 \qquad \tilde{\Delta}=0.756 \\ 
    \text{p-value}=P(\Delta \ge \tilde{\Delta}|H_0)=0.86
  \end{gather*}
\end{eg}

\subsection{Критерий Колмогорова для сл. гип. (непр. распр.)}
$H_0: \xi \sim F(x, \vec{\theta})$, $\vec{\theta} \in \Theta \subset \R^{m}$,
$H_1:\bar{H_0}$, $\vec{x}_n$, $A_1\dots A_k$ - полная группа событий
\begin{gather*}
  \Delta = \sqrt{n}\sup \limits_{x\in \R}|\tilde{F}(x)-F(x, \vec{\theta})|
\end{gather*}
Параметрический бутстрап: $\vec{x}_n \rightarrow \tilde{\vec{\theta}}$ - сост. оценка (любой метод)
\begin{gather*}
  \tilde{\Delta} = \sqrt{n}\sup \limits_{x\in \R}|\tilde{F}(x)-F(x, \tilde{\vec{\theta}})|
\end{gather*}
$\xi \sim F(x, \tilde{\vec{\theta}})$, $N=10 0 0 0 - 50 0 0 0$
\begin{itemize}
  \item $\vec{x}_n^{*} \rightarrow \tilde{\vec{\theta}}^{*} \rightarrow \Delta_1^{*}=\sqrt{n}\sup \limits_{x\in\R}|\tilde{F}^{*}(x)-F(x, \tilde{\vec{\theta}})|$
  \item ...
\end{itemize}
Вариационный ряд $\Delta_{(1)}^{*}\dots \Delta_{(N)}^{*}$, p-value $=\frac{K}{N}$,
$K$ - число элементов $\Delta_{(i)}^{*} \ge \tilde{\Delta}$
\begin{eg}[Эрланг]
  \[
    \tilde{\Delta}=0.3982 \qquad \text{p-value}=0.9284
  \]
\end{eg}

\subsection{Проверка гипотезы однородности}
$A_1\dots A_{k}$ - полная группа
\begin{itemize}
  \item 1 выборка $m_{11}\dots m_{1k}$
  \item ...
  \item l выборка $m_{l1}\dots m_{lk}$
\end{itemize}
$H_0:$ все выборки из одного распределения, $H_1:\bar{H_0}$
\begin{gather*}
  n = n_1 + \dots  + n_l \qquad \nu_{j}=\frac{\sum_{i=1}^{l}m_ij}{n} \\ 
  \Delta_1=\sum_{j=1}^{k}\frac{(m_{1j}-n_1\nu_j)^{2}}{n_1\nu_j} \qquad
  \Delta_s=\sum_{j=s}^{k}\frac{(m_{sj}-n_s\nu_j)^{2}}{n_s\nu_j} \\ 
  \Delta = \Delta_1+ \dots + \Delta_l
\end{gather*}
\begin{theorem}
  Если $H_0$ верна, то $\Delta \rightsquigarrow \chi^{2}((k-1)(l-1))$
\end{theorem}

\begin{eg}[Коллоквиум 2023]
  \phantom{.}

  \begin{center}
  \begin{tabular}{| c | c | c | c | c | c |}
    \hline
    & 2 & 3 & 4 & 5 & \\
    \hline
    1гр & 0 & 1 & 10 & 5 & 16 \\ 
    \hline
    2гр & 1 & 0 & 9 & 1 & 11 \\ 
    \hline
    3гр & 2 & 4 & 6 & 4 & 16 \\ 
    \hline
    4гр & 1 & 0 & 8 & 6 & 15 \\ 
    \hline
        & 4 & 5 & 33 & 16 & \\
    \hline
  \end{tabular}
  \end{center}
  \begin{center}
  \begin{tabular}{| c | c |}
    \hline
    2 и 5 & 3 и 4 \\ 
    \hline
    5 & 11 \\
    \hline
    2 & 9 \\ 
    \hline
    6 & 10 \\
    \hline
    7 & 8 \\
    \hline
    $\frac{20}{58}$ & $\frac{38}{58}$ \\
    \hline
  \end{tabular}
  \end{center}
  \begin{gather*}
    \Delta_1=0.074 \qquad \Delta_2=1.294 \qquad \Delta_3=0.064 \qquad \Delta_4=0.986 \\ 
    \tilde{\Delta}=2.418 \qquad \chi^{2}(1 \cdot 3) \\ 
    \text{p-value}=P(\Delta \ge \tilde{\Delta}|H_0)=0.49
  \end{gather*}
\end{eg}

\subsection{Проверка гипотезы независимости}
$(\xi, \eta)$, $H_0:$ $\xi$ и $\eta$ - независимы, $H_1:\bar{H_0}$, $A_i$ и $B_j$ - полные группы событий
\begin{center}
  \begin{tabular}{| c | c | c | c |}
    \hline 
    & $A_1$ & $\dots $ & $A_k$ \\ 
    \hline 
    $B_1$ & $m_{11}$ & $\dots $ & $m_{1k}$ \\ 
    \hline 
    $\vdots$ &$\vdots$ &$\vdots$ &$\vdots$ \\
    \hline 
    $B_l$ & $m_{l1}$ & $\dots $ & $m_{lk}$ \\ 
    \hline 
  \end{tabular}
\end{center}
\begin{gather*}
  P_1 = \frac{m_{11}+\dots +m_{1k}}{n} \qquad q_1 = \frac{m_{11}+\dots +m_{l1}}{n} \\ 
  \Delta = \sum_{i,j}^{}\frac{(m_{ij}-np_iq_j)^{2}}{np_iq_j}
\end{gather*}
\begin{theorem}
  Если $H_0$ верна, то $\Delta \rightsquigarrow \chi^{2}((k-1)(l-1))$.
\end{theorem}
\begin{eg}
  $n=246$, зависимость успеваемости от родного города
  \begin{center}
    \begin{tabular}{| c | c | c | c | c |}
      \hline 
      & Москва & Подмоск & Остальное & \\
      \hline 
      2 & 13 & 10 & 17 & $\frac{40}{246}$ \\ 
      \hline 
      3 & 35 & 38 & 19 & $\frac{92}{246}$ \\ 
      \hline 
      4 & 21 & 21 & 26 & $\frac{68}{246}$ \\ 
      \hline 
      5 & 16 & 11 & 19 & $\frac{46}{246}$ \\ 
      \hline 
        & $\frac{85}{246}$ & $\frac{80}{246}$ & $\frac{81}{246}$ & \\ 
      \hline
    \end{tabular}
  \end{center}
  \begin{gather*}
    \tilde{\Delta}=11.05 \qquad \text{p-value}=\int_{11.05}^{\infty}q(t)dt=0.087
  \end{gather*}
  Нет оснований отвергать $H_0$.
\end{eg}
\subsection{Проверка гипотезы случайности}
$H_0:$ элементы выборки независимы и одинакого распределены, $H_1:\bar{H_0}$,
$I_n$ - число инверсий в выборке
\begin{theorem}
  Если $H_0$ верно, то
\[
  \Delta=\frac{I_n-\frac{n(n-1)}{4}}{\sqrt{\frac{n^{3}}{36}}} \rightsquigarrow N(0,1)
\]
\end{theorem}
\begin{eg}
  $n=10$, $\vec{x}_n=(4, 10, 8, 8, 6, 7, 7, 9, 8, 9)$
  \begin{gather*}
    I_n=0+8+3+3+\dots + 0 = 15 \\ 
    \tilde{\Delta}=\frac{15-\frac{10\cdot 9}{4}}{\sqrt{\frac{10^3}{36}}}=-1.42 \\ 
    \text{p-value}=P(|\Delta| \ge |\tilde{\Delta}| \big| H_0)=2P(\Delta \ge |\tilde{\Delta}| \big| H_0)
    = 2 \int_{ 1.42}^{\infty}q(t)dt=0.155
  \end{gather*}
  Нет оснований отвергать $H_0$.
\end{eg}

% lecture 9 

\subsection{Критерий Смирнова для проверки гипотезы однородности (непр. расп.)}
$H_0: F(x)=G(x)$, $H_1: \bar{H_0}$ 
Выборки $\vec{x}_n$, $\vec{y}_m$
\[
  \Delta = \sqrt{\frac{nm}{n+m}}\sup \limits_{R}|\tilde{F}(x)-\tilde{G}(x)|
\]
где $\tilde{F}$ и $\tilde{G}$ - эмпирические функции распределения
\begin{theorem}
  Если $H_0$ верна, то $\Delta \rightsquigarrow K(x)$
\end{theorem}

\section{Использование доверительных интервалов для проверки гипотез}
Вероятностная модель, $h$ - характеристика вероятностной модели, $\tilde{h}$ - оценка

$H_0: h \in T_0$, $H_1: h \in T_1$, $T_0 \cap T_1 = \emptyset$

$\tilde{h} \ \rightarrow$  доверительный интервал (точный, асимптотический или непараметрический бутстраповский)

Если $I \subset T_1$, то $H_0$ отвергаем
\begin{eg}
  $H_0: h\le 3$, $H_1: h > 3$

  \begin{itemize}
    \item Если $\tilde{h} \le 3$ сразу говорим что нет оснований отвергать гипотезу
    \item Если $\tilde{h} > 3$, считаем доверительный интервал (правосторонний):
      $\tilde{h} \rightarrow I=[h_0, +\infty)$
  \end{itemize}
\end{eg}
\begin{eg}
  $H_0: h=3$, $H_1: h\neq 3$, в таком случае интервал двухсторонний: $I=(\tilde{h}-\delta, \tilde{h}+\delta)$
\end{eg}

\section{Методы построения критериев}
$G_{\text{кр}}$ ($G_{cr}$) - критическая область

$H_0$ отвергаем $\iff$ $\vec{x}_n \in G_{cr}$

$P(\vec{x}_n \in G \, | \, H_0) \le \alpha$ 

Ошибка I рода $\alpha_1=P(H_1 | H_0)$.

Ошибка II рода $\alpha_0=P(H_0 | H_1)$.

Если $H_0$ и $H_1$ сложные, то $\alpha_1=\sup \limits_{H_0} P(\vec{x}_n \in G| H_0)$,
$\alpha_2 = \sup \limits_{H_1} P(\vec{x}_n \not \in G | H_1)$

\begin{definition}[Мощность критерия]
  \[
    W(H_1)= P(\vec{x}_n \in G | H_1)
  \]
  Для простой гипотезы $W=1-\alpha_2$
\end{definition}

\begin{definition}[Состоятельность критерия]
  Критерий называется состоятельным, если 
  \[
    \forall H_1 \true W(H_1) \underset{n\to\infty}{\to} 1
  \]
\end{definition}

\begin{remark}
  $\alpha_1$ - наиболее опасная ошибка 

  $\alpha_1 \le \alpha$ обязательно, $\alpha_2 \to \min$,
  решаем оптимизационную задачу $ \ \rightarrow \ G_{opt}$
\end{remark}
\begin{eg}
  $H_0:$ болен, $H_1:$ здоров

  $\alpha_1=P(H_1|H_0)$ - признали больного здоровым - беда

  $\alpha_2=P(H_0|H_1)$ - признали здорового больным - не так критично
\end{eg}

\subsection{Теорема Неймана-Пирсона для проверки простой H0 против простой H1}
$\alpha_2 \to \min$, $\alpha_1 \le \alpha$
\begin{gather*}
  W=1 - \alpha_2=P(\vec{x}_n \in G | H_1) \to \max \\ 
  \int_{G}^{}L_1(\vec{x}_n)d\vec{x}_n= \int_{G}^{}\underbrace{\frac{L_1}{L_0}}_{l}L_0d\vec{x}_n \to \max \\ 
  G: l \ge C \qquad \int_{G}^{}L_0 d \vec{x}_n \le L
\end{gather*}

$l$ - отношение правдоподобия

\begin{eg}
  $n=25$, $\vec{x}=9.3$, $\alpha=0.02$

  $H_0: \xi  \sim N(10, 4)$, $H_1: \xi \sim N(9, 4)$
  \begin{gather*}
    l = \frac{L_1}{L_0}=\frac{\prod_{i=1}^{n}p_1(x_i)}{\prod_{i=1}^{n}p_0(x_i)}
    = \frac{\left(\frac{1}{\sqrt{2\pi}\cdot2}\right)^{n}e^{-\frac{1}{8}\sum_{i=1}^{n}(x_i-9)^{2}}}{\left(\frac{1}{\sqrt{2\pi}\cdot2}\right)^{n}e^{-\frac{1}{8}\sum_{i=1}^{n}(x_i-10)^{2}}} =\\
    = e^{-\frac{1}{8}\sum_{i=1}^{n}(2x_i-10)}=e^{-\frac{1}{4}n\bar{x}+\frac{19}{8}n} \ge C \\ 
    -\frac{1}{4}n \bar{x}+\frac{19}{8}n \ge \ln C \qquad G:\bar{x} \le A \\ 
    P(\bar{x} \le A | H_0) \le \alpha
  \end{gather*}
  По Т. Фишера:
  \begin{gather*}
    \frac{\bar{x}-a}{\sigma}\sqrt{n} \sim N(0,1) \\ 
    P(\frac{\bar{x}-10}{2}\sqrt{25}\le \frac{A-10}{2}\sqrt{25}) \le \alpha
  \end{gather*}
  $\frac{5}{2}(A-10)=U_{\alpha}$ - квантиль порядка $\alpha$ для нормального распределения
  \begin{gather*}
    \frac{A-10}{2}5=U_{\alpha}=-2.054 \\ 
    G: \bar{x} \le 9.18
  \end{gather*}
  $\bar{x} \not \in G$ нет оснований отвергунть $H_0$
  \begin{gather*}
    W=P(\bar{x}\in G | H_1)=P(\frac{\bar{x}-9}{2}5 \le \frac{9.18-9}{2}5)
    =\int_{-\infty}^{0.45}\frac{1}{\sqrt{2\pi}}e^{-\frac{x^{2}}{2}}dx=0.67 \\ 
    \alpha_1=0.02 \qquad \alpha_2=1-W=0.33
  \end{gather*}
  Сколько нужно $n$ чтобы имело смысл
  \begin{gather*}
    \alpha_1=0.01 \qquad \alpha_2=0.1 \\ 
    G\cdot \bar{x} \le B \\ 
    \alpha_1=P(\bar{x}\le B | H_0) = P(\frac{\bar{x}-10}{2}\sqrt{n} \le \frac{B-10}{2}\sqrt{n})=0.01 \\
    \alpha_2=P(\bar{x}> B | H_0) = P(\frac{\bar{x}-9}{2}\sqrt{n} \le \frac{B-10}{2}\sqrt{n})=0.1 \\
    \left\{\begin{aligned}
      & \frac{B-10}{2}\sqrt{n}=U_{0.01}=-2.33\\
      & \frac{B-9}{2}\sqrt{n}=U_{0.9}=1.28
    \end{aligned}\right. \\ 
    B=9.36 \qquad n=53
  \end{gather*}
\end{eg}

\begin{eg}
  $\xi \sim \xi(x)=(2-2\theta){x}\{(0,1)\}+\theta\{0\}$

  $H_0:\theta=\frac{1}{3}$, $H_1:\theta=\frac{1}{2}$, $n=1$, $\alpha=0.35$
  \begin{gather*}
    l=\frac{L_1}{L_0}=\frac{\rho_1(x)}{\rho_0(x)}
  \end{gather*}
  \begin{center}
    \begin{tabular}{| c | c | c |}
      \hline
      x & $(0,1)$ & 2 \\
      \hline 
      l & $\frac{x}{4x/3}=\frac{3}{4}$ & $\frac{1/2}{1/3}=\frac{3}{2}$\\ 
      \hline 
      $H_0, p$ & $\frac{2}{3}$ & $\frac{1}{3}$ \\ 
      \hline
      $H_1, p$ & $\frac{1}{2}$ & $\frac{1}{2}$ \\
      \hline
    \end{tabular}
  \end{center}
  \begin{gather*}
    G:l \ge C \qquad P(l \ge C | H_0) \le 0.35
  \end{gather*}
  $G: l\ge \frac{3}{2}$, $\alpha_1=\frac{1}{3}$, $\alpha_2=P(l < C|H_1)=\frac{1}{2}$
\end{eg}
\begin{eg}
  Те же условия что и в прошлом но $n=2$
  l:
  \begin{center}
    \begin{tabular}{| c | c | c |}
      \hline
      & $(0,1)$ & 2 \\
      \hline 
      $(0,1)$ & $\frac{1\cdot 1 \cdot x_1 \cdot x_2}{\frac{4}{3}x_1\frac{4}{3}x_2}=\frac{9}{16}$ & $\frac{x_2 \cdot \frac{1}{2}}{\frac{4}{3}x_2 \frac{1}{3}}=\frac{9}{8}$ \\
      \hline 
      $2$ & $\frac{9}{8}$ & $\frac{\frac{1}{2}\frac{1}{2}}{\frac{1}{3}\frac{1}{3}}=\frac{9}{4}$ \\
      \hline 
    \end{tabular}
  \end{center}
  $H_0$:
  \begin{center}
    \begin{tabular}{| c | c | c |}
      \hline
      & $(0,1)$ & 2 \\
      \hline 
      $(0,1)$ & $\frac{4}{9}$& $\frac{2}{9}$ \\
      \hline 
      $2$ & $\frac{2}{9}$& $\frac{1}{9}$ \\
      \hline 
    \end{tabular}
  \end{center}
  $H_1$:
  \begin{center}
    \begin{tabular}{| c | c | c |}
      \hline
      & $(0,1)$ & 2 \\
      \hline 
      $(0,1)$ & $\frac{1}{4}$& $\frac{1}{4}$ \\
      \hline 
      $2$ & $\frac{1}{4}$& $\frac{1}{4}$ \\
      \hline 
    \end{tabular}
  \end{center}
  \begin{gather*}
    G:l \ge C \qquad P(l \ge C | H_0) \le 0.35
  \end{gather*}
  $G: l\ge \frac{9}{4}$, $\alpha_1=\frac{1}{9}$, $\alpha_2=P(l < C|H_1)=\frac{3}{4}$, $W=\frac{1}{4}$

  Асимптотический критерий $n\to\infty$
  \begin{gather*}
    l=\frac{L_1}{L_0}=\prod_{i=1}^{n}\frac{\rho_1(x_i)}{\rho_0(x_i)} \ge C \\ 
    \ln l = \sum_{i=1}^{n}\ln \underbrace{\frac{\rho_1(x_i)}{\rho_0(x_i)}}_{\eta_i} \ge \ln C
  \end{gather*}
  ЦПТ

  Параметрический бутстрап

  $m$ - число появлений $2$
  \begin{gather*}
    l=\frac{L_1}{L_0}=\frac{\prod_{}^{}x_i\cdot \left(\frac{1}{2}\right)^{2}}{\left(\frac{4}{3}\right)^{n-m}\prod_{}^{}x_i\left(\frac{1}{3}\right)^{m}} \\ 
    l=\left(\frac{3}{4}\right)^{n-m}\left(\frac{3}{2}\right)^{n} \ge C \qquad P(l\ge C | H_0) \le \alpha \\ 
    \rho_0(x)=\frac{4}{3}x\{(0,1)\}+\frac{1}{3}\{2\}
  \end{gather*}
  \begin{itemize}
    \item $\vec{x}_n^{*} \rightarrow m_{1}^{*} \rightarrow l_1^{*}$
    \item ...
    \item $\vec{x}_n^{*} \rightarrow m_{N}^{*} \rightarrow l_N^{*}$
  \end{itemize}
  Вариационный ряд $l_{(1)}^{*}\dots l_{(N)}^{*}$, $k=[(1-\alpha)N]$, $C=l_{(k)}^{*}$

  $n=1$, $\alpha=0.02$, $N=50 0 0 0$, $C=4$

  $W=P(l \ge C|H_1)$, те же самые процедуры с другим распределением $W=\frac{k}{N}$, $W=0.17$
\end{eg}
\begin{eg}[Т11 из задания]
  $H_0: \xi \sim p_0(x)=1\{(0,1)\}$
  $H_1: \xi \sim p_0(x)=\frac{e}{e-1}e^{-x}\{(0,1)\}$

  \hr 
  a) $n=1$, $\alpha$
  \begin{gather*}
    l=\frac{L_1}{L_0}=\frac{\frac{e}{e-1}e^{-x}}{1} \ge C \qquad e^{-x} \ge B \qquad x \le A \\ 
    P(x \le A | H_0) = \alpha \qquad \int_{0}^{A}1dx=A=\alpha \\ 
    G: x \le \alpha \qquad \alpha_1= \alpha \\ 
    W=P(x \le A | H_1) = \int_{0}^{\alpha}\frac{e}{e-1}e^{-x}dx=\frac{e}{e-1}(1-e^{-\alpha}) \qquad \alpha_2=1-W
  \end{gather*}
  \hr 
  b) $n=2$, $\alpha$
  \begin{gather*}
    l = \frac{L_1}{L_0}=\frac{\left(\frac{e}{e-1}\right)^{2}e^{-x_1}e^{-x_2}}{1 \cdot 1} \ge C 
    \qquad x_1+x_2\le A \\ 
    P(x_1+x_2 \le A | H_0) =\alpha \qquad \iint\limits_{x_1+x_2 \le A}1dx_1dx_2=\frac{A^{2}}{2}=\alpha \qquad A=\sqrt{2\alpha}  \\ 
    G:x_1+x_2 \le \sqrt{2\alpha} \qquad \alpha_1=\alpha \\ 
    W=P(x_1 + x_2 \le A | H_1) =\iint\limits_{x_1+x_2 \le A} \left(\frac{e}{e-1}\right)^{2}e^{-x_1-x_2}dx_1dx_2=\\
    =\left(\frac{e}{e-1}\right)^{2}\int_{0}^{A}dx_1\int_{0}^{A-x_1}e^{-x_1}e^{-x_2}dx_2= \\ 
    =\left(\frac{e}{e-1}\right)^{2}\int_{0}^{A}e^{-x_1}(1-e^{-(A-x_1)})dx_1= \\ 
    =\left(\frac{e}{e-1}\right)^{2}\int_{0}^{A}(e^{-x_1}-e^{-A})dx_1 
    =\left(\frac{e}{e-1}\right)^{2}(1-e^{-A}-Ae^{-A}) \qquad A=\sqrt{2\alpha} \\ 
    \alpha=1-W
  \end{gather*}
  \hr
  c)
  \begin{gather*}
    l = \frac{L_1}{L_0} = \prod\frac{p_1(x_i)}{p_0(x_i)} \ge C \\ 
    \ln l = \sum_{}^{}\ln \underbrace{\frac{p_1(x_i)}{p_0(x_i)}}_{\eta_i} \ge \ln C \\ 
    \frac{\sum_{}^{}\eta_i-nM\eta_i}{\sqrt{nD\eta_i}} \rightsquigarrow N(0,1) \\ 
    P(\ln l \ge \ln C|H_0) = \alpha \qquad \eta=\ln(\frac{e}{e-1}e^{-x})=\ln \frac{e}{e-1}-x \\ 
    \ln l = \sum_{}^{}\ln \frac{e}{e-1}-\sum_{}^{}x_i \ge \ln C \qquad G:\sum_{}^{}x_i \le A \\ 
    P(\sum_{}^{}x_i \le A | H_0) = \alpha \qquad P(\frac{\sum_{}^{}x_i-nMx}{\sqrt{nDx}}\le \frac{A-nMx}{\sqrt{nDx}}|H_0)=\alpha \\ 
    Mx=\frac{1}{2} \qquad Dx = \frac{1}{2}(b-a)^{2}=\frac{1}{12} \\ 
    \frac{A-n\frac{1}{2}}{\sqrt{n\frac{1}{2}}}=u_\alpha \qquad A = n\frac{1}{2}+\sqrt{n\frac{1}{12}}u_\alpha \\ 
    G: \sum_{}^{}x_i \le n\frac{1}{2} + u_\alpha\sqrt{\frac{n}{12}} \qquad \alpha_1=\alpha \\
    W=P(\sum_{}^{}x_i \le A | H_1)=P(\frac{\sum_{}^{}x_i-nMx}{\sqrt{nDx}}\le \frac{A-nMx}{\sqrt{nDx}}|H_1) \\ 
    Mx = \int_{0}^{1}x \frac{e}{e-1}e^{-x}dx = \frac{e-2}{e-1} \qquad Mx^{2}=\frac{2e-5}{e-1} \qquad Dx=\frac{e^{2}-3e+1}{(e-1)^{2}} \\ 
    W = \int_{-\infty}^{B}\frac{1}{\sqrt{2\pi}}e^{-\frac{x^{2}}{2}}dx \qquad B=\frac{\frac{n}{2}+U_\alpha\sqrt{\frac{n}{12}}-n\frac{e-2}{e-1}}{\sqrt{n\frac{e^{2}-3e+1}{(e-1)^{2}}}} \qquad \alpha_2 = 1- W \\
    B=\frac{\sqrt{n}\cdot 0.082 + U_\alpha \sqrt{\frac{1}{12}}}{\sqrt{\frac{e^{2}-3e+1}{(e-1)^{2}}}} \underset{n\to\infty}{\to}\infty
  \end{gather*}
  Критерий состоятелен.

  \hr
  $\alpha=0.05$, $n=1$, $x \le 0.05$, $W=0.077$, $\alpha_2=0.923$

  $\alpha=0.05$, $n=2$, $x_1+x_2 \le 0.316$, $W=0.102$, $\alpha_2=0.898$

  $\alpha=0.05$, $n=10$, $\sum_{}^{}x_i \le 3.5$, $B=-0.78$, $W=0.22$, $\alpha_2=0.78$

% lecture 10 

  \hr 
  d) $G: x_{max} \le C$
  \begin{gather*}
    P(\vec{x}_n \in G | H_0)=\alpha \qquad P(x_{max} \le G | H_0)=\alpha \\ 
    \xi \sim F(x) \qquad \xi_{max} \sim (F(x))^{n} \\ 
    P(x_{max} \le C | H_0) = (\underbrace{F_0(C)}_{C})^{n}=\alpha \qquad C = \sqrt[n]{\alpha} \\ 
    G: x_{max} \le \sqrt[n]{\alpha} \qquad \alpha_1=\alpha \\ 
    W=P(\vec{x}_n \in G | H_1) =P(x_{max} \le C | H_1) \\
    H_1: \xi \sim p(x)=\frac{e}{e-1}e^{-x}\{(0,1)\} \qquad F_1(x)=\frac{e}{e-1}(1-e^{-x}) \\ 
    W=(F_1(C))^{n}=\left(\frac{e}{e-1}(1-e^{-\sqrt[n]{\alpha}})\right)^{n} \qquad \alpha_2=1-W
  \end{gather*} 
  Состоятельность $W\to 1$ при $n \to \infty$:
  \begin{gather*}
    e^{-(e^{\frac{1}{n}\ln \alpha})}= e^{-(1-\frac{1}{n}\ln\alpha+o(\frac{1}{n}))} \\ 
    \left(\frac{e}{e-1}(1-e^{-1}e^{-\frac{1}{n}\ln\alpha+o(\frac{1}{n})})\right)^{n}=\left(\frac{e}{e-1}(1-e^{-1}(1-\frac{1}{n}\ln \alpha+o(\frac{1}{n})))\right)^{n} = \\ 
    = \left[\frac{e}{e-1}\left(\frac{e-1}{e}+\frac{\ln \alpha}{ne}+o(\frac{1}{n})\right)\right]^{n} = \\ 
    =\left[1+\frac{\ln\alpha}{e-1}\frac{1}{n}+o(\frac{1}{n})\right]^{n} \underset{n\to\infty}{\to} e^{\frac{\ln \alpha}{e-1}}=\alpha^{\frac{1}{e-1}}\neq1
  \end{gather*}
  Не является состоятельной
\end{eg}

\subsection{Проверка сложных гипотез. КОП-критерий отношения правдоподобия}
$\xi \sim F(x, \vec{\theta}$, $\vec{\theta} \in \Theta \subset \R^{m}$

$H_0: \vec{\theta} \in \Omega_{0}$, $H_1: \vec{\theta} \in \Omega_{1}$, $\Omega_0 \cap \Omega_1 = \emptyset$, $\Omega=\Omega_0 \cup \Omega_1$
\begin{gather*}
  l=\frac{L_1}{L_0} \ge C \qquad l(x)=\frac{\sup_{\Omega_1}L}{\sup_{\Omega_0}L} \\ 
  G: \ l(x)=\frac{\sup_{\Omega}L}{\sup_{\Omega_0}L} \ge C \qquad P(l \ge C|H_0)=\alpha
\end{gather*}
(сверху в числителе омега без индекса!)
\begin{theorem}
  Если $H_0$ верна, то
  \[
    2\ln l \rightsquigarrow \chi^{2}(dim\Omega - dim \Omega_0)
  \]
\end{theorem}
\begin{eg}
  $\xi \sim p(x)=\theta e^{-\theta x}\{(0, +\infty)\}$, $\theta > 0$

  $H:\theta=\theta_0$, $H_1:\theta>\theta_0$

  $\Omega_0=\{\theta_0\}$, $\theta_1=\{\theta:\theta>\theta_0\}$, $\Omega=[\theta_0, +\infty)$
  
  Размерности соответсвенно 0, 1, 1

  \hr 
  \underline{$n=1$}
  \begin{gather*}
    L=\prod_{i=1}^{n}p(x_i,\theta)=p(x,\theta) \\ 
    \sup_{\theta_0}L=\theta_0e^{-\theta_0 x} \qquad \sup_{\Omega} L = \left\{\begin{aligned}
      & \theta_0 < \frac{1}{x}: \  \frac{1}{x}e^{-1} \\ 
      & \theta_0 > \frac{1}{x}: \ \theta_0 e^{-\theta_0 x}
    \end{aligned}\right. \\ 
    l=\left\{\begin{aligned}
      & \theta_0 < \frac{1}{x}: \  \frac{1}{x}\frac{e^{-1}}{\theta_0 e^{-\theta_0 x}} \\
      & \theta_0 > \frac{1}{x}: \ 1
    \end{aligned}\right. \ge C
  \end{gather*}
  \hr 
  Давим логикой

  \incfig{l10_eg1}
  Рассматривая записимость распределения от $\theta$, видим что у альтернативной гипотезы
  вероятность попасть в окрестность нуля больше, оттлакиваемся от этого
  \begin{gather*}
    G: x \le C \qquad P(x \le C | H_0) =\alpha \\ 
    \int_{0}^{C}\theta_0 e^{-\theta_0 x}dx = 1 - e^{-\theta_0 C}=\alpha \qquad C=-\frac{1}{\theta_0}\ln (1-\alpha) \\ 
    W(\theta)=P(x \le C | H_1) = \int_{0}^{C}\theta e^{-\theta x}dx =1-e^{-\theta C} 
    =1-e^{\frac{\theta}{\theta_0}\ln(1-\alpha)}
  \end{gather*}

  \incfig{l10_eg1_w}

  \incfig{l10_eg1_w2}
\end{eg}

\subsection{Проверка гипотез о параметрах нормальной модели}
$\xi \sim N(\theta_1, \theta_2^{2})$, $\theta_1 \in R$, $\theta_2 > 0$
\subsubsection{Проверка гипотез о значениях параметров}
a) $H_0: \theta_1=a$, $H_1: \theta_1 \neq a; \; \theta_1 > a; \; \theta_1 < a$

b) $H_0: \theta_2^{2}=b$, $H_1: \theta_2^{2} \neq b; \; \theta_2^{2} > b; \; \theta_2^{2} < b$

Теорема Фишера:
\begin{gather*}
\frac{\bar{x}-a}{\sigma}\sqrt{n}\sim N(0,1)  \qquad \frac{S^{2}(n-1)}{\sigma^{2}} \sim \chi^{2(n-1)} \qquad \frac{\bar{x}-a}{S}\sqrt{n}\sim t(n)
\end{gather*}
\begin{eg}
  $\xi \sim N(\theta, 0,001)$, $H_0: \theta_1 = 43$, $H_1: \theta \neq 43$, $n=50$, $\bar{x}=42.972$, $\alpha=0.05$
  \begin{gather*}
    \Delta=\frac{\bar{x}-43}{.1}\sqrt{50} \qquad G: |\Delta| \ge C \qquad P(|\Delta| \ge C| H_0)=\alpha \\ 
    2P(\Delta \ge C | H_0) =\alpha \qquad C=u_{1-\frac{\alpha}{2}} \\ 
    G: |\Delta| \ge u_{1-\alpha/2}=1.96 \\ 
    G: \left[\begin{aligned}
      & \bar{x} \ge 43.027 \\
      & \bar{x} \le 42.9723
    \end{aligned}\right.
  \end{gather*}
  $\bar{x}\in G$, отвергаем $H_0$
  \begin{gather*}
    W(\theta_1)=P(\vec{x}_n \in G | H_1)=P(\bar{x}\ge 43.027 | H_1) + P(\bar{x} \le 42.9723 | H_1) = \\ 
    = P(\frac{\bar{x}-\theta_1}{0.1}\sqrt{50} \ge \underbrace{\frac{43.027 - \theta_1}{0.1}\sqrt{50}}_{a_1}) +
P(\frac{\bar{x}-\theta_1}{0.1}\sqrt{50} \le \underbrace{\frac{42.9723 - \theta_1}{0.1}\sqrt{50}}_{a_2})= \\ 
= \int_{a_1}^{\infty}\frac{1}{\sqrt{2\pi}}e^{-\frac{x^{2}}{2}}dx + \int_{-\infty}^{a_2}\frac{1}{\sqrt{2\pi}}e^{-\frac{x^{2}}{2}}dx
  \end{gather*}
  
  \incfig{l10_eg2_w}

  Парктические методы:
  \begin{enumerate}
    \item p-value:
  \begin{gather*}
    \text{p-value}=P(|\Delta| \ge |\tilde{\Delta}| | H_0)= \\ 
    (\Delta=\frac{\bar{x}-43}{0.1}\sqrt{50} \qquad \tilde{\Delta}=-1.98) \\ 
    =2P(\Delta \ge 1.98) = 2 \int_{ 1.98}^{\infty}\frac{1}{\sqrt{2\pi}}e^{-\frac{x^{2}}{2}}dx = 0.0477
  \end{gather*}
    \item Доверительный интервал: 
      \begin{gather*}
        \beta=1-\alpha=0.95 \\ 
        -1.96 \le \frac{\bar{x}-a}{0.1}\sqrt{50} \le 1.96  \\ 
        I=(42.9443;42.9997) \qquad a \in I
      \end{gather*}
      $a=43$, $H_0$ отвергаем
  \end{enumerate}
\end{eg}

\begin{eg}
  $\xi \sim N(\theta_1, \theta_2^{2})$, $H_0: \theta_2^{2}=40 0$, $H_1:\theta_2^{2}\neq 40 0$,
  $S^{2}=784$, $n=20$, $\Delta = \frac{S^{2}(n-1)}{\theta_2^{2}} $

  \incfig{l10_eg3_d}
  \begin{gather*}
    P(\Delta \le C_1 | H_0) + P(\Delta \ge C_2 | H_0) = \alpha\\ 
    C_1= \chi^{2}_{\alpha/2}(n-1) \qquad C_2 = \chi^{2}_{1-\alpha/2}(n-1) \\ 
    \chi^{2}_{0.025}(19)=8.907 \qquad \chi^{2}_{0.975}(19)=32.87 \\ 
    \tilde{\Delta}=37.24
  \end{gather*}
  Попали в критическую область, отвергаем $H_0$.
  \begin{gather*}
    \text{p-value}=P(\Delta \ge \tilde{D} | H_0)=0.0 074
  \end{gather*}
  Оставляем гипотезу если $\frac{\alpha}{2}\le \text{p-value} \le 1- \frac{\alpha}{2}$,
  в данном случае не отвергаем.
\end{eg}

\subsubsection{Проверка гипотез о равенстве параметров}
a) $\xi \sim N(\phi, \theta_2^{2})$, $\eta \sim N(\psi, \theta_2^{2})$, 
независимы, $\theta_2^{2}$ одинакова, но неизвестна

$H_0: \phi=\psi$, $H_1: \phi \neq \psi, \phi > \psi, \phi < \psi$

\begin{gather*}
  x_n \qquad y_m \\ 
  \frac{\bar{x}-\phi}{\theta_2}\sqrt{n} \sim N(0,1) \qquad \frac{\bar{y}-\psi}{\theta_2}\sqrt{m} \sim N(0,1) \\ 
  \bar{x}-\phi \sim N(0, \frac{\theta_2^{2}}{n}) \qquad \bar{y}-\psi \sim N(0, \frac{\theta_2^{2}}{m}) \\ 
  \Delta = \bar{x} - \phi - (\bar{y}-\psi) \sim N(0, \frac{\theta_2^{2}}{n}+\frac{\theta_2^{2}}{m}) \\ 
  \tilde{\xi} \sim N(\vec{0}, K) \qquad L\vec{\xi}\sim N(\vec{0}, LKL^{T}) \\ 
  \Delta \sim N(0, \theta_2^{2}\frac{n+m}{nm}) \\ 
  \frac{\bar{x}-\bar{y}-(\phi -\psi)}{\theta_2 \sqrt{\frac{n+m}{nm}}} \sim N(0,1) \\ 
  \frac{S_x^{2}(n-1)}{\theta_2^{2}} \sim \chi^{2}(n-1) \qquad \frac{S_y^{2}(m-1)}{\theta_2^{2}} \sim \chi^{2}(m-1) \\ 
  \frac{S_x^{2}(n-1)-S_y^{2}(m-1)}{\theta_2^{2}} \sim \chi^{2}(n+m-2)
\end{gather*}
\begin{theorem}
  Если $H_0$ верна, то
  \[
    \cfrac{\bar{x}-\bar{y}}{\sqrt{\frac{n+m}{nm}}\sqrt{\frac{S_x^{2}(n-1)+S_y^{2}(m-1)}{n+m-2}}} \sim t(n+m-2)
  \]
\end{theorem}
Асимптотическое приближение $n\to \infty$, $m \to \infty$
\begin{gather*}
  \frac{\bar{x}-\phi}{\theta_2'}\sqrt{n} \sim N(0,1) \qquad \frac{\bar{y}-\psi}{\theta_2''}\sqrt{m} \sim N(0,1) \\ 
\end{gather*}
По лемме Слуцкого:
\begin{gather*}
  \frac{\bar{x}-\phi}{S_x}\sqrt{n} \rightsquigarrow N(0,1) \qquad \frac{\bar{y}-\psi}{S_y}\sqrt{m} \rightsquigarrow N(0,1) \\ 
  \bar{x}-\phi - (\bar{y}-\psi) \rightsquigarrow N(0, \frac{S_x^{2}}{n} + \frac{S_y^{2}}{m})
\end{gather*}
\begin{theorem}
  Если $H_0$ верна ($\phi=\psi$), то
  \[
    \frac{\bar{x}-\bar{y}}{\sqrt{\frac{S_x^{2}}{n}+\frac{S_y^{2}}{m}}} \rightsquigarrow N(0,1)
  \]
\end{theorem}

b) $\xi \sim N(a, \phi^{2})$, $\eta \sim N(b, \psi^{2})$ независ.

$H_0: \phi^{2}=\psi^{2}$, $H_1: \phi^{2}\neq \psi^{2}, \phi^{2} > \psi ^{2}, \phi^{2} < \psi ^{2}$
\begin{gather*}
  x_n \qquad y_m \\ 
  \frac{S_x^{2}(n-1)}{\phi} \sim \chi^{2}(n-1) \qquad \frac{S_y^{2}(m-1)}{\psi^{2}} \sim \chi^{2}(m-1) \\ 
  \frac{S_x^{2}}{\phi^{2}}\frac{\psi^{2}}{S_y^{2}} \sim F(n-1,m-1)
\end{gather*}
\begin{theorem}
  Если $H_0$ верна, то 
  \[
    \frac{S_x^{2}}{S_y^{2}} \sim F(n-1, m-1)
  \]
\end{theorem}

\begin{eg}
  $n=20$, $n_1=10$, $n_2=10$, A/B тестирование

  1 группа сразу: $12, 17.5, 16, 9.5, 15, 15.5, 13, 16.5, 14.5, 17$
  
  2 группа сразу: $16, 12, 15.5, 15, 14, 18.5, 18, 13, 17.5, 17$
  \begin{gather*}
    \bar{x}=14.65 \qquad S_x=2.49 \\ 
    \bar{y}=15.65 \qquad S_y = 2.17
  \end{gather*}
  \begin{enumerate}
    \item норм. закон распределения
    \item дисперсии равны
  \end{enumerate}
  $H_0: M\xi=M\eta$, $H_1:M\xi\neq M\eta$
  \begin{gather*}
    \frac{\bar{x}-\bar{y}}{\sigma}\sqrt{\frac{nm}{n+m}}\sim t(n+m-2) \qquad \sigma = \sqrt{\frac{(n-1)S_x^{2}+(m-1)S_y^{2}}{n+m-2}} \\ 
    \tilde{\Delta}=-1.044 \\ 
    \text{p-value} = P(|\Delta| \ge |\tilde{\Delta}| | H_0) = 2P(\Delta \ge 1.044) 
    = 2 \int_{1.044}^{+\infty}q(t)dt=0.31
  \end{gather*}
  Нет оснований отвергать гипотезу
\end{eg}

1) Критерий Колмогорова для двух выборок p-value $=0.3$, p-value $=0.68$

2) $H_0: D\xi=D\eta$, $H_1: D\xi \neq D\eta$
\begin{gather*}
 \Delta = \frac{S_x^{2}}{S_y^{2}} \sim F(n-1, m-1) \\ 
 \tilde{\Delta} = 1.147 \qquad g(t): F(9,9)\\ 
 \text{p-value}=P(\Delta \ge \tilde{\Delta} | H_0) = \int_{1.147}^{\infty}g(t)dt=0.42
\end{gather*}
3) Проверка гипотезы случайности:
\begin{gather*}
  \Delta=\frac{I_n-\frac{n(n-1)}{4}}{\sqrt{\frac{n^{3}}{36}}} \rightsquigarrow N(0,1)
\end{gather*}
Для $y$: $I_m=19$, $\tilde{\Delta}=-0.626$, p-value $=P(|\Delta| \ge |\tilde{\Delta}|)=2P(\Delta \ge 0.626)=0.531$,
нет оснований отвергать гипотезу.

Бутстрап - непараметрический бутстрап + метот доверительных инт.
\begin{gather*}
  h=M\xi - M\eta \qquad \tilde{h}=\bar{x}-\bar{y}=-1 \qquad \Delta=\tilde{h}-h \\ 
  \left\{\begin{aligned}
    & \vec{x}_n \to \vec{x}_n^{*} \\
    & \vec{y}_m \to \vec{y}_m^{*}
  \end{aligned}\right. \to \Delta_i^{*}=\bar{x}^{*}-\bar{y}^{*}-\tilde{h} \\ 
  K_1=[N\frac{1-\beta}{2}] \qquad K_2=[N\frac{1+\beta}{2}] \\ 
  P(\Delta^{*}_{(k_1)} < \Delta^{*} < \Delta^{*}_{(k_2)}) \approx \beta \\ 
\Delta^{*}_{(k_1)} < \Delta^{*} < \Delta^{*}_{(k_2)} \to (-1, 2)
\end{gather*}
$0 \in I$, нет оснований отвергнуть гипотезу

\subsection{Множественная проверка гипотез}
$H_{01}, \dots , H_{0m}$, всем соответсвует $\alpha$, $P(A_i)=\alpha $
\begin{gather*}
  P(A_1 + \dots + A_m)=\bar{P}({\bar{A}_1\dots \bar{A}_m}) = \\
  = 1 - P(\bar{A}_1\dots \bar{A}_m)= 1 - (1-\alpha)^{m} \approx 1 - (1-\alpha m) = \alpha m
\end{gather*}
\subsection{Метод Бонферрони}
Проверяем гипотезы на уровне $\alpha/m$, адекватно при $m \le 5$
\subsection{Метод Холма-Бонферрони}
Считаем p-value для всех гипотиз и упорядовиваем

$p_{(1)} \le p_{(2)} \le \dots  \le p_{(m)}$

$p_{(1)}$ сравниваем с $\alpha/m$: 

если $p_{(1)} \ge \alpha/m$, то нет оснаваний отвернуть все гипотезы

если $p_{(1)} < \alpha /m$, отвергаем $H_{0(1)}$, $p_{(2)}$ сравн. с $\alpha/(m-1)$, ..., $p_{(m)}$ сравн. с $\alpha$

% lecture 11

\section{Исследование зависимостей}
\subsection{Методы статистики}
\begin{enumerate}
  \item Традиционный анализ (ANCOVA)

    Обнаружение зависимостей в количественных данных
  \item Дисперсионный анализ (ANOVA)

    Обнаружение зависимости в качественных данных
  \item Регрессионный анализ

    Обнаружение и определение формы зависимости
\end{enumerate}

\hr
$\vec{\xi}=(\xi_1,\dots ,\xi_k)$ - факторы (регрессоры)

$\eta$ - отклик 

$\eta = f(\vec x)+\epsilon(\vec x)$ - апроксимация зависмости

$\vec{x}$ - значение $\vec{\xi}$, $\epsilon(\vec{x})$ - сл. вел.

Базис $\Psi_1^{(\vec{x})},\dots ,\Psi_p^{(\vec{x})}$, $f(\vec{x})=\sum_{m=1}^{p}\beta_m\Psi_m(\vec{x})$

Выбор базиса зависит от цели:
\begin{enumerate}
  \item Сглаживание данных
  \item Факторный анализ: $\Psi: 1,\underbrace{x_1,\dots ,x_k}_{\text{факторы}},\underbrace{x_1x_2,\dots, x_i^2}_{\text{взаим. влиян.}} $
\end{enumerate}
\begin{eg}
  Популяция $\xi=x$, $\eta=\dot{x}$
  \begin{enumerate}
    \item развитие $\eta=kx+\epsilon_1$, вероят. модель.
    \item ограниченность ресурсов $\eta=kx(a-x)+\epsilon_2$
    \item агрессивность внешней сред $\eta=kx(a-x)(x-b)+\epsilon_3$
  \end{enumerate}
\end{eg}
$\epsilon(\vec{x})\sim N(0, \sigma^{2})$

$\beta_1=M\eta$ при $x_i=0$ - среднее влияние внешних факторов
Вероятностная модель для одного отклика:
\begin{gather*}
  \eta = \sum_{m=1}^{p}\beta_m\Psi_m(\vec{x}) + \epsilon(\vec{x}) \ \text{- линейная регрессия}
\end{gather*}
Выборка $(y_i,\vec{x}_i) \ i=1,\dots ,n$
\begin{gather*}
  \Psi = \begin{pmatrix}
    \Psi_1(\vec{x}_1) & \dots & \Psi_p(\vec{x}_1) \\ 
    \dots & \dots & \dots \\ 
    \Psi_1(\vec{x}_n) & \dots & \Psi_p(\vec{x}_n)
  \end{pmatrix} \ \text{- матрица наблюдений} \\ 
  \eta = \begin{pmatrix}
    \eta_1 \\ \vdots \\ \eta_n
  \end{pmatrix} \ \text{- вектор отклика - сл. вел.} \qquad
  Y = \begin{pmatrix}
    y_1 \\ \vdots \\ y_n
  \end{pmatrix} \ \text{- значение век. откл.} \\ 
  \beta = \begin{pmatrix}
    \beta_1 \\ \vdots \\ \beta_n
  \end{pmatrix} \qquad 
  \epsilon = \begin{pmatrix}
    \epsilon_1(\vec{x}_1) \\ \vdots \\ \epsilon_n(\vec{x}_n)
  \end{pmatrix} = \begin{pmatrix}
    \epsilon_1 \\ \vdots \\ \epsilon_n
  \end{pmatrix} \ \text{ - вектор ошибок - сл. вел.} \\ 
  \tilde\beta = \begin{pmatrix}
    \tilde\beta_1 \\ \vdots \\ \tilde\beta_n
  \end{pmatrix} \qquad 
  e = \begin{pmatrix}
    e_1 \\ \vdots \\ e_n
  \end{pmatrix}  \ \text{ - значение } \epsilon
\end{gather*}
Вероятностная модель для вектора отклика
\[
  \eta = \Psi \beta + \epsilon
\]
Оценка по выборке
\[
  Y=\Psi \tilde{\beta} + e
\] 
$\epsilon \sim N(\vec{0}, \sigma^{2}E)$ - сильно регулярная, открытое множество $\sigma > 0$
\begin{gather*}
  L=\frac{1}{(\sqrt{2\pi})^{n}\sigma^{n}}e^{-\frac{1}{2\sigma^{2}}e^{T}e} \to \max \\ 
  e^{T}e \to \min \\ 
  (Y-\Psi\tilde{\beta})^{T}(Y-\Psi \tilde{\beta}) \to \min \\ 
  Y-\Psi \tilde{\beta} \perp \Psi t \qquad (\Psi t)^{T}(Y-\Psi \tilde{\beta})=0 \\ 
  t^{T}(\underbrace{\Psi^{T}Y-\Psi^{T}\Psi \tilde{\beta}}_{0})=0 \ \forall t \\ 
  F=\Psi^{T}\Psi \ \text{- полож. определённая (предположение)} \\ 
  F^{-1} \ \text{- матрица Фишера} \\ 
  \tilde{\beta}=F^{-1}\Psi^{T} Y
\end{gather*}
Свойства $\tilde{\beta}$: сост., асим. несмещ., асим. нормальн., асим. эффект (см. Замечание после примера)
\begin{eg}
  Выборка: $x=(1,2,3,4,5)$, $y=(6,5, 4, 5, 6)$

  Базис берём $x$, $\frac{1}{x}$
  \begin{gather*}
    \Psi =\begin{pmatrix}
      1 & 1 \\ 
      2 & \frac{1}{2} \\ 
      3 & \frac{1}{3} \\ 
      4 & \frac{1}{4} \\ 
      5 & \frac{1}{5}
    \end{pmatrix} \qquad 
    Y = \begin{pmatrix}
      6 \\ 5 \\ 4 \\ 5 \\ 6
    \end{pmatrix} \\ 
    F=\Psi^{T}\Psi = \begin{pmatrix}
      55 & 5 \\ 
      5 & 1.464
    \end{pmatrix} \qquad 
    F^{-1} = \begin{pmatrix}
      0.0264 & -0.09 \\ 
      -0.09 & 0.991
    \end{pmatrix} \\ 
    \tilde{\beta}=F^{-1}\Psi^{T}Y=\begin{pmatrix}
      0.954 \\ 5.153
    \end{pmatrix} \\ 
    y=0.954x + \frac{5.153}{x}+e
  \end{gather*}
  Распределение $\tilde{\beta}$ (как случайной вел)
  \begin{gather*}
    \tilde{\beta}=F^{-1}\Psi^{T}\eta = F^{-1}\Psi^{T}(\Psi\beta+\epsilon) 
    = F^{-1}\underbrace{\Psi^{T}\Psi}_{F}\beta + F^{-1}\Psi^{T}\epsilon \\ 
    \underbrace{F^{-1}\Psi^{T}}_{L}\epsilon \sim N(\vec{0},LEL^{T})=N(\vec{0}, F^{-1}) \\ 
    \tilde{\beta}\sim N(\beta, \sigma^{2}F^{-1})
  \end{gather*}
\end{eg}
\begin{remark}[Уточнение свойств $\tilde{\beta}$]
  \phantom{.}

  \begin{enumerate}
    \item состоятельная
    \item несмещ
    \item нормальная
    \item эффективная (trust me bro, без доказательства)
  \end{enumerate}
\end{remark}
\begin{eg}
  \begin{gather*}
    \tilde{\beta} \sim N\left(\begin{pmatrix}
      \beta_1 \\ \beta_2
    \end{pmatrix}, \sigma^{2}\begin{pmatrix}
    0.0264 & -0.09 \\ 
    -0.09 & 0.991 
    \end{pmatrix}\right) \\ 
    D\tilde{\beta}_1 = 0.0264\sigma^{2} \qquad 
    D\tilde{\beta}_2 = 0.991\sigma^{2} \qquad
    cov(\tilde{\beta}_1,\tilde{\beta}_2)=\sigma^{2}(-0.09) \\ 
  \end{gather*}
\end{eg}
\subsubsection{Оценка парметра сигма квадрат}
$RSS$ - остаточная сумма квадратов (residual sum of squares)

$RSS=e^{T}e$ - числа

  \incfig{l11_eg1}
  \begin{gather*}
    \eta_{L_1} = \Psi \tilde{\beta} \qquad \eta_{L_2} = \eta-\eta_{L_1} \\ 
    \eta = \Psi \beta + \epsilon \\ 
    (\Psi \beta + \epsilon)_{L_1} = \Psi \beta + \epsilon_{L_1} = \Psi \tilde{\beta} \\ 
    (\Psi \beta + \epsilon)_{L_2} = \epsilon_{L_2}=\eta_{L_2}
    RSS = |\eta_{L_2}|^{2} \ \text{- как сл. вел} \\ 
    RSS=|\epsilon_{L_2}|^{2}
  \end{gather*}
  Теорема о процекциях: $\epsilon \sim N(\vec{0}, \sigma^{2} E)$, $L_1$ и $L_2$ лин. подпр.
  $L_2 = L_1^{\perp}$, тогда $\epsilon_{L_1}$, $\epsilon_{L_2}$ норм. распр., незав
  и $\frac{|\epsilon_{L_1}|^{2}}{\sigma^{2}} \sim \chi^{2}(dim \, L_1)$,
  $\frac{|\epsilon_{L_2}|^{2}}{\sigma^{2}} \sim \chi^{2}(dim \, L_2)$
  \begin{gather*}
    \frac{RSS}{\sigma^{2}} \sim \chi^{2}(n-p) \\ 
    \Psi \beta + \epsilon_{L_1}=\Psi \tilde{\beta} \ |\cdot F^{-1}\Psi^{T} \\ 
  F^{-1}\Psi^{T}\Psi \beta + F^{-1}\Psi^{T}\epsilon_{L_1}=F^{-1}\Psi^{T}\Psi \tilde{\beta} \\ 
  \tilde{\beta} - \beta = F^{-1}\Psi^{T}\epsilon_{L_1}
  \end{gather*}
  $RSS$ и $\tilde{\beta}-\beta$ независ. как случайные величины
  \begin{gather*}
    \tilde{\sigma^{2}}=\frac{RSS}{n-p} \\ 
    M[\tilde{\sigma^{2}}]=M[\frac{RSS}{n-p}]=\frac{\sigma^{2}}{n-p}M[\frac{RSS}{\sigma^{2}}]=\sigma^{2} \quad \text{несмещ.} \\ 
  D[\tilde{\sigma^{2}}]=\frac{\sigma^{4}}{(n-p)^{2}}D[\frac{RSS}{\sigma^{2}}]=\frac{2\sigma^{4}}{n-p} \underset{n\to\infty}{\to} 0 \quad \text{сост.}
  \end{gather*}
\begin{eg}
  \begin{gather*}
    Y=\Psi \tilde{\beta}+e \\ 
    e = \begin{pmatrix}
      6 \\ 5 \\ 4 \\ 5 \\ 6 
    \end{pmatrix} - \Psi \begin{pmatrix}
      0.954 \\ 5.153
    \end{pmatrix} = \begin{pmatrix}
      -0.107 \\ 0.5155 \\ -0.58 \\ -0.104 \\ 0.2
    \end{pmatrix} \\ 
    RSS=e^{T}e=0.664 \qquad \tilde{\sigma^{2}}=\frac{0.664}{5-2}=0.221
  \end{gather*}
  Прогноз:
  \begin{gather*}
    x_0 = 2.5 \qquad \tilde y_0=\Psi(x_0)\tilde{\beta} \\ 
    \Psi(x_0) = (\Psi_1(x_0) \ \Psi_2(x_0))=(2.5 \ \frac{1}{2.5})  \\ 
    \tilde y_0 = (2.5 \ \frac{1}{2.5})\begin{pmatrix}
      0.954 \\ 5.153
    \end{pmatrix} = 4.45
  \end{gather*}
\end{eg}
\subsubsection{Доверительный интервал}
  \begin{gather*}
    \eta_0= \underbrace{\Psi(x_0)}_{\Psi_0}\beta + \underbrace{\epsilon(x_0)}_{\epsilon_0} \\ 
    \tilde{y_0} \sim N(\Psi_0 \beta, \sigma^{2}\Psi_0 F^{-1}\Psi_0^{T}) \\ 
    \eta_0 \sim N(\Psi_0 \beta, \sigma^{2}) \\ 
    \tilde{y_0}-\eta_0 \sim N(0, \sigma^{2}(1+\Psi_0 F^{-1}\Psi^{T})) \\ 
    \left\{\begin{aligned}
      & \frac{\tilde{y_0}-\eta_0}{\sigma \sqrt{1+\Psi_0 F^{-1}\Psi^{T}}} \sim N(0,1) \\ 
      & \frac{RSS}{\sigma^{2}} \sim \chi^{2}(n-p)
    \end{aligned}\right. \quad \text{независ.} \\ 
    \frac{\cfrac{\tilde{y_0}-\eta_0}{\sqrt{1+\Psi_0F^{-1}\Psi_0}}}{\sqrt{\cfrac{RSS}{n-p}}} \sim t(n-p) \\ 
    t_{\frac{1-\beta}{2}}(n-p) < \frac{\tilde{y_0}-\eta_0}{\sqrt{1+\Psi_0F^{-1}\Psi_0}}\sqrt{\frac{n-p}{RSS}} < t_{\frac{1+\beta}{2}}(n-p) \\ 
    \tilde{y_0}-\Delta < \eta_0 < \tilde{y_0} + \Delta \\ 
    \Delta = t_{\frac{1+\beta}{2}}(n-p)\frac{\sqrt{RSS(1+\Psi_0F^{-1}\Psi_0)}}{\sqrt{n-p}}
  \end{gather*}
\begin{eg}
  \begin{gather*}
    \beta = 0.95 \qquad t_{0.975}(3)=3.182 \\ 
    \Delta = 3.182\sqrt{\frac{(1+0.144)0.664}{3}}=1.6 \\ 
    \tilde{y_0}=4.45 \\ 
    (2.85, 6.05)
  \end{gather*}    
\end{eg}

\subsection{Проверка гипотез}
\subsubsection{Проверка значимости коэфф. регрессии}
$H_0: \beta_i=0$, $H_1: B_i \neq 0$ 
\begin{gather*}
  \tilde{\beta_i}\sim N(\beta_i, \sigma^{2}F_{ii}^{-1}) \\ 
  \frac{\tilde{\beta_i}-\beta_i}{\sigma\sqrt{F_{ii}^{-1}}} \sim N(0,1) \qquad \frac{RSS}{\sigma^{2}}\sim \chi^{2}(n-p) \\ 
  \frac{\tilde{\beta_i}-\beta}{\sqrt{RSS \cdot F_{ii}^{-1}}\sqrt{n-p}}\sim t(n-p)
\end{gather*}
\begin{theorem}
  Если $H_0$ верна, то 
  \[
    \Delta = \frac{\tilde{\beta_i}}{\sqrt{RSS \cdot F_{ii}^{-1}}}\sqrt{n-p} \sim t(n-p)
  \]
\end{theorem}
\begin{eg}
  \begin{gather*}
    \tilde{\beta_1}=0.954 \qquad RSS=0.664 \qquad F_{11}^{-1}=0.0264 \\ 
    \tilde{\Delta}=12.48 \qquad \Delta \sim t(3) \\ 
    \text{p-value} = P(|\Delta| \ge |\tilde{\Delta}| \big| H_0)=
    2P(\Delta \ge 12.48) = 2 \int_{12.48}^{\infty}g(t)dt = 0.0 011
  \end{gather*}
  Отвергаем $H_0$, $\beta_1$ значимый
\end{eg}
\subsubsection{Проверка равенства коэфф.}
$H_0: \: \beta_i =\beta_j$, $H_1:\: \beta_i\neq\beta_j, \beta_i > \beta_k, \beta_i < \beta_j$
\begin{gather*}
  \tilde{\beta_i}\sim N(\beta_i, \sigma^{2}F_{ii}^{-1}) \\ 
  \tilde{\beta_j}\sim N(\beta_j, \sigma^{2}F_{jj}^{-1}) \\ 
  \frac{\tilde{\beta_i}-\beta_i - (\tilde{\beta_j}-\beta_j)}{\sigma}\sim N(0, F^{-1}_{ii}+F^{-1}_{ij}) \\ 
\end{gather*}
\begin{theorem}
  Если $H_0$ верна, то
  \[
    \Delta = \frac{\tilde{\beta_i}-\tilde{\beta_j}}{\sqrt{RSS(F^{-1}_{ii}+F^{-1}_{jj})}}\sqrt{n-p} \sim t(n-p)
  \]
\end{theorem}
\begin{eg}
  $H_0:\beta_1=\beta_2$, $H_1:\beta_1\neq B_2$
  \begin{gather*}
    \tilde{\Delta}=-8.85 \qquad \Delta \sim t(3) \\ 
    \text{p-value}=2P(|\Delta| \ge |\tilde{\Delta}|)=2P(\delta \ge 8.85)
    = 2 \int_{8.85}^{\infty}g(t)dt=0.0 03
  \end{gather*}
  Различие $\beta_i$ значимо
\end{eg}
\begin{remark}
  Нормировка:\[
    y_i = \frac{x_i-x_{i\, min}}{x_{i \, max}-x_{i \, min}} \qquad z_i \in [0,1]
  \]
\end{remark}
\subsubsection{Сравнение регрессий}
Вспомогательная задача: 

$\eta = \gamma + \epsilon \qquad \epsilon \sim N(\vec{0}, \sigma^{2}E)$

$\gamma$ - лежит в подпр $L_1$, $L_0 \subset L_1$

$H_0: \: \gamma \in L_0$, $H_1: \: \gamma \in L_1/L_0$

\incfig{l11_rc}
\begin{gather*}
  d_1=|\eta-\eta_{L_1}|^{2} \qquad d_0=|\eta-\eta_{L_0}|^{2} \qquad d_{01}=d_0 -d_1 \\ 
  \R^{n}=L_0 \oplus L_0^{\perp} \oplus L_2
\end{gather*}
Теорема о проекц: $\epsilon \sim N(0, \sigma^{2} E)$ и $L_1 \oplus L_2 \oplus L_3$,
тогда $\epsilon_{L_1},\epsilon_{L_2},\epsilon_{L_3}$ - независ и $\frac{|\epsilon_{L_i}|^{2}}{\sigma^{2}} \sim \chi^{2}(dim \, L_i)$
\begin{gather*}
  \eta = \gamma + \epsilon \qquad H_0: \eta=\gamma+\epsilon \\ 
  d_1 = |\gamma+\epsilon - \gamma - \epsilon_{L_1}|^{2}=|\epsilon-\epsilon_{L_1}|^{2} \\ 
  H_0: d_0=|\gamma+\epsilon-\gamma-\epsilon_{L_0}|^{2}=|\epsilon-\epsilon_{L_0}|^{2}
\end{gather*}
$d_{01}$ - проек. $\epsilon$ на $L_0^{\perp}$
\begin{gather*}
  \left\{\begin{aligned}
    &\frac{d_{01}}{\sigma^{2}}\sim \chi^{2}(n_1-n_0) \\ 
    & \frac{d_1}{\sigma^{2}}\sim \chi^{2}(n-n_1)
  \end{aligned}\right. \quad \text{независ.} \\ 
  H_0: \Delta=\frac{d_{01}/(n_1-n_0)}{d_1/(n-n_1)}\sim F(n_1-n_0, n-n_1)
\end{gather*}

\end{document}
